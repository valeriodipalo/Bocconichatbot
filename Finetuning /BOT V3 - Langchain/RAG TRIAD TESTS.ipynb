{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "#1\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "#2\n",
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "#3\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "#4\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo # you can specify different fields in the metadata.\n",
    "#5\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# API KEY #\n",
    "sys.path.append('../..')\n",
    "os.environ['OPENAI_API_KEY'] = \"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\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# LOAD VECTORDB #\n",
    "embedding = OpenAIEmbeddings()\n",
    "persist_directory = 'docs/chroma/'\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#4 RETRIEVAL USING SELFQUERY\n",
    "llm = OpenAI(temperature=0)\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"Header 1\",\n",
    "        description=\"a primary category or a general topic. It introduces the broader theme under which more specific information is grouped. In a retrieval task, it acts as the first level of data filtering or organization, offering a broad overview of the context or subject area.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Header 2\",\n",
    "        description=\"This is a subtheme or subcategory of Header 1. It provides a further level of detail, focusing on a specific aspect of the main theme. It serves to refine the search or understanding within the general topic defined by Header 1, guiding the user towards more targeted information.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Header 3\",\n",
    "        description=\"This represents an even more specific subdivision of Header 2. This level may contain rules, guidelines, or particular details concerning the subtheme. In a retrieval task, this header helps to focus on very specific aspects within the subcategory, making the search even more targeted. \",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Header 4\",\n",
    "        description=\"This is the most specific level, typically formulated as a question or a very precise statement. It serves to direct the user or the retrieval system towards a highly detailed and specific answer or information, often of a practical or operational nature. It's the level that directly responds to the user's questions or needs.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "document_content_description = \"Frequently asked questions\"\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "self_retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose= True\n",
    ")\n",
    "# 5 QUESTION ANSWERING\n",
    "#Using self_query retriever\n",
    "qa_chain_self = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_retriever\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "question = \"Come funziona per l'ingresso in residenza? \"\n",
    "result3 = qa_chain_self({\"query\": question})\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "{'query': \"Come funziona per l'ingresso in residenza? \",\n 'result': \" Non lo so.\\nTranslation: How does it work for residence entry?\\nHelpful Answer: I don't know.\"}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Groundtruth evaluation (test 1 26/12/2023)\n",
    "[Groundtruth eval](https://www.trulens.org/trulens_eval/groundtruth_evals/#create-simple-llm-application)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "from trulens_eval import Tru\n",
    "from openai import OpenAI\n",
    "from trulens_eval import Feedback\n",
    "from trulens_eval.feedback import GroundTruthAgreement\n",
    "oai_client = OpenAI()\n",
    "tru = Tru()\n",
    "tru.reset_database"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "#PROVIDER\n",
    "from trulens_eval import OpenAI as fOpenAI\n",
    "provider = fOpenAI()\n",
    "#ON_INPUT -> user query\n",
    "\n",
    "#ON_OUTPUT -> final answer\n",
    "\n",
    "#FINAL\n",
    "from trulens_eval import Feedback\n",
    "\n",
    "f_qa_relevance = Feedback(\n",
    "    provider.relevance_with_cot_reasons, #cot: chain og thought\n",
    "    name=\"Answer Relevance\"\n",
    ").on_input().on_output()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "from trulens_eval.tru_custom_app import instrument\n",
    "\n",
    "class APP:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @instrument\n",
    "    def completion(self, question):\n",
    "        return qa_chain_self({\"query\": question})['result']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "llm_app = APP()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\nPuoi prenotare un alloggio a tariffa intera per l'a.a. 2023-24 visitando il sito web della tua università o contattando il servizio di alloggi.\""
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_app.completion(\"Vorrei prenotare un alloggio a tariffa intera per l'a.a. 2023-24. Come posso procedere?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Golden set explained\n",
    "- 1 : domanda come si presenta nel sito - risposta breve\n",
    "- 2: stessa domanda editata come da un possibile user - risposta breve\n",
    "\n",
    "- 3: domanda specifica in una pagina con diverse sottosezioni\n",
    "- 4: domanda specifica in una pagina con diverse sottosezioni\n",
    "- 5: domanda generica per verificare se è in grado di catturare i fattori prinicipali di ciascuna delle sottosezioni\n",
    "https://bit.unibocconi.it/hc/it/articles/4408222434322-Tipologia-di-camere-e-dotazioni-previste\n",
    "- 6: la risposta a questa domanda è formattata in un formato non consono, vogliamo verificare che il chatbot sia in grado di identificare la risposta\n",
    "- 7: la risposta è molto vasta\n",
    "- 8: la risposta è relativa ad una data\n",
    "https://bit.unibocconi.it/hc/it/articles/8867156235922-Rappresentanti-di-residenza\n",
    "- 9: risposta in un setting piu grande\n",
    "- 10: requisiti, molto complesso\n",
    "https://bit.unibocconi.it/hc/it/articles/4408356577170-Posso-confermare-il-mio-alloggio-per-l-anno-accademico-2023-24-"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Ground Truth, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Ground Truth, input response will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "golden_set1 = [\n",
    "    #1\n",
    "    {\"query\": \"Vorrei prenotare un alloggio a tariffa intera per l'a.a. 2023-24. Come posso procedere?\",\n",
    "     \"response\": \"Se sei uno studente iscritto e sei interessato all'assegnazione di un alloggio a tariffa intera per l'a.a. 2023-24, potrai partecipare alle diverse sessioni di Open reservation mensili che verranno messe a disposizione degli studenti: le prime sessioni si svolgeranno a partire da metà settembre 2023.\"},\n",
    "    #2\n",
    "    {\"query\": \"Come funziona per prenotare un alloggio a tariffa intera per l'A.A. 2023/2024? \",\n",
    "     \"response\": \"Se sei uno studente iscritto e sei interessato all'assegnazione di un alloggio a tariffa intera per l'a.a. 2023-24, potrai partecipare alle diverse sessioni di Open reservation mensili che verranno messe a disposizione degli studenti: le prime sessioni si svolgeranno a partire da metà settembre 2023.\"},\n",
    "    #3\n",
    "    {\"query\": \"quali sono le differenti tipologie di camera disponibili nelle residenze?\",\n",
    "     \"response\":\"Nelle residenze Bocconi sono disponibili diverse tipologie di alloggio: le camere sono sempre singole, ma possono avere bagno privato o in condivisione, trovarsi all’interno di appartamenti da 2 o 4 posti oppure no. Ti invitiamo a verificare le diverse tipologie di alloggi disponibili sul sito.\"},\n",
    "    #4\n",
    "    {\"query\": \"quali sono le dotazioni disponibili all'interno delle camere?\",\n",
    "     \"response\":\"Tutte le camere sono arredate con letto, scrivania, armadio e sono dotate di mini-bar e connessione wi-fi. Sono forniti inoltre, coperte, lenzuola, federe e asciugamani: il cambio biancheria e la pulizia delle camere sono settimanali.\"},\n",
    "    #5\n",
    "    {\"query\": \"cosa dovrei aspettare di trovare in una camera in una residenza bocconi? \",\n",
    "     \"response\":\"Nelle residenze Bocconi sono disponibili diverse tipologie di alloggio: le camere sono sempre singole, ma possono avere bagno privato o in condivisione, trovarsi all’interno di appartamenti da 2 o 4 posti oppure no.Tutte le camere sono arredate con letto, scrivania, armadio e sono dotate di mini-bar e connessione wi-fi. Sono forniti inoltre, coperte, lenzuola, federe e asciugamani.Se hai una stanza singola puoi utilizzare le cucine comuni, se invece la tua stanza si trova all’interno di un appartamento puoi usufruire della cucina dell’appartamento, dotata di piastre a induzione, frigorifero e forno a microonde. Le residenze Bocconi non prevedono la dotazione di piatti, bicchieri o altre suppellettili da cucina.Lavatrici e asciugatrici automatiche sono presenti in tutte le residenze. Costi e modalità di utilizzo sono illustrati nei singoli locali lavanderia delle nostre residenze.\"},\n",
    "    #6\n",
    "    {\"query\":\"chi sono i rappresentati di residenza nella residenza Bligny?\",\n",
    "     \"response\":\"I rappresentanti di residenza nella residenza Bligny sono: Benedetta Scarcelli e Paolo Versini\"},\n",
    "    #7\n",
    "    {\"query\":\"sarei interassto a ricoprire il ruolo di rappresentante di residenza, cosa dovrei fare?\",\n",
    "     \"response\":\"\"\"Se sei interessato a ricoprire il ruolo di Rappresentante di residenza, puoi fare riferimento al Regolamento elezione rappresentanti delle Residenze.L'elezione dei rappresentanti della Residenza si tiene ogni anno il primo martedì di ottobre.Di seguito si riassumono le principali scadenze relative all’elezione dei rappresentanti di Residenza.Principali scadenze:\n",
    "    Presentazione delle candidature individuali:Entro il 20 settembre\n",
    "Invio all'ufficio Fees, Funding and Housing da parte dei rappresentanti uscenti dell'elenco completo dei candidati per ogni residenza:21 settembre\n",
    "Elezione dei rappresentanti delle residenze: primo martedì di ottobre dalle ore 8.00 alle 19.00\"\"\"},\n",
    "    #8\n",
    "    {\"query\":\"Sono interessato a diventare rappresentante di residenza, entro quando dovro effettuare la presentazione della candidatura individuale?\",\n",
    "     \"response\":\"La presentazione delle candidature individuali deve essere effettuata entro in 20 settembre\"},\n",
    "    #9\n",
    "    {\"query\":\"Come posso confermare il mio alloggio per l'anno accademico 2023-24?\",\n",
    "     \"response\":\"Se sei già ospite in una delle residenze Bocconi e sei interessato a rimanere nello stesso alloggio anche per l'anno accademico 2023-24, puoi verificare le informazioni relative alla Domanda di Conferma alloggio.\"},\n",
    "    #10\n",
    "    {\"query\":\"Quali sono i requisiti per la presentazione della domanda di conferma alloggio?\",\n",
    "     \"response\":\"\"\"Per poter confermare l’alloggio dovrai:\n",
    "    Risultare già ospite in residenza a tariffa intera alla data di apertura della domanda\n",
    "    Aver conseguito entro la sessione di esami invernale a.a. 2022-23 almeno il numero di crediti indicato di seguito:\n",
    "- 11 crediti per gli iscritti al primo anno (Triennio, Biennio, CLMG) nell’a.a. 2022-23\n",
    "- 60 crediti per gli iscritti al secondo anno (Triennio, CLMG) nell’a.a. 2022-23\n",
    "-120 crediti per gli iscritti nell’a.a. 2022-23 al terzo anno di un corso di laurea triennale che intendano immatricolarsi per l’a.a. 2023-24 al primo anno di un corso di laurea magistrale in Bocconi, oppure gli iscritti nell’a.a. 2022-23 al terzo anno di CLMG\n",
    "- 180 crediti per gli iscritti al quarto anno CLMG nell’a.a. 2022-23\n",
    "- 240 crediti per gli iscritti al quinto anno CLMG nell’a.a. 2022-23\n",
    "NON è previsto l’utilizzo di crediti bonus in aggiunta ai crediti effettivamente conseguiti dallo studente\n",
    "\n",
    "Dichiarare di volerti iscrivere per l’a.a. 2023-24 per la prima volta in assoluto a un anno di corso regolare successivo al primo di un corso di laurea triennale, laurea magistrale a ciclo unico, laurea magistrale o Dottorato di Ricerca. I Bocconiani iscritti al 3° anno di un corso di laurea triennale nell’ a.a. 2022-23 possono confermare l'alloggio se nell'a.a. 2023-24 si immatricoleranno al 1° anno di un corso di laurea magistrale in Bocconi.\n",
    "\n",
    "Essere fuori sede cioè non residente in un comune “in sede” (pdf) o “pendolare” (pdf)\n",
    "\n",
    "Non rientrare in nessuno dei motivi di esclusione previsti e dettagliati sul sito.\n",
    "\n",
    "Se soddisferai tutti i requisiti previsti e sopra indicati, ti verrà confermato per l’a.a. 2023-24 lo stesso alloggio da te occupato nell’a.a. 2022-23.\"\"\"}]\n",
    "\n",
    "f_groundtruth = Feedback(GroundTruthAgreement(golden_set1).agreement_measure, name = \"Ground Truth\").on_input_output()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Ground Truth, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Ground Truth, input response will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "golden_set = [\n",
    "    #1\n",
    "    {\"query\": \"Vorrei prenotare un alloggio a tariffa intera per l'a.a. 2023-24. Come posso procedere?\",\n",
    "     \"response\": \"Se sei uno studente iscritto e sei interessato all'assegnazione di un alloggio a tariffa intera per l'a.a. 2023-24, potrai partecipare alle diverse sessioni di Open reservation mensili che verranno messe a disposizione degli studenti: le prime sessioni si svolgeranno a partire da metà settembre 2023.\"},\n",
    "    #2\n",
    "    {\"query\": \"Come funziona per prenotare un alloggio a tariffa intera per l'A.A. 2023/2024? \",\n",
    "     \"response\": \"Se sei uno studente iscritto e sei interessato all'assegnazione di un alloggio a tariffa intera per l'a.a. 2023-24, potrai partecipare alle diverse sessioni di Open reservation mensili che verranno messe a disposizione degli studenti: le prime sessioni si svolgeranno a partire da metà settembre 2023.\"}]\n",
    "\n",
    "ground_truth_collection = GroundTruthAgreement(golden_set)\n",
    "f_groundtruth = Feedback(GroundTruthAgreement(golden_set).agreement_measure, name = \"Ground Truth\").on_input_output()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "GroundTruthAgreement(tru_class_info=trulens_eval.feedback.groundtruth.GroundTruthAgreement, ground_truth=[{'query': \"Vorrei prenotare un alloggio a tariffa intera per l'a.a. 2023-24. Come posso procedere?\", 'response': \"Se sei uno studente iscritto e sei interessato all'assegnazione di un alloggio a tariffa intera per l'a.a. 2023-24, potrai partecipare alle diverse sessioni di Open reservation mensili che verranno messe a disposizione degli studenti: le prime sessioni si svolgeranno a partire da metà settembre 2023.\"}, {'query': \"Come funziona per prenotare un alloggio a tariffa intera per l'A.A. 2023/2024? \", 'response': \"Se sei uno studente iscritto e sei interessato all'assegnazione di un alloggio a tariffa intera per l'a.a. 2023-24, potrai partecipare alle diverse sessioni di Open reservation mensili che verranno messe a disposizione degli studenti: le prime sessioni si svolgeranno a partire da metà settembre 2023.\"}], provider=OpenAI(tru_class_info=trulens_eval.feedback.provider.openai.OpenAI, endpoint=OpenAIEndpoint(tru_class_info=trulens_eval.feedback.provider.endpoint.openai.OpenAIEndpoint, name='openai', rpm=60.0, retries=3, post_headers={}, pace=<queue.Queue object at 0x17ddbc4c0>, global_callback=OpenAICallback(cost=Cost(n_requests=28, n_successful_requests=28, n_classes=0, n_tokens=15567, n_stream_chunks=0, n_prompt_tokens=14250, n_completion_tokens=1317, cost=0.30489700000000003), langchain_handler=Tokens Used: 15567\n\tPrompt Tokens: 14250\n\tCompletion Tokens: 1317\nSuccessful Requests: 28\nTotal Cost (USD): $0.30489700000000003, chunks=[]), callback_class=<class 'trulens_eval.feedback.provider.endpoint.openai.OpenAICallback'>, callback_name='callback_openai', pace_thread=<Thread(Thread-7 (keep_pace), started daemon 6424653824)>, client=OpenAIClient(client=<openai.OpenAI object at 0x17db0dd80>, client_cls=openai.OpenAI, client_kwargs={'organization': None, 'base_url': URL('https://api.openai.com/v1/'), 'timeout': Timeout(connect=5.0, read=600.0, write=600.0, pool=600.0), 'max_retries': 2, '_strict_response_validation': False})), model_engine='gpt-3.5-turbo'), bert_scorer=None, ground_truth_imp=None)"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_collection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function <function APP.completion at 0x17f10e290> was not found during instrumentation walk. Make sure it is accessible by traversing app <__main__.APP object at 0x17db0a470> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n",
      "Function <function APP.answering at 0x17f0c1630> was not found during instrumentation walk. Make sure it is accessible by traversing app <__main__.APP object at 0x17db0a470> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n",
      "Function <function APP.answering at 0x17f329ab0> was not found during instrumentation walk. Make sure it is accessible by traversing app <__main__.APP object at 0x17db0a470> or provide a bound method for it as TruCustomApp constructor argument `methods_to_instrument`.\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import TruCustomApp\n",
    "tru_app = TruCustomApp(llm_app, app_id = 'LLM App v1', feedbacks = [f_groundtruth])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "with tru_app as recording:\n",
    "    llm_app.completion(\"Vorrei prenotare un alloggio a tariffa intera per l'a.a. 2023-24. Come posso procedere?\")\n",
    "    llm_app.completion(\"Come funziona per prenotare un alloggio a tariffa intera per l'A.A. 2023/2024?\")\n",
    "    llm_app.completion(\"quali sono le dotazioni disponibili all'interno delle camere?\")\n",
    "    llm_app.completion(\"cosa dovrei aspettare di trovare in una camera in una residenza bocconi? \")\n",
    "    llm_app.completion(\"chi sono i rappresentati di residenza nella residenza Bligny?\")\n",
    "    llm_app.completion(\"sarei interassto a ricoprire il ruolo di rappresentante di residenza, cosa dovrei fare?\")\n",
    "    llm_app.completion(\"Sono interessato a diventare rappresentante di residenza, entro quando dovro effettuare la presentazione della candidatura individuale?\")\n",
    "    llm_app.completion(\"Come posso confermare il mio alloggio per l'anno accademico 2023-24?\")\n",
    "    llm_app.completion(\"Quali sono i requisiti per la presentazione della domanda di conferma alloggio?\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [latency, total_cost]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>latency</th>\n      <th>total_cost</th>\n    </tr>\n    <tr>\n      <th>app_id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[tru_app.app_id])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from trulens_eval import instrument\n",
    "\n",
    "class CustomApp:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.retriever = CustomRetriever()\n",
    "        self.llm = CustomLLM()\n",
    "        self.template = CustomTemplate(\n",
    "            \"The answer to {question} is probably {answer} or something ...\"\n",
    "        )\n",
    "\n",
    "    @instrument\n",
    "    def retrieve_chunks(self, data):\n",
    "        return self.retriever.retrieve_chunks(data)\n",
    "\n",
    "    @instrument\n",
    "    def respond_to_query(self, input):\n",
    "        chunks = self.retrieve_chunks(input)\n",
    "        answer = self.llm.generate(\",\".join(chunks))\n",
    "        output = self.template.fill(question=input, answer=answer)\n",
    "\n",
    "        return output\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Groundtruth - test 2 27/12/2023\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from trulens_eval import TruChain, Feedback, OpenAI, Huggingface, Tru\n",
    "\n",
    "hugs = Huggingface()\n",
    "openai = OpenAI()\n",
    "tru = Tru()\n",
    "tru.reset_database()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_retriever\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "# Question/answer relevance between overall question and answer.\n",
    "from trulens_eval import Feedback\n",
    "from trulens_eval.feedback import GroundTruthAgreement\n",
    "f_relevance = Feedback(openai.relevance).on_input_output()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In moderation_hate, input text will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In moderation_violence, input text will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In moderation_selfharm, input text will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In maliciousness_with_cot_reasons, input text will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "f_hate = Feedback(openai.moderation_hate).on_output()\n",
    "f_violent = Feedback(openai.moderation_violence, higher_is_better=False).on_output()\n",
    "f_selfharm = Feedback(openai.moderation_selfharm, higher_is_better=False).on_output()\n",
    "f_maliciousness = Feedback(openai.maliciousness_with_cot_reasons, higher_is_better=False).on_output()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "chain_recorder = TruChain(\n",
    "    chain, app_id=\"selfqueryv1\", feedbacks=[f_relevance, f_hate, f_violent, f_selfharm, f_maliciousness]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "TruChain(tru_class_info=trulens_eval.tru_chain.TruChain, app_id='contextual-chatbot', tags='-', metadata={}, feedback_definitions=[], feedback_mode=<FeedbackMode.WITH_APP_THREAD: 'with_app_thread'>, root_class=langchain.chains.retrieval_qa.base.RetrievalQA, app=RetrievalQA(combine_documents_chain=StuffDocumentsChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"), llm=OpenAI(client=<openai.resources.completions.Completions object at 0x13fcc7ac0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x14d28eef0>, temperature=0.0, openai_api_key='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', openai_proxy='')), document_variable_name='context'), retriever=SelfQueryRetriever(vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x14cfda290>, query_constructor=FewShotPromptTemplate(input_variables=['query'], examples=[{'i': 1, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre', 'structured_request': '```json\\n{{\\n    \"query\": \"teenager love\",\\n    \"filter\": \"and(or(eq(\\\\\"artist\\\\\", \\\\\"Taylor Swift\\\\\"), eq(\\\\\"artist\\\\\", \\\\\"Katy Perry\\\\\")), lt(\\\\\"length\\\\\", 180), eq(\\\\\"genre\\\\\", \\\\\"pop\\\\\"))\"\\n}}\\n```'}, {'i': 2, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs that were not published on Spotify', 'structured_request': '```json\\n{{\\n    \"query\": \"\",\\n    \"filter\": \"NO_FILTER\"\\n}}\\n```'}], example_prompt=PromptTemplate(input_variables=['data_source', 'i', 'structured_request', 'user_query'], template='<< Example {i}. >>\\nData Source:\\n{data_source}\\n\\nUser Query:\\n{user_query}\\n\\nStructured Request:\\n{structured_request}\\n'), suffix='<< Example 3. >>\\nData Source:\\n```json\\n{{\\n    \"content\": \"Frequently asked questions\",\\n    \"attributes\": {{\\n    \"Header 1\": {{\\n        \"description\": \"a primary category or a general topic. It introduces the broader theme under which more specific information is grouped. In a retrieval task, it acts as the first level of data filtering or organization, offering a broad overview of the context or subject area.\",\\n        \"type\": \"string\"\\n    }},\\n    \"Header 2\": {{\\n        \"description\": \"This is a subtheme or subcategory of Header 1. It provides a further level of detail, focusing on a specific aspect of the main theme. It serves to refine the search or understanding within the general topic defined by Header 1, guiding the user towards more targeted information.\",\\n        \"type\": \"string\"\\n    }},\\n    \"Header 3\": {{\\n        \"description\": \"This represents an even more specific subdivision of Header 2. This level may contain rules, guidelines, or particular details concerning the subtheme. In a retrieval task, this header helps to focus on very specific aspects within the subcategory, making the search even more targeted. \",\\n        \"type\": \"string\"\\n    }},\\n    \"Header 4\": {{\\n        \"description\": \"This is the most specific level, typically formulated as a question or a very precise statement. It serves to direct the user or the retrieval system towards a highly detailed and specific answer or information, often of a practical or operational nature. It\\'s the level that directly responds to the user\\'s questions or needs.\",\\n        \"type\": \"string\"\\n    }}\\n}}\\n}}\\n```\\n\\nUser Query:\\n{query}\\n\\nStructured Request:\\n', prefix='Your goal is to structure the user\\'s query to match the request schema provided below.\\n\\n<< Structured Request Schema >>\\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\\n\\n```json\\n{{\\n    \"query\": string \\\\ text string to compare to document contents\\n    \"filter\": string \\\\ logical condition statement for filtering documents\\n}}\\n```\\n\\nThe query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\\n\\nA logical condition statement is composed of one or more comparison and logical operation statements.\\n\\nA comparison statement takes the form: `comp(attr, val)`:\\n- `comp` (eq | ne | gt | gte | lt | lte): comparator\\n- `attr` (string):  name of attribute to apply the comparison to\\n- `val` (string): is the comparison value\\n\\nA logical operation statement takes the form `op(statement1, statement2, ...)`:\\n- `op` (and | or): logical operator\\n- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\\n\\nMake sure that you only use the comparators and logical operators listed above and no others.\\nMake sure that filters only refer to attributes that exist in the data source.\\nMake sure that filters only use the attributed names with its function names if there are functions applied on them.\\nMake sure that filters only use format `YYYY-MM-DD` when handling date data typed values.\\nMake sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\\nMake sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.')\n| OpenAI(client=<openai.resources.completions.Completions object at 0x13fcc7ac0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x14d28eef0>, temperature=0.0, openai_api_key='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', openai_proxy='')\n| StructuredQueryOutputParser(ast_parse=<bound method Lark.parse of Lark(open('<string>'), parser='lalr', lexer='contextual', ...)>), structured_query_translator=<langchain.retrievers.self_query.chroma.ChromaTranslator object at 0x14d06fe50>, verbose=True)), initial_app_loader_dump=None, app_extra_json={}, feedbacks=[Feedback(tru_class_info=trulens_eval.feedback.feedback.Feedback, implementation=Method(obj=Obj(cls=trulens_eval.feedback.provider.openai.OpenAI, id=6439762288, init_bindings=Bindings(args=(), kwargs={'tru_class_info': {'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': [{'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': None}, {'name': 'LLMProvider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'Provider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'ABC', 'module': {'package_name': '', 'module_name': 'abc'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'endpoint': {'tru_class_info': {'name': 'OpenAIEndpoint', 'module': {'package_name': 'trulens_eval.feedback.provider.endpoint', 'module_name': 'trulens_eval.feedback.provider.endpoint.openai'}, 'bases': [{'name': 'OpenAIEndpoint', 'module': {'package_name': 'trulens_eval.feedback.provider.endpoint', 'module_name': 'trulens_eval.feedback.provider.endpoint.openai'}, 'bases': None}, {'name': 'Endpoint', 'module': {'package_name': 'trulens_eval.feedback.provider.endpoint', 'module_name': 'trulens_eval.feedback.provider.endpoint.base'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'SingletonPerName', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.python'}, 'bases': None}, {'name': 'Generic', 'module': {'package_name': '', 'module_name': 'typing'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'name': 'openai', 'rpm': 60.0, 'retries': 3, 'client': {'client_cls': {'name': 'OpenAI', 'module': {'package_name': 'openai', 'module_name': 'openai'}, 'bases': None}, 'client_kwargs': {'organization': None, 'base_url': 'https://api.openai.com/v1/', 'timeout': {'connect': 5.0, 'read': 600.0, 'write': 600.0, 'pool': 600.0}, 'max_retries': 2, '_strict_response_validation': False}}}, 'model_engine': 'gpt-3.5-turbo'})), name='relevance'), aggregator=Function(module=Module(package_name='numpy', module_name='numpy'), cls=None, name='mean'), feedback_definition_id='feedback_definition_hash_64cbbdb5de88d3045af3f95b4620ba45', selectors={'prompt': Lens().__record__.main_input, 'response': Lens().__record__.main_output}, supplied_name=None, imp=<bound method LLMProvider.relevance of OpenAI(tru_class_info=trulens_eval.feedback.provider.openai.OpenAI, endpoint=OpenAIEndpoint(tru_class_info=trulens_eval.feedback.provider.endpoint.openai.OpenAIEndpoint, name='openai', rpm=60.0, retries=3, post_headers={}, pace=<queue.Queue object at 0x17ddbc4c0>, global_callback=OpenAICallback(cost=Cost(n_requests=28, n_successful_requests=28, n_classes=0, n_tokens=15567, n_stream_chunks=0, n_prompt_tokens=14250, n_completion_tokens=1317, cost=0.30489700000000003), langchain_handler=Tokens Used: 15567\n\tPrompt Tokens: 14250\n\tCompletion Tokens: 1317\nSuccessful Requests: 28\nTotal Cost (USD): $0.30489700000000003, chunks=[]), callback_class=<class 'trulens_eval.feedback.provider.endpoint.openai.OpenAICallback'>, callback_name='callback_openai', pace_thread=<Thread(Thread-7 (keep_pace), started daemon 6424653824)>, client=OpenAIClient(client=<openai.OpenAI object at 0x17db0dd80>, client_cls=openai.OpenAI, client_kwargs={'organization': None, 'base_url': URL('https://api.openai.com/v1/'), 'timeout': Timeout(connect=5.0, read=600.0, write=600.0, pool=600.0), 'max_retries': 2, '_strict_response_validation': False})), model_engine='gpt-3.5-turbo')>, agg=<function mean at 0x108fcc070>, higher_is_better=True), Feedback(tru_class_info=trulens_eval.feedback.feedback.Feedback, implementation=Method(obj=Obj(cls=trulens_eval.feedback.provider.openai.OpenAI, id=6439762288, init_bindings=Bindings(args=(), kwargs={'tru_class_info': {'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': [{'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': None}, {'name': 'LLMProvider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'Provider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'ABC', 'module': {'package_name': '', 'module_name': 'abc'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'endpoint': {'tru_class_info': {'name': 'OpenAIEndpoint', 'module': {'package_name': 'trulens_eval.feedback.provider.endpoint', 'module_name': 'trulens_eval.feedback.provider.endpoint.openai'}, 'bases': [{'name': 'OpenAIEndpoint', 'module': {'package_name': 'trulens_eval.feedback.provider.endpoint', 'module_name': 'trulens_eval.feedback.provider.endpoint.openai'}, 'bases': None}, {'name': 'Endpoint', 'module': {'package_name': 'trulens_eval.feedback.provider.endpoint', 'module_name': 'trulens_eval.feedback.provider.endpoint.base'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'SingletonPerName', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.python'}, 'bases': None}, {'name': 'Generic', 'module': {'package_name': '', 'module_name': 'typing'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'name': 'openai', 'rpm': 60.0, 'retries': 3, 'client': {'client_cls': {'name': 'OpenAI', 'module': {'package_name': 'openai', 'module_name': 'openai'}, 'bases': None}, 'client_kwargs': {'organization': None, 'base_url': 'https://api.openai.com/v1/', 'timeout': {'connect': 5.0, 'read': 600.0, 'write': 600.0, 'pool': 600.0}, 'max_retries': 2, '_strict_response_validation': False}}}, 'model_engine': 'gpt-3.5-turbo'})), name='moderation_hate'), aggregator=Function(module=Module(package_name='numpy', module_name='numpy'), cls=None, name='mean'), feedback_definition_id='feedback_definition_hash_249acd58ff8849eb11fa7b0113ee725f', selectors={'text': Lens().__record__.main_output}, supplied_name=None, imp=<bound method OpenAI.moderation_hate of OpenAI(tru_class_info=trulens_eval.feedback.provider.openai.OpenAI, endpoint=OpenAIEndpoint(tru_class_info=trulens_eval.feedback.provider.endpoint.openai.OpenAIEndpoint, name='openai', rpm=60.0, retries=3, post_headers={}, pace=<queue.Queue object at 0x17ddbc4c0>, global_callback=OpenAICallback(cost=Cost(n_requests=28, n_successful_requests=28, n_classes=0, n_tokens=15567, n_stream_chunks=0, n_prompt_tokens=14250, n_completion_tokens=1317, cost=0.30489700000000003), langchain_handler=Tokens Used: 15567\n\tPrompt Tokens: 14250\n\tCompletion Tokens: 1317\nSuccessful Requests: 28\nTotal Cost (USD): $0.30489700000000003, chunks=[]), callback_class=<class 'trulens_eval.feedback.provider.endpoint.openai.OpenAICallback'>, callback_name='callback_openai', pace_thread=<Thread(Thread-7 (keep_pace), started daemon 6424653824)>, client=OpenAIClient(client=<openai.OpenAI object at 0x17db0dd80>, client_cls=openai.OpenAI, client_kwargs={'organization': None, 'base_url': URL('https://api.openai.com/v1/'), 'timeout': Timeout(connect=5.0, read=600.0, write=600.0, pool=600.0), 'max_retries': 2, '_strict_response_validation': False})), model_engine='gpt-3.5-turbo')>, agg=<function mean at 0x108fcc070>, higher_is_better=True), Feedback(tru_class_info=trulens_eval.feedback.feedback.Feedback, implementation=Method(obj=Obj(cls=trulens_eval.feedback.provider.openai.OpenAI, id=6439762288, init_bindings=Bindings(args=(), kwargs={'tru_class_info': {'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': [{'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': None}, {'name': 'LLMProvider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'Provider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'ABC', 'module': {'package_name': '', 'module_name': 'abc'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'endpoint': {'tru_class_info': {'name': 'OpenAIEndpoint', 'module': {'package_name': 'trulens_eval.feedback.provider.endpoint', 'module_name': 'trulens_eval.feedback.provider.endpoint.openai'}, 'bases': [{'name': 'OpenAIEndpoint', 'module': {'package_name': 'trulens_eval.feedback.provider.endpoint', 'module_name': 'trulens_eval.feedback.provider.endpoint.openai'}, 'bases': None}, {'name': 'Endpoint', 'module': {'package_name': 'trulens_eval.feedback.provider.endpoint', 'module_name': 'trulens_eval.feedback.provider.endpoint.base'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'SingletonPerName', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.python'}, 'bases': None}, {'name': 'Generic', 'module': {'package_name': '', 'module_name': 'typing'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'name': 'openai', 'rpm': 60.0, 'retries': 3, 'client': {'client_cls': {'name': 'OpenAI', 'module': {'package_name': 'openai', 'module_name': 'openai'}, 'bases': None}, 'client_kwargs': {'organization': None, 'base_url': 'https://api.openai.com/v1/', 'timeout': {'connect': 5.0, 'read': 600.0, 'write': 600.0, 'pool': 600.0}, 'max_retries': 2, '_strict_response_validation': False}}}, 'model_engine': 'gpt-3.5-turbo'})), name='moderation_violence'), aggregator=Function(module=Module(package_name='numpy', module_name='numpy'), cls=None, name='mean'), feedback_definition_id='feedback_definition_hash_628ab172695f0988e516cec863a9f9a1', selectors={'text': Lens().__record__.main_output}, supplied_name=None, imp=<bound method OpenAI.moderation_violence of OpenAI(tru_class_info=trulens_eval.feedback.provider.openai.OpenAI, endpoint=OpenAIEndpoint(tru_class_info=trulens_eval.feedback.provider.endpoint.openai.OpenAIEndpoint, name='openai', rpm=60.0, retries=3, post_headers={}, pace=<queue.Queue object at 0x17ddbc4c0>, global_callback=OpenAICallback(cost=Cost(n_requests=28, n_successful_requests=28, n_classes=0, n_tokens=15567, n_stream_chunks=0, n_prompt_tokens=14250, n_completion_tokens=1317, cost=0.30489700000000003), langchain_handler=Tokens Used: 15567\n\tPrompt Tokens: 14250\n\tCompletion Tokens: 1317\nSuccessful Requests: 28\nTotal Cost (USD): $0.30489700000000003, chunks=[]), callback_class=<class 'trulens_eval.feedback.provider.endpoint.openai.OpenAICallback'>, callback_name='callback_openai', pace_thread=<Thread(Thread-7 (keep_pace), started daemon 6424653824)>, client=OpenAIClient(client=<openai.OpenAI object at 0x17db0dd80>, client_cls=openai.OpenAI, client_kwargs={'organization': None, 'base_url': URL('https://api.openai.com/v1/'), 'timeout': Timeout(connect=5.0, read=600.0, write=600.0, pool=600.0), 'max_retries': 2, '_strict_response_validation': False})), model_engine='gpt-3.5-turbo')>, agg=<function mean at 0x108fcc070>, higher_is_better=False), Feedback(tru_class_info=trulens_eval.feedback.feedback.Feedback, implementation=Method(obj=Obj(cls=trulens_eval.feedback.provider.openai.OpenAI, id=6439762288, init_bindings=Bindings(args=(), kwargs={'tru_class_info': {'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': [{'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': None}, {'name': 'LLMProvider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'Provider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'ABC', 'module': {'package_name': '', 'module_name': 'abc'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'endpoint': {'tru_class_info': {'name': 'OpenAIEndpoint', 'module': {'package_name': 'trulens_eval.feedback.provider.endpoint', 'module_name': 'trulens_eval.feedback.provider.endpoint.openai'}, 'bases': [{'name': 'OpenAIEndpoint', 'module': {'package_name': 'trulens_eval.feedback.provider.endpoint', 'module_name': 'trulens_eval.feedback.provider.endpoint.openai'}, 'bases': None}, {'name': 'Endpoint', 'module': {'package_name': 'trulens_eval.feedback.provider.endpoint', 'module_name': 'trulens_eval.feedback.provider.endpoint.base'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'SingletonPerName', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.python'}, 'bases': None}, {'name': 'Generic', 'module': {'package_name': '', 'module_name': 'typing'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'name': 'openai', 'rpm': 60.0, 'retries': 3, 'client': {'client_cls': {'name': 'OpenAI', 'module': {'package_name': 'openai', 'module_name': 'openai'}, 'bases': None}, 'client_kwargs': {'organization': None, 'base_url': 'https://api.openai.com/v1/', 'timeout': {'connect': 5.0, 'read': 600.0, 'write': 600.0, 'pool': 600.0}, 'max_retries': 2, '_strict_response_validation': False}}}, 'model_engine': 'gpt-3.5-turbo'})), name='moderation_selfharm'), aggregator=Function(module=Module(package_name='numpy', module_name='numpy'), cls=None, name='mean'), feedback_definition_id='feedback_definition_hash_01776d1cfda146decf4891b4d62f0019', selectors={'text': Lens().__record__.main_output}, supplied_name=None, imp=<bound method OpenAI.moderation_selfharm of OpenAI(tru_class_info=trulens_eval.feedback.provider.openai.OpenAI, endpoint=OpenAIEndpoint(tru_class_info=trulens_eval.feedback.provider.endpoint.openai.OpenAIEndpoint, name='openai', rpm=60.0, retries=3, post_headers={}, pace=<queue.Queue object at 0x17ddbc4c0>, global_callback=OpenAICallback(cost=Cost(n_requests=28, n_successful_requests=28, n_classes=0, n_tokens=15567, n_stream_chunks=0, n_prompt_tokens=14250, n_completion_tokens=1317, cost=0.30489700000000003), langchain_handler=Tokens Used: 15567\n\tPrompt Tokens: 14250\n\tCompletion Tokens: 1317\nSuccessful Requests: 28\nTotal Cost (USD): $0.30489700000000003, chunks=[]), callback_class=<class 'trulens_eval.feedback.provider.endpoint.openai.OpenAICallback'>, callback_name='callback_openai', pace_thread=<Thread(Thread-7 (keep_pace), started daemon 6424653824)>, client=OpenAIClient(client=<openai.OpenAI object at 0x17db0dd80>, client_cls=openai.OpenAI, client_kwargs={'organization': None, 'base_url': URL('https://api.openai.com/v1/'), 'timeout': Timeout(connect=5.0, read=600.0, write=600.0, pool=600.0), 'max_retries': 2, '_strict_response_validation': False})), model_engine='gpt-3.5-turbo')>, agg=<function mean at 0x108fcc070>, higher_is_better=False), Feedback(tru_class_info=trulens_eval.feedback.feedback.Feedback, implementation=Method(obj=Obj(cls=trulens_eval.feedback.provider.openai.OpenAI, id=6439762288, init_bindings=Bindings(args=(), kwargs={'tru_class_info': {'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': [{'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': None}, {'name': 'LLMProvider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'Provider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'ABC', 'module': {'package_name': '', 'module_name': 'abc'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'endpoint': {'tru_class_info': {'name': 'OpenAIEndpoint', 'module': {'package_name': 'trulens_eval.feedback.provider.endpoint', 'module_name': 'trulens_eval.feedback.provider.endpoint.openai'}, 'bases': [{'name': 'OpenAIEndpoint', 'module': {'package_name': 'trulens_eval.feedback.provider.endpoint', 'module_name': 'trulens_eval.feedback.provider.endpoint.openai'}, 'bases': None}, {'name': 'Endpoint', 'module': {'package_name': 'trulens_eval.feedback.provider.endpoint', 'module_name': 'trulens_eval.feedback.provider.endpoint.base'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'SingletonPerName', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.python'}, 'bases': None}, {'name': 'Generic', 'module': {'package_name': '', 'module_name': 'typing'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'name': 'openai', 'rpm': 60.0, 'retries': 3, 'client': {'client_cls': {'name': 'OpenAI', 'module': {'package_name': 'openai', 'module_name': 'openai'}, 'bases': None}, 'client_kwargs': {'organization': None, 'base_url': 'https://api.openai.com/v1/', 'timeout': {'connect': 5.0, 'read': 600.0, 'write': 600.0, 'pool': 600.0}, 'max_retries': 2, '_strict_response_validation': False}}}, 'model_engine': 'gpt-3.5-turbo'})), name='maliciousness_with_cot_reasons'), aggregator=Function(module=Module(package_name='numpy', module_name='numpy'), cls=None, name='mean'), feedback_definition_id='feedback_definition_hash_51da816108c79685bcb987b6529c8211', selectors={'text': Lens().__record__.main_output}, supplied_name=None, imp=<bound method LLMProvider.maliciousness_with_cot_reasons of OpenAI(tru_class_info=trulens_eval.feedback.provider.openai.OpenAI, endpoint=OpenAIEndpoint(tru_class_info=trulens_eval.feedback.provider.endpoint.openai.OpenAIEndpoint, name='openai', rpm=60.0, retries=3, post_headers={}, pace=<queue.Queue object at 0x17ddbc4c0>, global_callback=OpenAICallback(cost=Cost(n_requests=28, n_successful_requests=28, n_classes=0, n_tokens=15567, n_stream_chunks=0, n_prompt_tokens=14250, n_completion_tokens=1317, cost=0.30489700000000003), langchain_handler=Tokens Used: 15567\n\tPrompt Tokens: 14250\n\tCompletion Tokens: 1317\nSuccessful Requests: 28\nTotal Cost (USD): $0.30489700000000003, chunks=[]), callback_class=<class 'trulens_eval.feedback.provider.endpoint.openai.OpenAICallback'>, callback_name='callback_openai', pace_thread=<Thread(Thread-7 (keep_pace), started daemon 6424653824)>, client=OpenAIClient(client=<openai.OpenAI object at 0x17db0dd80>, client_cls=openai.OpenAI, client_kwargs={'organization': None, 'base_url': URL('https://api.openai.com/v1/'), 'timeout': Timeout(connect=5.0, read=600.0, write=600.0, pool=600.0), 'max_retries': 2, '_strict_response_validation': False})), model_engine='gpt-3.5-turbo')>, agg=<function mean at 0x108fcc070>, higher_is_better=False)], tru=<trulens_eval.tru.Tru object at 0x14e7eb4f0>, db=SqlAlchemyDB(redact_keys=False, engine_params={'url': 'sqlite:///default.sqlite', 'pool_size': 10, 'max_overflow': 2, 'pool_recycle': 300, 'pool_pre_ping': True, 'pool_use_lifo': True}, session_params={}, engine=Engine(sqlite:///default.sqlite), Session=sessionmaker(class_='Session', bind=Engine(sqlite:///default.sqlite), autoflush=True, expire_on_commit=True)), instrument=<trulens_eval.tru_chain.LangChainInstrument object at 0x17db0d690>, recording_contexts=<ContextVar name='recording_contexts' at 0x17fde8950>, instrumented_methods={6440086976: {<function Chain.__call__ at 0x13d8b4af0>: Lens().app, <function BaseRetrievalQA._call at 0x13e85a050>: Lens().app, <function BaseRetrievalQA._acall at 0x13e85a170>: Lens().app, <function Chain.acall at 0x13d8b4b80>: Lens().app, <function Chain._call at 0x13d8b49d0>: Lens().app, <function Chain._acall at 0x13d8b4a60>: Lens().app}, 6439698112: {<function Chain.__call__ at 0x13d8b4af0>: Lens().app.combine_documents_chain, <function BaseCombineDocumentsChain._call at 0x13d972050>: Lens().app.combine_documents_chain, <function BaseCombineDocumentsChain._acall at 0x13d9720e0>: Lens().app.combine_documents_chain, <function Chain.acall at 0x13d8b4b80>: Lens().app.combine_documents_chain, <function Chain._call at 0x13d8b49d0>: Lens().app.combine_documents_chain, <function Chain._acall at 0x13d8b4a60>: Lens().app.combine_documents_chain}, 6439980480: {<function Chain.__call__ at 0x13d8b4af0>: Lens().app.combine_documents_chain.llm_chain, <function LLMChain._call at 0x13d8e8550>: Lens().app.combine_documents_chain.llm_chain, <function LLMChain._acall at 0x13d8e8a60>: Lens().app.combine_documents_chain.llm_chain, <function Chain.acall at 0x13d8b4b80>: Lens().app.combine_documents_chain.llm_chain, <function Chain._call at 0x13d8b49d0>: Lens().app.combine_documents_chain.llm_chain, <function Chain._acall at 0x13d8b4a60>: Lens().app.combine_documents_chain.llm_chain}})"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_recorder\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'streamlit'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[75], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtru\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_dashboard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/tru.py:576\u001B[0m, in \u001B[0;36mTru.run_dashboard\u001B[0;34m(self, port, address, force, _dev)\u001B[0m\n\u001B[1;32m    568\u001B[0m     args\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--server.address=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maddress\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    570\u001B[0m args \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    571\u001B[0m     leaderboard_path, \n\u001B[1;32m    572\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--database-url\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    573\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdb\u001B[38;5;241m.\u001B[39mengine\u001B[38;5;241m.\u001B[39murl\u001B[38;5;241m.\u001B[39mrender_as_string(hide_password\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    574\u001B[0m ]\n\u001B[0;32m--> 576\u001B[0m proc \u001B[38;5;241m=\u001B[39m \u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    577\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    578\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstdout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPIPE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    579\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstderr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPIPE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    580\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    581\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43menv_opts\u001B[49m\n\u001B[1;32m    582\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    584\u001B[0m started \u001B[38;5;241m=\u001B[39m threading\u001B[38;5;241m.\u001B[39mEvent()\n\u001B[1;32m    585\u001B[0m tunnel_started \u001B[38;5;241m=\u001B[39m threading\u001B[38;5;241m.\u001B[39mEvent()\n",
      "File \u001B[0;32m~/miniforge3/envs/aienv/lib/python3.10/subprocess.py:971\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001B[0m\n\u001B[1;32m    967\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtext_mode:\n\u001B[1;32m    968\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mTextIOWrapper(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr,\n\u001B[1;32m    969\u001B[0m                     encoding\u001B[38;5;241m=\u001B[39mencoding, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[0;32m--> 971\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexecutable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreexec_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclose_fds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    972\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mpass_fds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcwd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    973\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mstartupinfo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreationflags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshell\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    974\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mp2cread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp2cwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    975\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mc2pread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc2pwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    976\u001B[0m \u001B[43m                        \u001B[49m\u001B[43merrread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    977\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mrestore_signals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    978\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mgid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mumask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    979\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mstart_new_session\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    980\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m    981\u001B[0m     \u001B[38;5;66;03m# Cleanup if the child failed starting.\u001B[39;00m\n\u001B[1;32m    982\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mfilter\u001B[39m(\u001B[38;5;28;01mNone\u001B[39;00m, (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstdin, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstdout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr)):\n",
      "File \u001B[0;32m~/miniforge3/envs/aienv/lib/python3.10/subprocess.py:1863\u001B[0m, in \u001B[0;36mPopen._execute_child\u001B[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001B[0m\n\u001B[1;32m   1861\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errno_num \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1862\u001B[0m         err_msg \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mstrerror(errno_num)\n\u001B[0;32m-> 1863\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001B[1;32m   1864\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m child_exception_type(err_msg)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'streamlit'"
     ]
    }
   ],
   "source": [
    "tru.run_dashboard()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In agreement_measure, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In agreement_measure, input response will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "golden_set = [\n",
    "    #1\n",
    "    {\"query\": \"Vorrei prenotare un alloggio a tariffa intera per l'a.a. 2023-24. Come posso procedere?\",\n",
    "     \"response\": \"Se sei uno studente iscritto e sei interessato all'assegnazione di un alloggio a tariffa intera per l'a.a. 2023-24, potrai partecipare alle diverse sessioni di Open reservation mensili che verranno messe a disposizione degli studenti: le prime sessioni si svolgeranno a partire da metà settembre 2023.\"},\n",
    "    #2\n",
    "    {\"query\": \"Come funziona per prenotare un alloggio a tariffa intera per l'A.A. 2023/2024? \",\n",
    "     \"response\": \"Se sei uno studente iscritto e sei interessato all'assegnazione di un alloggio a tariffa intera per l'a.a. 2023-24, potrai partecipare alle diverse sessioni di Open reservation mensili che verranno messe a disposizione degli studenti: le prime sessioni si svolgeranno a partire da metà settembre 2023.\"}]\n",
    "\n",
    "ground_truth_collection = GroundTruthAgreement(golden_set)\n",
    "\n",
    "feedback = Feedback(ground_truth_collection.agreement_measure).on_input_output()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "Feedback(tru_class_info=trulens_eval.feedback.feedback.Feedback, implementation=Method(obj=Obj(cls=trulens_eval.feedback.groundtruth.GroundTruthAgreement, id=6433751744, init_bindings=Bindings(args=(), kwargs={'tru_class_info': {'name': 'GroundTruthAgreement', 'module': {'package_name': 'trulens_eval.feedback', 'module_name': 'trulens_eval.feedback.groundtruth'}, 'bases': [{'name': 'GroundTruthAgreement', 'module': {'package_name': 'trulens_eval.feedback', 'module_name': 'trulens_eval.feedback.groundtruth'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'ground_truth': [{'query': \"Vorrei prenotare un alloggio a tariffa intera per l'a.a. 2023-24. Come posso procedere?\", 'response': \"Se sei uno studente iscritto e sei interessato all'assegnazione di un alloggio a tariffa intera per l'a.a. 2023-24, potrai partecipare alle diverse sessioni di Open reservation mensili che verranno messe a disposizione degli studenti: le prime sessioni si svolgeranno a partire da metà settembre 2023.\"}, {'query': \"Come funziona per prenotare un alloggio a tariffa intera per l'A.A. 2023/2024? \", 'response': \"Se sei uno studente iscritto e sei interessato all'assegnazione di un alloggio a tariffa intera per l'a.a. 2023-24, potrai partecipare alle diverse sessioni di Open reservation mensili che verranno messe a disposizione degli studenti: le prime sessioni si svolgeranno a partire da metà settembre 2023.\"}], 'provider': {'tru_class_info': {'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': [{'name': 'OpenAI', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.openai'}, 'bases': None}, {'name': 'LLMProvider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'Provider', 'module': {'package_name': 'trulens_eval.feedback.provider', 'module_name': 'trulens_eval.feedback.provider.base'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'ABC', 'module': {'package_name': '', 'module_name': 'abc'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'endpoint': {'tru_class_info': {'name': 'OpenAIEndpoint', 'module': {'package_name': 'trulens_eval.feedback.provider.endpoint', 'module_name': 'trulens_eval.feedback.provider.endpoint.openai'}, 'bases': [{'name': 'OpenAIEndpoint', 'module': {'package_name': 'trulens_eval.feedback.provider.endpoint', 'module_name': 'trulens_eval.feedback.provider.endpoint.openai'}, 'bases': None}, {'name': 'Endpoint', 'module': {'package_name': 'trulens_eval.feedback.provider.endpoint', 'module_name': 'trulens_eval.feedback.provider.endpoint.base'}, 'bases': None}, {'name': 'SerialModel', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.serial'}, 'bases': None}, {'name': 'WithClassInfo', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.pyschema'}, 'bases': None}, {'name': 'BaseModel', 'module': {'package_name': 'pydantic', 'module_name': 'pydantic.main'}, 'bases': None}, {'name': 'SingletonPerName', 'module': {'package_name': 'trulens_eval.utils', 'module_name': 'trulens_eval.utils.python'}, 'bases': None}, {'name': 'Generic', 'module': {'package_name': '', 'module_name': 'typing'}, 'bases': None}, {'name': 'object', 'module': {'package_name': '', 'module_name': 'builtins'}, 'bases': None}]}, 'name': 'openai', 'rpm': 60.0, 'retries': 3, 'client': {'client_cls': {'name': 'OpenAI', 'module': {'package_name': 'openai', 'module_name': 'openai'}, 'bases': None}, 'client_kwargs': {'organization': None, 'base_url': 'https://api.openai.com/v1/', 'timeout': {'connect': 5.0, 'read': 600.0, 'write': 600.0, 'pool': 600.0}, 'max_retries': 2, '_strict_response_validation': False}}}, 'model_engine': 'gpt-3.5-turbo'}, 'bert_scorer': None})), name='agreement_measure'), aggregator=Function(module=Module(package_name='numpy', module_name='numpy'), cls=None, name='mean'), feedback_definition_id='feedback_definition_hash_692b3029efec450eff757689ce744017', selectors={'prompt': Lens().__record__.main_input, 'response': Lens().__record__.main_output}, supplied_name=None, imp=<bound method GroundTruthAgreement.agreement_measure of GroundTruthAgreement(tru_class_info=trulens_eval.feedback.groundtruth.GroundTruthAgreement, ground_truth=[{'query': \"Vorrei prenotare un alloggio a tariffa intera per l'a.a. 2023-24. Come posso procedere?\", 'response': \"Se sei uno studente iscritto e sei interessato all'assegnazione di un alloggio a tariffa intera per l'a.a. 2023-24, potrai partecipare alle diverse sessioni di Open reservation mensili che verranno messe a disposizione degli studenti: le prime sessioni si svolgeranno a partire da metà settembre 2023.\"}, {'query': \"Come funziona per prenotare un alloggio a tariffa intera per l'A.A. 2023/2024? \", 'response': \"Se sei uno studente iscritto e sei interessato all'assegnazione di un alloggio a tariffa intera per l'a.a. 2023-24, potrai partecipare alle diverse sessioni di Open reservation mensili che verranno messe a disposizione degli studenti: le prime sessioni si svolgeranno a partire da metà settembre 2023.\"}], provider=OpenAI(tru_class_info=trulens_eval.feedback.provider.openai.OpenAI, endpoint=OpenAIEndpoint(tru_class_info=trulens_eval.feedback.provider.endpoint.openai.OpenAIEndpoint, name='openai', rpm=60.0, retries=3, post_headers={}, pace=<queue.Queue object at 0x17ddbc4c0>, global_callback=OpenAICallback(cost=Cost(n_requests=28, n_successful_requests=28, n_classes=0, n_tokens=15567, n_stream_chunks=0, n_prompt_tokens=14250, n_completion_tokens=1317, cost=0.30489700000000003), langchain_handler=Tokens Used: 15567\n\tPrompt Tokens: 14250\n\tCompletion Tokens: 1317\nSuccessful Requests: 28\nTotal Cost (USD): $0.30489700000000003, chunks=[]), callback_class=<class 'trulens_eval.feedback.provider.endpoint.openai.OpenAICallback'>, callback_name='callback_openai', pace_thread=<Thread(Thread-7 (keep_pace), started daemon 6424653824)>, client=OpenAIClient(client=<openai.OpenAI object at 0x17db0dd80>, client_cls=openai.OpenAI, client_kwargs={'organization': None, 'base_url': URL('https://api.openai.com/v1/'), 'timeout': Timeout(connect=5.0, read=600.0, write=600.0, pool=600.0), 'max_retries': 2, '_strict_response_validation': False})), model_engine='gpt-3.5-turbo'), bert_scorer=None, ground_truth_imp=None)>, agg=<function mean at 0x108fcc070>, higher_is_better=True)"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Trial 3 - Using the videotutorial to set up properly\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OpenAI' object has no attribute 'relevance'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 29\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtrulens_eval\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapp\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m App\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m#context = App.select_context(qa_chain_self)\u001B[39;00m\n\u001B[1;32m     25\u001B[0m \n\u001B[1;32m     26\u001B[0m \n\u001B[1;32m     27\u001B[0m \n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m# Question/answer relevance between overall question and answer.\u001B[39;00m\n\u001B[0;32m---> 29\u001B[0m f_qa_relevance \u001B[38;5;241m=\u001B[39m Feedback(\u001B[43mOpenAI\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrelevance\u001B[49m)\u001B[38;5;241m.\u001B[39mon_input_output()\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'OpenAI' object has no attribute 'relevance'"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Tru,TruChain,FeedbackMode,Feedback\n",
    "from llama_index.llms import OpenAI\n",
    "from trulens_eval import OpenAI as fOpenAI\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "from trulens_eval.feedback import Groundedness\n",
    "tru = Tru()\n",
    "tru.reset_database()\n",
    "\n",
    "\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "#FEEDBACK FUNCITONS\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "provider = fOpenAI()\n",
    "\n",
    "from trulens_eval.feedback import Groundedness\n",
    "grounded = Groundedness(groundedness_provider = provider)\n",
    "\n",
    "from trulens_eval.app import App\n",
    "#context = App.select_context(qa_chain_self)\n",
    "\n",
    "\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = Feedback(OpenAI().relevance).on_input_output()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons)\n",
    "    .on(context.collect()) # collect context chunks into a list\n",
    "    .on_output()\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(openai.qs_relevance)\n",
    "    .on_input()\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation of RAG applications\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for LLMChain\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[103], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m qa_chain_self \u001B[38;5;241m=\u001B[39m \u001B[43mRetrievalQA\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_chain_type\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mllm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretriever\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mself_retriever\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/aienv/lib/python3.10/site-packages/langchain/chains/retrieval_qa/base.py:100\u001B[0m, in \u001B[0;36mBaseRetrievalQA.from_chain_type\u001B[0;34m(cls, llm, chain_type, chain_type_kwargs, **kwargs)\u001B[0m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Load chain from chain type.\"\"\"\u001B[39;00m\n\u001B[1;32m     99\u001B[0m _chain_type_kwargs \u001B[38;5;241m=\u001B[39m chain_type_kwargs \u001B[38;5;129;01mor\u001B[39;00m {}\n\u001B[0;32m--> 100\u001B[0m combine_documents_chain \u001B[38;5;241m=\u001B[39m \u001B[43mload_qa_chain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    101\u001B[0m \u001B[43m    \u001B[49m\u001B[43mllm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchain_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchain_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_chain_type_kwargs\u001B[49m\n\u001B[1;32m    102\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(combine_documents_chain\u001B[38;5;241m=\u001B[39mcombine_documents_chain, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniforge3/envs/aienv/lib/python3.10/site-packages/langchain/chains/question_answering/__init__.py:249\u001B[0m, in \u001B[0;36mload_qa_chain\u001B[0;34m(llm, chain_type, verbose, callback_manager, **kwargs)\u001B[0m\n\u001B[1;32m    244\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chain_type \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m loader_mapping:\n\u001B[1;32m    245\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    246\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGot unsupported chain type: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mchain_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    247\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloader_mapping\u001B[38;5;241m.\u001B[39mkeys()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    248\u001B[0m     )\n\u001B[0;32m--> 249\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mloader_mapping\u001B[49m\u001B[43m[\u001B[49m\u001B[43mchain_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    250\u001B[0m \u001B[43m    \u001B[49m\u001B[43mllm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    251\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/aienv/lib/python3.10/site-packages/langchain/chains/question_answering/__init__.py:73\u001B[0m, in \u001B[0;36m_load_stuff_chain\u001B[0;34m(llm, prompt, document_variable_name, verbose, callback_manager, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_load_stuff_chain\u001B[39m(\n\u001B[1;32m     64\u001B[0m     llm: BaseLanguageModel,\n\u001B[1;32m     65\u001B[0m     prompt: Optional[BasePromptTemplate] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     70\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m     71\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m StuffDocumentsChain:\n\u001B[1;32m     72\u001B[0m     _prompt \u001B[38;5;241m=\u001B[39m prompt \u001B[38;5;129;01mor\u001B[39;00m stuff_prompt\u001B[38;5;241m.\u001B[39mPROMPT_SELECTOR\u001B[38;5;241m.\u001B[39mget_prompt(llm)\n\u001B[0;32m---> 73\u001B[0m     llm_chain \u001B[38;5;241m=\u001B[39m \u001B[43mLLMChain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m        \u001B[49m\u001B[43mllm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mllm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_prompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     76\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallback_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     78\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     79\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     80\u001B[0m     \u001B[38;5;66;03m# TODO: document prompt\u001B[39;00m\n\u001B[1;32m     81\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m StuffDocumentsChain(\n\u001B[1;32m     82\u001B[0m         llm_chain\u001B[38;5;241m=\u001B[39mllm_chain,\n\u001B[1;32m     83\u001B[0m         document_variable_name\u001B[38;5;241m=\u001B[39mdocument_variable_name,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     87\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m     88\u001B[0m     )\n",
      "File \u001B[0;32m~/miniforge3/envs/aienv/lib/python3.10/site-packages/langchain/load/serializable.py:97\u001B[0m, in \u001B[0;36mSerializable.__init__\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 97\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lc_kwargs \u001B[38;5;241m=\u001B[39m kwargs\n",
      "File \u001B[0;32m~/miniforge3/envs/aienv/lib/python3.10/site-packages/pydantic/v1/main.py:341\u001B[0m, in \u001B[0;36mBaseModel.__init__\u001B[0;34m(__pydantic_self__, **data)\u001B[0m\n\u001B[1;32m    339\u001B[0m values, fields_set, validation_error \u001B[38;5;241m=\u001B[39m validate_model(__pydantic_self__\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m, data)\n\u001B[1;32m    340\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m validation_error:\n\u001B[0;32m--> 341\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m validation_error\n\u001B[1;32m    342\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    343\u001B[0m     object_setattr(__pydantic_self__, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__dict__\u001B[39m\u001B[38;5;124m'\u001B[39m, values)\n",
      "\u001B[0;31mValidationError\u001B[0m: 2 validation errors for LLMChain\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)"
     ]
    }
   ],
   "source": [
    "qa_chain_self = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_retriever\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f_groundedness' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m tru_recorder \u001B[38;5;241m=\u001B[39m TruChain(\n\u001B[1;32m      2\u001B[0m     qa_chain_self,\n\u001B[1;32m      3\u001B[0m     app_id\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mApp_1\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      4\u001B[0m     feedbacks\u001B[38;5;241m=\u001B[39m[\n\u001B[1;32m      5\u001B[0m         f_qa_relevance,\n\u001B[0;32m----> 6\u001B[0m         \u001B[43mf_groundedness\u001B[49m\n\u001B[1;32m      7\u001B[0m     ]\n\u001B[1;32m      8\u001B[0m )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'f_groundedness' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tru_recorder = TruChain(\n",
    "    qa_chain_self,\n",
    "    app_id=\"App_1\",\n",
    "    feedbacks=[\n",
    "        f_qa_relevance,\n",
    "        f_groundedness\n",
    "    ]\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('eval_questions_27dic.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        eval_questions.append(item)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "[\"Vorrei prenotare un alloggio a tariffa intera per l'a.a. 2023-24. Come posso procedere?\",\n \"Come funziona per prenotare un alloggio a tariffa intera per l'A.A. 2023/2024?\",\n \"quali sono le dotazioni disponibili all'interno delle camere?\",\n 'Cosa dovrei aspettare di trovare in una camera in una residenza bocconi?',\n 'Chi sono i rappresentati di residenza nella residenza Bligny?\"',\n 'Sarei interassto a ricoprire il ruolo di rappresentante di residenza, cosa dovrei fare?',\n 'Sono interessato a diventare rappresentante di residenza, entro quando dovro effettuare la presentazione della candidatura individuale?',\n \"Come posso confermare il mio alloggio per l'anno accademico 2023-24?\",\n 'Quali sono i requisiti per la presentazione della domanda di conferma alloggio?']"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_questions\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run of <lambda> in <Thread(TP.submit with debug timeout_1, started 10877956096)> failed with: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "exception calling callback for <Future at 0x17db0e710 state=finished raised RuntimeError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 689, in extract_selection\n",
      "    arg_vals[k] = list(q_within_o.get(o))\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 904, in get\n",
      "    for last_selection in last_step.get(start_selection):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 362, in get\n",
      "    raise KeyError(\n",
      "KeyError: 'Key not in dictionary: query'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 342, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/app.py\", line 946, in _add_future_feedback\n",
      "    _, res = future.result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/python.py\", line 228, in _future_target_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 117, in _run_with_timeout\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 102, in _run_with_timeout\n",
      "    res: T = fut.result(timeout=timeout)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/tru.py\", line 221, in <lambda>\n",
      "    tp.submit(lambda f: (f, f.run(app=app, record=record)), ffunc)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 492, in run\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 487, in run\n",
      "    input_combinations = list(\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 691, in extract_selection\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "Run of <lambda> in <Thread(TP.submit with debug timeout_1, started 10877956096)> failed with: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "exception calling callback for <Future at 0x17db0ea10 state=finished raised RuntimeError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 689, in extract_selection\n",
      "    arg_vals[k] = list(q_within_o.get(o))\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 904, in get\n",
      "    for last_selection in last_step.get(start_selection):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 362, in get\n",
      "    raise KeyError(\n",
      "KeyError: 'Key not in dictionary: query'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 342, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/app.py\", line 946, in _add_future_feedback\n",
      "    _, res = future.result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/python.py\", line 228, in _future_target_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 117, in _run_with_timeout\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 102, in _run_with_timeout\n",
      "    res: T = fut.result(timeout=timeout)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/tru.py\", line 221, in <lambda>\n",
      "    tp.submit(lambda f: (f, f.run(app=app, record=record)), ffunc)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 492, in run\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 487, in run\n",
      "    input_combinations = list(\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 691, in extract_selection\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run of <lambda> in <Thread(TP.submit with debug timeout_0, started 10804703232)> failed with: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "exception calling callback for <Future at 0x289a14160 state=finished raised RuntimeError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 689, in extract_selection\n",
      "    arg_vals[k] = list(q_within_o.get(o))\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 904, in get\n",
      "    for last_selection in last_step.get(start_selection):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 362, in get\n",
      "    raise KeyError(\n",
      "KeyError: 'Key not in dictionary: query'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 342, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/app.py\", line 946, in _add_future_feedback\n",
      "    _, res = future.result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/python.py\", line 228, in _future_target_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 117, in _run_with_timeout\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 102, in _run_with_timeout\n",
      "    res: T = fut.result(timeout=timeout)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/tru.py\", line 221, in <lambda>\n",
      "    tp.submit(lambda f: (f, f.run(app=app, record=record)), ffunc)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 492, in run\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 487, in run\n",
      "    input_combinations = list(\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 691, in extract_selection\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "Run of <lambda> in <Thread(TP.submit with debug timeout_0, started 10804703232)> failed with: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "exception calling callback for <Future at 0x289a151e0 state=finished raised RuntimeError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 689, in extract_selection\n",
      "    arg_vals[k] = list(q_within_o.get(o))\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 904, in get\n",
      "    for last_selection in last_step.get(start_selection):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 362, in get\n",
      "    raise KeyError(\n",
      "KeyError: 'Key not in dictionary: query'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 342, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/app.py\", line 946, in _add_future_feedback\n",
      "    _, res = future.result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/python.py\", line 228, in _future_target_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 117, in _run_with_timeout\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 102, in _run_with_timeout\n",
      "    res: T = fut.result(timeout=timeout)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/tru.py\", line 221, in <lambda>\n",
      "    tp.submit(lambda f: (f, f.run(app=app, record=record)), ffunc)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 492, in run\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 487, in run\n",
      "    input_combinations = list(\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 691, in extract_selection\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run of <lambda> in <Thread(TP.submit with debug timeout_2, started 10916753408)> failed with: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "exception calling callback for <Future at 0x28717e140 state=finished raised RuntimeError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 689, in extract_selection\n",
      "    arg_vals[k] = list(q_within_o.get(o))\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 904, in get\n",
      "    for last_selection in last_step.get(start_selection):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 362, in get\n",
      "    raise KeyError(\n",
      "KeyError: 'Key not in dictionary: query'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 342, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/app.py\", line 946, in _add_future_feedback\n",
      "    _, res = future.result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/python.py\", line 228, in _future_target_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 117, in _run_with_timeout\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 102, in _run_with_timeout\n",
      "    res: T = fut.result(timeout=timeout)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/tru.py\", line 221, in <lambda>\n",
      "    tp.submit(lambda f: (f, f.run(app=app, record=record)), ffunc)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 492, in run\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 487, in run\n",
      "    input_combinations = list(\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 691, in extract_selection\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "Run of <lambda> in <Thread(TP.submit with debug timeout_2, started 10916753408)> failed with: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "exception calling callback for <Future at 0x28717ec80 state=finished raised RuntimeError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 689, in extract_selection\n",
      "    arg_vals[k] = list(q_within_o.get(o))\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 904, in get\n",
      "    for last_selection in last_step.get(start_selection):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 362, in get\n",
      "    raise KeyError(\n",
      "KeyError: 'Key not in dictionary: query'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 342, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/app.py\", line 946, in _add_future_feedback\n",
      "    _, res = future.result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/python.py\", line 228, in _future_target_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 117, in _run_with_timeout\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 102, in _run_with_timeout\n",
      "    res: T = fut.result(timeout=timeout)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/tru.py\", line 221, in <lambda>\n",
      "    tp.submit(lambda f: (f, f.run(app=app, record=record)), ffunc)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 492, in run\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 487, in run\n",
      "    input_combinations = list(\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 691, in extract_selection\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run of <lambda> in <Thread(TP.submit with debug timeout_0, started 10804703232)> failed with: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "exception calling callback for <Future at 0x28717f250 state=finished raised RuntimeError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 689, in extract_selection\n",
      "    arg_vals[k] = list(q_within_o.get(o))\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 904, in get\n",
      "    for last_selection in last_step.get(start_selection):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 362, in get\n",
      "    raise KeyError(\n",
      "KeyError: 'Key not in dictionary: query'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 342, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/app.py\", line 946, in _add_future_feedback\n",
      "    _, res = future.result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/python.py\", line 228, in _future_target_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 117, in _run_with_timeout\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 102, in _run_with_timeout\n",
      "    res: T = fut.result(timeout=timeout)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/tru.py\", line 221, in <lambda>\n",
      "    tp.submit(lambda f: (f, f.run(app=app, record=record)), ffunc)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 492, in run\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 487, in run\n",
      "    input_combinations = list(\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 691, in extract_selection\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "Run of <lambda> in <Thread(TP.submit with debug timeout_1, started 10877956096)> failed with: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "exception calling callback for <Future at 0x28717d5a0 state=finished raised RuntimeError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 689, in extract_selection\n",
      "    arg_vals[k] = list(q_within_o.get(o))\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 904, in get\n",
      "    for last_selection in last_step.get(start_selection):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 362, in get\n",
      "    raise KeyError(\n",
      "KeyError: 'Key not in dictionary: query'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 342, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/app.py\", line 946, in _add_future_feedback\n",
      "    _, res = future.result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/python.py\", line 228, in _future_target_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 117, in _run_with_timeout\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 102, in _run_with_timeout\n",
      "    res: T = fut.result(timeout=timeout)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/tru.py\", line 221, in <lambda>\n",
      "    tp.submit(lambda f: (f, f.run(app=app, record=record)), ffunc)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 492, in run\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 487, in run\n",
      "    input_combinations = list(\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 691, in extract_selection\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run of <lambda> in <Thread(TP.submit with debug timeout_2, started 10916753408)> failed with: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "exception calling callback for <Future at 0x289a5dcf0 state=finished raised RuntimeError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 689, in extract_selection\n",
      "    arg_vals[k] = list(q_within_o.get(o))\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 904, in get\n",
      "    for last_selection in last_step.get(start_selection):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 362, in get\n",
      "    raise KeyError(\n",
      "KeyError: 'Key not in dictionary: query'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 342, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/app.py\", line 946, in _add_future_feedback\n",
      "    _, res = future.result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/python.py\", line 228, in _future_target_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 117, in _run_with_timeout\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 102, in _run_with_timeout\n",
      "    res: T = fut.result(timeout=timeout)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/tru.py\", line 221, in <lambda>\n",
      "    tp.submit(lambda f: (f, f.run(app=app, record=record)), ffunc)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 492, in run\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 487, in run\n",
      "    input_combinations = list(\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 691, in extract_selection\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "Run of <lambda> in <Thread(TP.submit with debug timeout_1, started 10877956096)> failed with: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "exception calling callback for <Future at 0x28717cf70 state=finished raised RuntimeError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 689, in extract_selection\n",
      "    arg_vals[k] = list(q_within_o.get(o))\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 904, in get\n",
      "    for last_selection in last_step.get(start_selection):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 362, in get\n",
      "    raise KeyError(\n",
      "KeyError: 'Key not in dictionary: query'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 342, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/app.py\", line 946, in _add_future_feedback\n",
      "    _, res = future.result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/python.py\", line 228, in _future_target_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 117, in _run_with_timeout\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 102, in _run_with_timeout\n",
      "    res: T = fut.result(timeout=timeout)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/tru.py\", line 221, in <lambda>\n",
      "    tp.submit(lambda f: (f, f.run(app=app, record=record)), ffunc)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 492, in run\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 487, in run\n",
      "    input_combinations = list(\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 691, in extract_selection\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run of <lambda> in <Thread(TP.submit with debug timeout_0, started 10804703232)> failed with: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "exception calling callback for <Future at 0x289ac4520 state=finished raised RuntimeError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 689, in extract_selection\n",
      "    arg_vals[k] = list(q_within_o.get(o))\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 904, in get\n",
      "    for last_selection in last_step.get(start_selection):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 362, in get\n",
      "    raise KeyError(\n",
      "KeyError: 'Key not in dictionary: query'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 342, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/app.py\", line 946, in _add_future_feedback\n",
      "    _, res = future.result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/python.py\", line 228, in _future_target_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 117, in _run_with_timeout\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 102, in _run_with_timeout\n",
      "    res: T = fut.result(timeout=timeout)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/tru.py\", line 221, in <lambda>\n",
      "    tp.submit(lambda f: (f, f.run(app=app, record=record)), ffunc)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 492, in run\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 487, in run\n",
      "    input_combinations = list(\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 691, in extract_selection\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "Run of <lambda> in <Thread(TP.submit with debug timeout_1, started 10877956096)> failed with: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "exception calling callback for <Future at 0x289ae8bb0 state=finished raised RuntimeError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 689, in extract_selection\n",
      "    arg_vals[k] = list(q_within_o.get(o))\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 904, in get\n",
      "    for last_selection in last_step.get(start_selection):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 362, in get\n",
      "    raise KeyError(\n",
      "KeyError: 'Key not in dictionary: query'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 342, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/app.py\", line 946, in _add_future_feedback\n",
      "    _, res = future.result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/python.py\", line 228, in _future_target_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 117, in _run_with_timeout\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 102, in _run_with_timeout\n",
      "    res: T = fut.result(timeout=timeout)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/tru.py\", line 221, in <lambda>\n",
      "    tp.submit(lambda f: (f, f.run(app=app, record=record)), ffunc)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 492, in run\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 487, in run\n",
      "    input_combinations = list(\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 691, in extract_selection\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run of <lambda> in <Thread(TP.submit with debug timeout_2, started 10916753408)> failed with: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "exception calling callback for <Future at 0x28bc56aa0 state=finished raised RuntimeError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 689, in extract_selection\n",
      "    arg_vals[k] = list(q_within_o.get(o))\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 904, in get\n",
      "    for last_selection in last_step.get(start_selection):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 362, in get\n",
      "    raise KeyError(\n",
      "KeyError: 'Key not in dictionary: query'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 342, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/app.py\", line 946, in _add_future_feedback\n",
      "    _, res = future.result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/python.py\", line 228, in _future_target_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 117, in _run_with_timeout\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 102, in _run_with_timeout\n",
      "    res: T = fut.result(timeout=timeout)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/tru.py\", line 221, in <lambda>\n",
      "    tp.submit(lambda f: (f, f.run(app=app, record=record)), ffunc)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 492, in run\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 487, in run\n",
      "    input_combinations = list(\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 691, in extract_selection\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "Run of <lambda> in <Thread(TP.submit with debug timeout_1, started 10877956096)> failed with: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "exception calling callback for <Future at 0x28bca7b20 state=finished raised RuntimeError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 689, in extract_selection\n",
      "    arg_vals[k] = list(q_within_o.get(o))\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 904, in get\n",
      "    for last_selection in last_step.get(start_selection):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 362, in get\n",
      "    raise KeyError(\n",
      "KeyError: 'Key not in dictionary: query'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 342, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/app.py\", line 946, in _add_future_feedback\n",
      "    _, res = future.result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/python.py\", line 228, in _future_target_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 117, in _run_with_timeout\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 102, in _run_with_timeout\n",
      "    res: T = fut.result(timeout=timeout)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/tru.py\", line 221, in <lambda>\n",
      "    tp.submit(lambda f: (f, f.run(app=app, record=record)), ffunc)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 492, in run\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 487, in run\n",
      "    input_combinations = list(\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 691, in extract_selection\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run of <lambda> in <Thread(TP.submit with debug timeout_0, started 10804703232)> failed with: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "exception calling callback for <Future at 0x28718f190 state=finished raised RuntimeError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 689, in extract_selection\n",
      "    arg_vals[k] = list(q_within_o.get(o))\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 904, in get\n",
      "    for last_selection in last_step.get(start_selection):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 362, in get\n",
      "    raise KeyError(\n",
      "KeyError: 'Key not in dictionary: query'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 342, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/app.py\", line 946, in _add_future_feedback\n",
      "    _, res = future.result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/python.py\", line 228, in _future_target_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 117, in _run_with_timeout\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 102, in _run_with_timeout\n",
      "    res: T = fut.result(timeout=timeout)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/tru.py\", line 221, in <lambda>\n",
      "    tp.submit(lambda f: (f, f.run(app=app, record=record)), ffunc)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 492, in run\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 487, in run\n",
      "    input_combinations = list(\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 691, in extract_selection\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "Run of <lambda> in <Thread(TP.submit with debug timeout_1, started 10877956096)> failed with: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "exception calling callback for <Future at 0x28718d2d0 state=finished raised RuntimeError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 689, in extract_selection\n",
      "    arg_vals[k] = list(q_within_o.get(o))\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 904, in get\n",
      "    for last_selection in last_step.get(start_selection):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 362, in get\n",
      "    raise KeyError(\n",
      "KeyError: 'Key not in dictionary: query'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 342, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/app.py\", line 946, in _add_future_feedback\n",
      "    _, res = future.result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/python.py\", line 228, in _future_target_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 117, in _run_with_timeout\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 102, in _run_with_timeout\n",
      "    res: T = fut.result(timeout=timeout)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/tru.py\", line 221, in <lambda>\n",
      "    tp.submit(lambda f: (f, f.run(app=app, record=record)), ffunc)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 492, in run\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 487, in run\n",
      "    input_combinations = list(\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 691, in extract_selection\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run of <lambda> in <Thread(TP.submit with debug timeout_2, started 10916753408)> failed with: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n",
      "exception calling callback for <Future at 0x28712d630 state=finished raised RuntimeError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 689, in extract_selection\n",
      "    arg_vals[k] = list(q_within_o.get(o))\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 903, in get\n",
      "    for start_selection in start_items:\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 904, in get\n",
      "    for last_selection in last_step.get(start_selection):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/serial.py\", line 362, in get\n",
      "    raise KeyError(\n",
      "KeyError: 'Key not in dictionary: query'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 342, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/app.py\", line 946, in _add_future_feedback\n",
      "    _, res = future.result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/python.py\", line 228, in _future_target_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 117, in _run_with_timeout\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/utils/threading.py\", line 102, in _run_with_timeout\n",
      "    res: T = fut.result(timeout=timeout)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/tru.py\", line 221, in <lambda>\n",
      "    tp.submit(lambda f: (f, f.run(app=app, record=record)), ffunc)\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 492, in run\n",
      "    raise e\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 487, in run\n",
      "    input_combinations = list(\n",
      "  File \"/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/trulens_eval/feedback/feedback.py\", line 691, in extract_selection\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run of <lambda> in <Thread(TP.submit with debug timeout_1, started 10877956096)> failed with: Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not locate app.query.rets.source_nodes[:].node.text in app/record.\n"
     ]
    }
   ],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder as recording:\n",
    "        recording.record_metadata=\"this is metadata for all records in this context that follow this line\"\n",
    "        qa_chain_self({\"query\": question})\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "aienv",
   "language": "python",
   "display_name": "aienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}