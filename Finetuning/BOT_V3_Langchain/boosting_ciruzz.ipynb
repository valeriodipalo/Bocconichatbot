{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### SET UP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__a7cd2e593e7248e594ac5b698bae1f7c\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] =\"Bocconi-chat\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ciruzz v0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current Residence representatives, in charge until September 2024, are as follows:\n",
      "BLIGNY - Benedetta Scarcelli, Paolo Versini\n",
      "BOCCONI - Alessandro Pacitto, Gabriele Stella\n",
      "CASTIGLIONI - Giuseppe Greco, Ernesto Nocerino\n",
      "DUBINI - Francesco Salvatore Panarisi, Giulio Vitale\n",
      "ISONZO - Giuseppe Savona, Martina Violi\n",
      "JAVOTTE - Giorgio Armillis, Michele Lo Buono\n",
      "SPADOLINI - Michele Baretta, Mariano Benedetto\n",
      "\n",
      "If you need any further information, don't hesitate to ask!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path_full_p = \"S3_files/Full_plain.md\"\n",
    "headers_to_split_on_plain = [\n",
    "    (\"#\", \"Category\"),\n",
    "    (\"##\", \"Subcategory\"),\n",
    "    (\"###\", \"Question\"),\n",
    "    (\"####\", \"URL\"),\n",
    "    (\"#####\", \"ID\"),\n",
    "]\n",
    "\n",
    "\n",
    "with open(path_full_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "\n",
    "embedding=OpenAIEmbeddings() #\n",
    "\n",
    "llm_name = \"gpt-3.5-turbo\" #\n",
    "llm = ChatOpenAI(model_name=llm_name, temperature=0) #\n",
    "\n",
    "#vs_full_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings(),persist_directory=\"./chroma_db\" )\n",
    "db3 = Chroma(embedding_function=embedding, persist_directory=\"S3_files/chroma_db\")\n",
    "\n",
    "#ret_full_plain = vs_full_plain.as_retriever()\n",
    "ret_full_plain = db3.as_retriever()\n",
    "\n",
    "\n",
    "template0 = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "If you the question is too broad and could lead to multiple answers ask the user for clarifications.\n",
    "Keep the answer as concise as possible.\n",
    "Be exhaustive if the user is asking for it.\n",
    "For text provided in the format [some text](link) always include the link.\n",
    "Try to keep the same the \"text\" when it surrounded by quotation marks.\n",
    "Always say \"If you need any further information, don't hesitate to ask!\" at the end of the answer.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template0)\n",
    "\n",
    "# %%\n",
    "rqa_basic_full_plain0 = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=ret_full_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here is a simple Python code to generate the Fibonacci series:\n",
      "\n",
      "```python\n",
      "def fibonacci(n):\n",
      "    fib_series = [0, 1]\n",
      "    while len(fib_series) < n:\n",
      "        fib_series.append(fib_series[-1] + fib_series[-2])\n",
      "    return fib_series\n",
      "\n",
      "n = 10  # Change this number to generate a different length Fibonacci series\n",
      "print(fibonacci(n))\n",
      "```\n",
      "\n",
      "If you need any further information, don't hesitate to ask!\n"
     ]
    }
   ],
   "source": [
    "question = \"Can you write me a python code to do fibonacci series\"\n",
    "print(rqa_basic_full_plain0.invoke(question)['result'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ciruzz v0.1 - Prompt engineered\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "\n",
    "headers_to_split_on_plain = [\n",
    "    (\"#\", \"Category\"),\n",
    "    (\"##\", \"Subcategory\"),\n",
    "    (\"###\", \"Question\"),\n",
    "    (\"####\", \"URL\"),\n",
    "    (\"#####\", \"ID\"),\n",
    "]\n",
    "\n",
    "\n",
    "with open(path_full_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "\n",
    "embedding=OpenAIEmbeddings() #\n",
    "\n",
    "llm_name = \"gpt-3.5-turbo\" #\n",
    "llm = ChatOpenAI(model_name=llm_name, temperature=0) #\n",
    "\n",
    "#vs_full_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings(),persist_directory=\"./chroma_db\" )\n",
    "db3 = Chroma(embedding_function=embedding, persist_directory=\"S3_files/chroma_db\")\n",
    "\n",
    "#ret_full_plain = vs_full_plain.as_retriever()\n",
    "ret_full_plain = db3.as_retriever()\n",
    "\n",
    "\n",
    "template1 = \"\"\"\n",
    "This chatbot is designed to provide assistance with university-related inquiries. Please ensure that all responses are relevant to the domain of universities and adhere to the following constraints:\n",
    "\n",
    "1. Responses should only contain information relevant to universities, including but not limited to admissions, academics, campus life, and student services.\n",
    "2. Be very careful to avoid generating responses that stray into unrelated topics or provide general information outside the scope of university-related queries. In case user asks, suggest the user to use ChatGPT to answer that question.\n",
    "3. Avoid generating code when asked. This function is not relevant for the chatbot purpose, so, n case user asks, suggest the user to use ChatGPT to answer that question.\n",
    "4. Responses should be accurate and informative, drawing from a designated knowledge base consisting of FAQs and guides specific to universities.\n",
    "5. Maintain a professional and helpful tone in all responses, reflecting the expected demeanor of a university representative or advisor.\n",
    "6. Prioritize providing concise and clear answers to questions, avoiding unnecessary verbosity or repetition.\n",
    "7. If the response is mentioning a date, suggest the user to refer to sources to actually verify the answer is right\n",
    "\n",
    "As general suggestion ashere to the following instructions:\n",
    "\n",
    "1. If you don't know the answer, just say that you don't know, don't try to make up an answer and suggest the user to refer to a University Associations or University Advisor for further informations.\n",
    "2. If you the question is too broad and could lead to multiple answers ask the user for clarifications.\n",
    "3. Keep the answer as concise as possible while providing all the relevant information.\n",
    "4. Be exhaustive if the user is asking for it.\n",
    "5. For text provided in the format [some text](link) always include the link.\n",
    "6. Incentivize the user to ask more question if needed at the end of the answer.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT01 = PromptTemplate.from_template(template1)\n",
    "\n",
    "# %%\n",
    "rqa_basic_full_plain01 = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=ret_full_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To build a startup at Bocconi University, you can take advantage of the resources and support available on campus. You can start by participating in entrepreneurship programs, workshops, and events organized by the university's entrepreneurship center. Additionally, you can network with fellow students, professors, and alumni who may be interested in joining your startup or providing guidance. Bocconi also offers incubator programs and access to funding opportunities for student startups. For more specific guidance and support, you can reach out to the entrepreneurship center at Bocconi University. If you need any further information, don't hesitate to ask!\n"
     ]
    }
   ],
   "source": [
    "question = \"How can I build a startup in Bocconi \"\n",
    "answer = rqa_basic_full_plain01.invoke(question)\n",
    "print(answer['result'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ciruzz v0.1 + Sourcing implementation\n",
    "implement right next message"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To build a startup at Bocconi University, you can take advantage of the resources and support available through the university's entrepreneurship programs and initiatives. Bocconi offers various opportunities for students interested in entrepreneurship, such as workshops, networking events, mentorship programs, and access to incubators or accelerators. You can also consider participating in competitions or pitching events to showcase your startup idea and potentially secure funding. Additionally, connecting with like-minded students and faculty members who share your entrepreneurial spirit can help you build a strong foundation for your startup. If you need any further information, don't hesitate to ask!\n",
      "-----\n",
      "Here the sources that have been used to define your answers, check them to verify my answer !\n",
      "Question: How can I reach Bocconi from the airport/train station?\n",
      "Category: Incoming Exchange Program\n",
      "URL: https://bit.unibocconi.it/hc/en-us/articles/4404751158162-How-can-I-reach-Bocconi-from-the-airport-train-station\n",
      "Question: Does the University provide merit-based funding?\n",
      "Category: Funding\n",
      "URL: https://bit.unibocconi.it/hc/en-us/articles/4407879983378-Does-the-University-provide-merit-based-funding\n",
      "Question: Does Bocconi organize an Orientation Program?\n",
      "Category: Incoming Exchange Program\n",
      "URL: https://bit.unibocconi.it/hc/en-us/articles/4404734363026-Does-Bocconi-organize-an-Orientation-Program\n",
      "Question: How do I apply for accommodation?\n",
      "Category: Incoming Exchange Program\n",
      "URL: https://bit.unibocconi.it/hc/en-us/articles/4404616277266-How-do-I-apply-for-accommodation\n",
      "If none of the sources seems relevant for your question, you have probably incurred in an Hallucination, it something that we as AI do and means the produced response is not accurate. In case in which that happens let me know in the Form !\n"
     ]
    }
   ],
   "source": [
    "question = \"How can I build a startup in Bocconi \"\n",
    "answer = rqa_basic_full_plain01.invoke(question)\n",
    "print(answer['result'])\n",
    "print(\"-----\")\n",
    "print(\"Here the sources that have been used to define your answers, check them to verify my answer !\")\n",
    "for doc in answer['source_documents']:\n",
    "    print(\"Question: \" + doc.metadata['Question'] + \"\\nCategory: \" + doc.metadata['Category'])\n",
    "    print(\"URL: \" + doc.metadata['URL'])\n",
    "\n",
    "print(\"If none of the sources seems relevant for your question, you have probably incurred in an Hallucination, it something that we as AI do and means the produced response is not accurate. In case in which that happens let me know in the Form !\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Category': 'Incoming Exchange Program',\n 'ID': '129',\n 'Question': 'How do I apply for accommodation?',\n 'Subcategory': 'Housing',\n 'URL': 'https://bit.unibocconi.it/hc/en-us/articles/4404616277266-How-do-I-apply-for-accommodation'}"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.metadata\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}