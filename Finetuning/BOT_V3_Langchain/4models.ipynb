{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GRBzwNfnb38",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Langchain Quickstart\n",
    "\n",
    "In this quickstart you will create a simple LLM Chain and learn how to log it and get feedback on an LLM response.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/quickstart/langchain_quickstart.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJKBWDvCnb3_",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## 0.Setup\n",
    "### 0.1. Import statements & add API keys\n",
    "For this quickstart you will need Open AI and Huggingface keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#pip install -U langchain\n",
    "#! pip install trulens_eval==0.21.0 openai==1.3.7 langchain chromadb langchainhub bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "# Imports main tools:\n",
    "from trulens_eval import TruChain, Feedback, Huggingface, Tru\n",
    "from trulens_eval.schema import FeedbackResult\n",
    "tru = Tru()\n",
    "tru.reset_database()\n",
    "\n",
    "# Imports from langchain to build app\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain.chains import StuffDocumentsChain,LLMChain,ReduceDocumentsChain,MapReduceDocumentsChain\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "import json\n",
    "import os\n",
    "import textwrap\n",
    "from getpass import getpass\n",
    "from pathlib import Path\n",
    "\n",
    "import chromadb\n",
    "import langchain\n",
    "import openai\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.memory import (\n",
    "    ChatMessageHistory,\n",
    "    ConversationBufferMemory,\n",
    "    ConversationBufferWindowMemory,\n",
    "    ConversationSummaryBufferMemory,\n",
    "    VectorStoreRetrieverMemory,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.7\n",
      "0.22.2\n",
      "1.11.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.schema import messages_from_dict, messages_to_dict\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "import langchain \n",
    "print(langchain.__version__) \n",
    "\n",
    "import trulens_eval\n",
    "print(trulens_eval.__version__)\n",
    "\n",
    "import openai \n",
    "print(openai.__version__) #version update \n",
    "\n",
    "import os \n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__a7cd2e593e7248e594ac5b698bae1f7c\"\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] =\"Bocconi-chat\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Implementation "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load documents & Create Vector stores & Create RAG  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "## paths\n",
    "# reformat \n",
    "path_full_p = \"../../Data/New/Markdown/Full_plain.md\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Headers splitters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "headers_to_split_on_plain = [\n",
    "    (\"#\", \"Category\"),\n",
    "    (\"##\", \"Subcategory\"),\n",
    "    (\"###\", \"Question\"),\n",
    "    (\"####\", \"URL\"),\n",
    "    (\"#####\", \"ID\"), \n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Basic retriever + Vectorstore"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "## SETTING \n",
    "with open(path_full_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "\n",
    "embedding=OpenAIEmbeddings()\n",
    "\n",
    "llm_name = \"gpt-3.5-turbo\"\n",
    "llm = ChatOpenAI(model_name=llm_name, temperature=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "vs_full_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_full_plain = vs_full_plain.as_retriever()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 22.0.4 from /Users/valedipalo/miniforge3/lib/python3.9/site-packages/pip (python 3.9)\r\n"
     ]
    }
   ],
   "source": [
    "! pip --version"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Self query retriever"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SETUP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "metadata_field_info_plain = [\n",
    "    AttributeInfo(\n",
    "        name=\"Category\",\n",
    "        description=\"a primary category or a general topic. It introduces the broader theme under which more specific information is grouped. In a retrieval task, it acts as the first level of data filtering or organization, offering a broad overview of the context or subject area.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Subcategory\",\n",
    "        description=\"This is a subtheme or subcategory of Header 1. It provides a further level of detail, focusing on a specific aspect of the main theme. It serves to refine the search or understanding within the general topic defined by Header 1, guiding the user towards more targeted information.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Question\",\n",
    "        description=\"This represents an even more specific subdivision of Header 2. This level contains the actual question. In a retrieval task, this header helps to focus on a very specific question, making the search even more targeted. \",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "        AttributeInfo(\n",
    "        name=\"URL\",\n",
    "        description=\"A reference to the URL from which the Question has been obtained. It is not relevant in any way for retrieving\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"ID\",\n",
    "        description=\"A reference to the specific question. It is not relevant in any way for retrieving\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "document_content_description = \"Frequently asked questions\"\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "self_full_plain = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vs_full_plain,\n",
    "    document_content_description, #\n",
    "    metadata_field_info_plain,          #\n",
    "    verbose= True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prompt engineering "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PromptTemplate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 36\u001B[0m\n\u001B[1;32m      2\u001B[0m template0 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124mUse the following pieces of context to answer the question at the end. \u001B[39m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124mIf you don\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt know the answer, just say that you don\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt know, don\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt try to make up an answer. \u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;124mQuestion: \u001B[39m\u001B[38;5;132;01m{question}\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;124mHelpful Answer:\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m     15\u001B[0m template_2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;124mThis chatbot is designed to provide assistance with university-related inquiries. Please ensure that all responses are relevant to the domain of universities and adhere to the following constraints:\u001B[39m\n\u001B[1;32m     17\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;124mQuestion: \u001B[39m\u001B[38;5;132;01m{question}\u001B[39;00m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;124mHelpful Answer:\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m---> 36\u001B[0m QA_CHAIN_PROMPT \u001B[38;5;241m=\u001B[39m \u001B[43mPromptTemplate\u001B[49m\u001B[38;5;241m.\u001B[39mfrom_template(template)\n\u001B[1;32m     38\u001B[0m QA_CHAIN_PROMPT2 \u001B[38;5;241m=\u001B[39m PromptTemplate\u001B[38;5;241m.\u001B[39mfrom_template(template2)\n\u001B[1;32m     39\u001B[0m \u001B[38;5;66;03m#llm_name = \"gpt-3.5-turbo\"\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m#llm = ChatOpenAI(model_name=llm_name, temperature=0)\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'PromptTemplate' is not defined"
     ]
    }
   ],
   "source": [
    "# Build prompt\n",
    "template0 = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "If you the question is too broad ask the user for clarifications.\n",
    "Keep the answer as concise as possible.\n",
    "Be exhaustive if the user is asking for it. \n",
    "For text provided in the format [some text](link) always include the link. \n",
    "Try to keep the same the \"text\" when it surrounded by quotation marks.  \n",
    "Always say \"If you need any further information, don't hesitate to ask!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "template_2 = \"\"\"\n",
    "This chatbot is designed to provide assistance with university-related inquiries. Please ensure that all responses are relevant to the domain of universities and adhere to the following constraints:\n",
    "\n",
    "1. Responses should only contain information relevant to universities, including but not limited to admissions, academics, campus life, and student services.\n",
    "2. Avoid generating responses that stray into unrelated topics or provide general information outside the scope of university-related queries.\n",
    "3. Responses should be accurate and informative, drawing from a designated knowledge base consisting of FAQs and guides specific to universities.\n",
    "4. Maintain a professional and helpful tone in all responses, reflecting the expected demeanor of a university representative or advisor.\n",
    "5. Prioritize providing concise and clear answers to questions, avoiding unnecessary verbosity or repetition.\n",
    "6. If the response is mentioning a date, suggest the user to refer to sources to actually verify the answer is right\n",
    "\n",
    "As general suggestion ashere to the following instructions:\n",
    "\n",
    "1. If you don't know the answer, just say that you don't know, don't try to make up an answer and suggest the user to refer to a University Associations or University Advisor for further informations.\n",
    "2. If you the question is too broad and could lead to multiple answers ask the user for clarifications.\n",
    "3. Keep the answer as concise as possible while providing all the relevant information.\n",
    "4. Be exhaustive if the user is asking for it.\n",
    "5. For text provided in the format [some text](link) always include the link.\n",
    "6.  Incentivize the user to ask more question if needed at the end of the answer.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "QA_CHAIN_PROMPT2 = PromptTemplate.from_template(template2)\n",
    "#llm_name = \"gpt-3.5-turbo\"\n",
    "#llm = ChatOpenAI(model_name=llm_name, temperature=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RetrievalQA Chain + Base retriever "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "rqa_basic_full_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=ret_full_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SAVE CHAIN \n",
    "https://github.com/langchain-ai/langchain/discussions/16542"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_basic_full_plain.save(\"trail_save.yaml\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_basic_full_plain.save(\"trail_save.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cat trial_save.json "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load\n",
    "https://github.com/langchain-ai/langchain/issues/13696"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "? sace.save"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chain = load_qa_chain(llm, chain_type=qa_chain_type)(\"trail_save.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load t2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "? Chroma.from_documents"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "persist_directory = 'docs/chroma/'\n",
    "#!rm -rf ./docs/chroma  # remove old database files if any\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#vectordb = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings()) #persist directory missing \n",
    "\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=retriever)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_basic_full_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=ret_full_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SAVE CHAIN \n",
    "https://github.com/langchain-ai/langchain/discussions/16542"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "? Chroma"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_basic_full_plain.save(\"trail_save.yaml\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_basic_full_plain.save(\"trail_save.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cat trial_save.json "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load\n",
    "https://github.com/langchain-ai/langchain/issues/13696"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "? sace.save"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chain = load_qa_chain(llm, chain_type=qa_chain_type)(\"trail_save.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load t2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "? Chroma.from_documents"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "persist_directory = 'docs/chroma/'\n",
    "#!rm -rf ./docs/chroma  # remove old database files if any\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings()) #persist directory missing \n",
    "\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Memory RetrievalQA Chain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True \n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_basic_full_plain_memory = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=ret_full_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "    memory=memory\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_basic_full_plain_memory.invoke(\"What are the dotations in the room? \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conversational retriever chain "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True, output_key='answer')\n",
    "retriever = ret_full_plain\n",
    "\n",
    "# Create the multipurpose chain\n",
    "qachat = ConversationalRetrievalChain.from_llm(\n",
    "    llm=ChatOpenAI(temperature=0),\n",
    "    memory=memory,\n",
    "    retriever=retriever, \n",
    "    return_source_documents=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "qachat.invoke(\"what are the dotation in the rooms?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "qachat.invoke(\"what about the kitchens?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "qachat.invoke(\"are they shared?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RetrievalQA Chain + Self retriever "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True, output_key='answer')\n",
    "retriever = ret_full_plain\n",
    "\n",
    "# Create the multipurpose chain\n",
    "qachat = ConversationalRetrievalChain.from_llm(\n",
    "    llm=ChatOpenAI(temperature=0),\n",
    "    memory=memory,\n",
    "    retriever=retriever, \n",
    "    return_source_documents=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RetrievalQA Chain + Self retriever "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_self_full_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_full_plain,\n",
    "    memory = memory,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_self_full_plain.invoke(\"Who are the resident representatives\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Mapreduce Chain\n",
    "[link](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.map_reduce.MapReduceDocumentsChain.html#langchain.chains.combine_documents.map_reduce.MapReduceDocumentsChain)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "map_red_full_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=ret_full_plain,\n",
    "    memory = memory, \n",
    "    chain_type = \"map_reduce\"    \n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "map_red_full_plain.invoke(\"who are the resident representatives?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---- "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conversationalretriever Chain "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True \n",
    ")\n",
    "\n",
    "\n",
    "retriever=ret_full_plain\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "memor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "qa.invoke(\"who are the resident representatives?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "qa.invoke(\"what are the dotations in the rooms ?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "qa.invoke(\"what about the kitchen ?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "qa.invoke(\"Are they shared ?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "qa.invoke(\"who are the resident representative?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1,5. Memory and sourcing implementation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prototype"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Hello I'm the Bocconichatbot, I'm designed to answer you questions and provide as much help as I can!\") "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#user specific \n",
    "history = ChatMessageHistory()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#example commands \n",
    "history.add_user_message(\"Hello\")\n",
    "history.add_ai_message(\"What can I do you for?\")\n",
    "history.messages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#example commands - converting in a suitable format \n",
    "memory = ConversationBufferMemory(chat_memory=history)\n",
    "memory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#\n",
    "history_buffer = memory.load_memory_variables({})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(history_buffer[\"history\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "template_gen = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "If you the question is too broad and could lead to multiple answers ask the user for clarifications.\n",
    "Keep the answer as concise as possible.\n",
    "Be exhaustive if the user is asking for it. \n",
    "For text provided in the format [some text](link) always include the link. \n",
    "Try to keep the same the \"text\" when it surrounded by quotation marks.  \n",
    "Always say \"If you need any further information, don't hesitate to ask!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template_gen)\n",
    "\n",
    "rqa_basic_full_plain_memory = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    memory = ConversationBufferMemory(),\n",
    "    retriever=ret_full_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "    verbose = True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Hello I'm the Bocconichatbot, I'm designed to answer you questions and provide as much help as I can!\") \n",
    "while True:\n",
    "    prompt = input()\n",
    "    print()\n",
    "    result = rqa_basic_full_plain_memory.invoke(prompt)\n",
    "    print_response(result)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "template = \"\"\"The following is a conversation between a human and Dwight K. Schrute from the TV show The Office.\n",
    "Your goal is to outwit the human and show how much smarter Dwight is. No matter the question, Dwight responds as he's talking in The Office.\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "Dwight:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    prompt=PROMPT,\n",
    "    llm=chat_gpt,\n",
    "    verbose=False,\n",
    "    memory=ConversationBufferMemory(ai_prefix=\"Dwight\"),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = ChatMessageHistory()\n",
    "history.add_user_message(\"Hello\")\n",
    "history.add_ai_message(\"What can I do you for?\")\n",
    "\n",
    "history.messages\n",
    "     "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(chat_memory=history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history_buffer = memory.load_memory_variables({})\n",
    "history_buffer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(history_buffer[\"history\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chat_gpt = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat_gpt, verbose=True, memory=ConversationBufferMemory()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conversation(\"hello\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conversation_messages = conversation.memory.chat_memory.messages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "messages = messages_to_dict(conversation_messages)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "messages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with Path(\"messages.json\").open(\"w\") as f:\n",
    "    json.dump(messages, f, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with Path(\"messages.json\").open(\"r\") as f:\n",
    "    loaded_messages = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = ChatMessageHistory(messages=messages_from_dict(loaded_messages))\n",
    "#retrieve informations \n",
    "history.messages[0].content"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Condensing conversations "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = ChatMessageHistory(messages=messages_from_dict(loaded_messages))\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    chat_memory=history,\n",
    "    k=1, #take last message \n",
    "    ai_prefix=\"Dwight\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = ChatMessageHistory(messages=messages_from_dict(loaded_messages))\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    chat_memory=history, ai_prefix=\"Dwight\", llm=chat_gpt, max_token_limit=10\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_basic_full_plain_memory = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=ret_full_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "    verbose = True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_basic_full_plain_memory(\"hello\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Evaluations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Langchain: [link](https://smith.langchain.com/o/917d7cd4-4420-5477-8a36-902a60673259/projects?paginationState=%7B%22pageIndex%22%3A0%2C%22pageSize%22%3A10%7D&chartedColumn=latency_p50)\n",
    "- Trulens: "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trulens set up"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from trulens_eval import TruChain, Feedback, Huggingface, Tru\n",
    "from trulens_eval.schema import FeedbackResult\n",
    "tru = Tru()\n",
    "#tru.reset_database()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from trulens_eval.feedback.provider import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "# Initialize provider class\n",
    "openai = OpenAI()\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "from trulens_eval.app import App\n",
    "context = App.select_context(rqa_basic_full_plain)\n",
    "\n",
    "from trulens_eval.feedback import Groundedness\n",
    "grounded = Groundedness(groundedness_provider=OpenAI())\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons)\n",
    "    .on(context.collect()) # collect context chunks into a list\n",
    "    .on_output()\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = Feedback(openai.relevance_with_cot_reasons).on_input_output()\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(openai.qs_relevance_with_cot_reasons)\n",
    "    .on_input()\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    "    )\n",
    "\n",
    "f_conciseness = Feedback(openai.conciseness_with_cot_reasons).on_output()\n",
    "f_helpfulness = Feedback(openai.helpfulness_with_cot_reasons).on_output()\n",
    "#f_comprensiveness = Feedback(openai.comprehensiveness_with_cot_reasons).on_output()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Eval_question tests "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test tabular data \n",
    "question1 = (\"Who are the resident representatives?\") # 18\n",
    "question2 = (\"Are there any grants for international mobility programs?\") #65 - Good \n",
    "question3 = (\"I'm going to Danmark with my mobility program, what grant I will receive?\") #65 - good \n",
    "question4 = (\"I'm a second year student who is using a student loan, how many credit do I need by the end of the year?\")#69 - almost perfect, should ask for info about if you are bachelor or master \n",
    "question5 = (\"I'm a second year master student who is using a student loan, how many credit do I need by the end of the year?\")#69 - perfect \n",
    "question6 = (\"what are the deadlines for payment of tuition?\") # 74 Bad - test sources \n",
    "\n",
    "#test notes \n",
    "question10 = (\"what is maximum occupacy in the library?\") #29 Good \n",
    "\n",
    "#test factual info \n",
    "question11 = (\"where is located the library?\") #Â 29 Good \n",
    "\n",
    "#test specific info retrieval in answers which have to mention many points \n",
    "question17 = (\"What is the necessary documentation to apply for fees revaluation? \")#41\n",
    "question20 = (\"I want to apply for fees revaluation, what should I do?\")#41\n",
    "question21 = (\"what can u tell me abou fees revaluation?\")# 41 check references \n",
    "question22 = (\"what are the steps for fees revaluation?\")#41 \n",
    "\n",
    "#number list testing \n",
    "question23 = (\"what is the application procedure for international mobility grant?\") #ok\n",
    "    \n",
    "#bullet point testing \n",
    "question18 = (\"What are the requirements to apply for open reservation monthly?\") #6 Perfect \n",
    "question19 = (\"How can I apply for open reservation monthly?\") #6 Good \n",
    "\n",
    "#hard questions \n",
    "question12 = (\"Is it possible to visit the library without being a student?\") #Â 29 Perfect \n",
    "question13 = (\"I've booked an accomodation in Openreservation, but I can't pay the deposit. What should I do?\") #7 Good \n",
    "question14 = (\"What are the coordinates for making a bank transfer for securing the open reservation given that I can't pay with Paytool?\") #Â 7 Perfect\n",
    "\n",
    "#very hard \n",
    "question15 = (\"I broke my arm, I'm a bocconi student, who can I contact?\") #174 Verify sources \n",
    "\n",
    "#link retrieval \n",
    "question16 = (\"I broke my arm, does the Bocconi have a medical center?\") # 174 good helpful and secure "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#rqa_basic_full_plain.invoke(question4)['result']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (tests) Instrument chain for logging with TruLens\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#OK \n",
    "tru_recorder = TruChain(rqa_basic_full_plain,\n",
    "    app_id='eval_question_rqa_basic_full_plain',\n",
    "    tags = 'ciao',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with tru_recorder as recording:\n",
    "    llm_response = rqa_basic_full_plain.invoke(\"Who are the resident representatives ?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rec = recording.get()\n",
    "\n",
    "from concurrent.futures import as_completed\n",
    "\n",
    "for feedback_future in  as_completed(rec.feedback_results):\n",
    "    feedback = feedback_future.result()\n",
    "\n",
    "    feedback: Feedback\n",
    "\n",
    "    #display(feedback.name, feedback_result.result)\n",
    "\n",
    "records, feedback = tru.get_records_and_feedback(app_ids=['eval_question_rqa_basic_full_plain'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "records"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(rqa_basic_full_ref,\n",
    "    app_id='eval_question_rqa_basic_full_ref',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with tru_recorder as recording:\n",
    "    llm_response = rqa_basic_full_ref.invoke(\"Who are the resident representatives ?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm_response = rqa_basic_full_ref.invoke(\"Who are the resident representatives? \")\n",
    "\n",
    "from trulens_eval import TruChain\n",
    "    tru_recorder = TruChain(\n",
    "    rqa_basic_full_ref,\n",
    "    app_id='trial2')\n",
    "\n",
    "response, tru_record = tru_recorder.with_record(rqa_basic_full_ref, \"Who are the resident representatives? \")\n",
    "json_like = tru_record.layout_calls_as_app()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_basic_full_ref.invoke(\"What is the necessary documentation to apply for fees revaluation?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#gettig cot \n",
    "#records.groundedness_measure_with_cot_reasons_calls[0][0]['meta']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Iterating and looking results "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru.reset_database()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('../../Data/New/new_eval2.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        eval_questions.append(item)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#eval_questions\n",
    "eval_questions1 = eval_questions[:5]\n",
    "eval_questions2 = eval_questions[5:10]\n",
    "eval_questions3 = eval_questions[10:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## rqa_basic_full_plain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# single model \n",
    "tru_recorder = TruChain(rqa_basic_full_plain,\n",
    "    app_id= \"rqa_basic_full_plain\",\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])\n",
    "\n",
    "for question in eval_questions1:\n",
    "    with tru_recorder as recording:\n",
    "        rqa_basic_full_plain.invoke(question)\n",
    "\n",
    "    rec = recording.get()\n",
    "\n",
    "    from concurrent.futures import as_completed\n",
    "\n",
    "    for feedback_future in  as_completed(rec.feedback_results):\n",
    "        feedback = feedback_future.result()\n",
    "\n",
    "        feedback: Feedback\n",
    "\n",
    "    #display(feedback.name, feedback_result.result)\n",
    "\n",
    "    records, feedback = tru.get_records_and_feedback(app_ids=['eval_question_rqa_basic_full_plain'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(rqa_basic_full_plain,\n",
    "    app_id= \"rqa_basic_full_plain\",\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])\n",
    "\n",
    "for question in eval_questions2:\n",
    "    with tru_recorder as recording:\n",
    "        rqa_basic_full_plain.invoke(question)\n",
    "\n",
    "    rec = recording.get()\n",
    "\n",
    "    from concurrent.futures import as_completed\n",
    "\n",
    "    for feedback_future in  as_completed(rec.feedback_results):\n",
    "        feedback = feedback_future.result()\n",
    "\n",
    "        feedback: Feedback\n",
    "\n",
    "    #display(feedback.name, feedback_result.result)\n",
    "\n",
    "    records, feedback = tru.get_records_and_feedback(app_ids=['eval_question_rqa_basic_full_plain'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(rqa_basic_full_plain,\n",
    "    app_id= \"rqa_basic_full_plain\",\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])\n",
    "\n",
    "for question in eval_questions3:\n",
    "    with tru_recorder as recording:\n",
    "        rqa_basic_full_plain.invoke(question)\n",
    "\n",
    "    rec = recording.get()\n",
    "\n",
    "    from concurrent.futures import as_completed\n",
    "\n",
    "    for feedback_future in  as_completed(rec.feedback_results):\n",
    "        feedback = feedback_future.result()\n",
    "\n",
    "        feedback: Feedback\n",
    "\n",
    "    #display(feedback.name, feedback_result.result)\n",
    "\n",
    "    records, feedback = tru.get_records_and_feedback(app_ids=['eval_question_rqa_basic_full_plain'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example use-case "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chat = rqa_basic_full_plain.invoke(\"Till when I have to convert Language certificates for exchanges?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chat['result']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chat['source_documents']\n",
    "unique_urls = set()\n",
    "\n",
    "    # Iterate over each document in the source_documents list\n",
    "for document in chat['source_documents']:\n",
    "    # Extract the URL from the metadata dictionary and add it to the set\n",
    "    # This automatically ensures that only unique URLs are stored\n",
    "    unique_urls.add(document['metadata']['URL'])\n",
    "\n",
    "print(list(unique_urls))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## rqa_self_full_plain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(rqa_self_full_plain,\n",
    "    app_id= \"rqa_self_full_plain\",\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])\n",
    "\n",
    "for question in eval_questions1:\n",
    "    with tru_recorder as recording:\n",
    "        rqa_self_full_plain.invoke(question)\n",
    "\n",
    "    rec = recording.get()\n",
    "\n",
    "    from concurrent.futures import as_completed\n",
    "\n",
    "    for feedback_future in  as_completed(rec.feedback_results):\n",
    "        feedback = feedback_future.result()\n",
    "\n",
    "        feedback: Feedback\n",
    "\n",
    "    #display(feedback.name, feedback_result.result)\n",
    "\n",
    "    records, feedback = tru.get_records_and_feedback(app_ids=['eval_question_rqa_self_full_plain'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(rqa_self_full_plain,\n",
    "    app_id= \"rqa_self_full_plain\",\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])\n",
    "\n",
    "for question in eval_questions2:\n",
    "    with tru_recorder as recording:\n",
    "        rqa_self_full_plain.invoke(question)\n",
    "\n",
    "    rec = recording.get()\n",
    "\n",
    "    from concurrent.futures import as_completed\n",
    "\n",
    "    for feedback_future in  as_completed(rec.feedback_results):\n",
    "        feedback = feedback_future.result()\n",
    "\n",
    "        feedback: Feedback\n",
    "\n",
    "    #display(feedback.name, feedback_result.result)\n",
    "\n",
    "    records, feedback = tru.get_records_and_feedback(app_ids=['eval_question_rqa_self_full_plain'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(rqa_self_full_plain,\n",
    "    app_id= \"rqa_self_full_plain\",\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])\n",
    "\n",
    "for question in eval_questions3:\n",
    "    with tru_recorder as recording:\n",
    "        rqa_self_full_plain.invoke(question)\n",
    "\n",
    "    rec = recording.get()\n",
    "\n",
    "    from concurrent.futures import as_completed\n",
    "\n",
    "    for feedback_future in  as_completed(rec.feedback_results):\n",
    "        feedback = feedback_future.result()\n",
    "\n",
    "        feedback: Feedback\n",
    "\n",
    "    #display(feedback.name, feedback_result.result)\n",
    "\n",
    "    records, feedback = tru.get_records_and_feedback(app_ids=['eval_question_rqa_self_full_plain'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "--- "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## map_red_full_plain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(map_red_full_plain,\n",
    "    app_id= \"map_red_full_plain\",\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])\n",
    "\n",
    "for question in eval_questions1:\n",
    "    with tru_recorder as recording:\n",
    "        map_red_full_plain.invoke(question)\n",
    "\n",
    "    rec = recording.get()\n",
    "\n",
    "    from concurrent.futures import as_completed\n",
    "\n",
    "    for feedback_future in  as_completed(rec.feedback_results):\n",
    "        feedback = feedback_future.result()\n",
    "\n",
    "        feedback: Feedback\n",
    "\n",
    "    #display(feedback.name, feedback_result.result)\n",
    "\n",
    "    records, feedback = tru.get_records_and_feedback(app_ids=['eval_question_map_red_full_plain'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(map_red_full_plain,\n",
    "    app_id= \"map_red_full_plain\",\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])\n",
    "\n",
    "for question in eval_questions2:\n",
    "    with tru_recorder as recording:\n",
    "        map_red_full_plain.invoke(question)\n",
    "\n",
    "    rec = recording.get()\n",
    "\n",
    "    from concurrent.futures import as_completed\n",
    "\n",
    "    for feedback_future in  as_completed(rec.feedback_results):\n",
    "        feedback = feedback_future.result()\n",
    "\n",
    "        feedback: Feedback\n",
    "\n",
    "    #display(feedback.name, feedback_result.result)\n",
    "\n",
    "    records, feedback = tru.get_records_and_feedback(app_ids=['eval_question_map_red_full_plain'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(map_red_full_plain,\n",
    "    app_id= \"map_red_full_plain\",\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])\n",
    "\n",
    "for question in eval_questions3:\n",
    "    with tru_recorder as recording:\n",
    "        map_red_full_plain.invoke(question)\n",
    "\n",
    "    rec = recording.get()\n",
    "\n",
    "    from concurrent.futures import as_completed\n",
    "\n",
    "    for feedback_future in  as_completed(rec.feedback_results):\n",
    "        feedback = feedback_future.result()\n",
    "\n",
    "        feedback: Feedback\n",
    "\n",
    "    #display(feedback.name, feedback_result.result)\n",
    "\n",
    "    records, feedback = tru.get_records_and_feedback(app_ids=['eval_question_map_red_full_plain'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conversationalretriver chain "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(map_red_full_plain,\n",
    "    app_id= \"conversationalchain\",\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])\n",
    "\n",
    "for question in eval_questions1:\n",
    "    with tru_recorder as recording:\n",
    "        map_red_full_plain.invoke(question)\n",
    "\n",
    "    rec = recording.get()\n",
    "\n",
    "    from concurrent.futures import as_completed\n",
    "\n",
    "    for feedback_future in  as_completed(rec.feedback_results):\n",
    "        feedback = feedback_future.result()\n",
    "\n",
    "        feedback: Feedback\n",
    "\n",
    "    #display(feedback.name, feedback_result.result)\n",
    "\n",
    "    records, feedback = tru.get_records_and_feedback(app_ids=['eval_question_conversationalchain'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(map_red_full_plain,\n",
    "    app_id= \"conversationalchain\",\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])\n",
    "\n",
    "for question in eval_questions2:\n",
    "    with tru_recorder as recording:\n",
    "        map_red_full_plain.invoke(question)\n",
    "\n",
    "    rec = recording.get()\n",
    "\n",
    "    from concurrent.futures import as_completed\n",
    "\n",
    "    for feedback_future in  as_completed(rec.feedback_results):\n",
    "        feedback = feedback_future.result()\n",
    "\n",
    "        feedback: Feedback\n",
    "\n",
    "    #display(feedback.name, feedback_result.result)\n",
    "\n",
    "    records, feedback = tru.get_records_and_feedback(app_ids=['eval_question_conversationalchain'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(map_red_full_plain,\n",
    "    app_id= \"conversationalchain\",\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])\n",
    "\n",
    "for question in eval_questions3:\n",
    "    with tru_recorder as recording:\n",
    "        map_red_full_plain.invoke(question)\n",
    "\n",
    "    rec = recording.get()\n",
    "\n",
    "    from concurrent.futures import as_completed\n",
    "\n",
    "    for feedback_future in  as_completed(rec.feedback_results):\n",
    "        feedback = feedback_future.result()\n",
    "\n",
    "        feedback: Feedback\n",
    "\n",
    "    #display(feedback.name, feedback_result.result)\n",
    "\n",
    "    records, feedback = tru.get_records_and_feedback(app_ids=['eval_question_conversationalchain'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "--- "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# multiple models \n",
    "\n",
    "models = {\n",
    "    \"rqa_basic_full_plain\": rqa_basic_full_plain}\n",
    "\n",
    "#SET UP MODELS \n",
    "\n",
    "# Function to invoke models\n",
    "def invoke_model_with_inputs(model, inputs):\n",
    "    print(f\"ðŸ¤– starting execution of the model: {model}\") \n",
    "    result = models[model].invoke(inputs)\n",
    "    return result\n",
    "\n",
    "\n",
    "for model_name,model_instance in models.items():\n",
    "    tru_recorder = TruChain(model_name,\n",
    "        app_id= model_instance,\n",
    "        feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])\n",
    "\n",
    "    for question in eval_questions:\n",
    "        with tru_recorder as recording:\n",
    "            invoke_model_with_inputs(model, question)\n",
    "\n",
    "        rec = recording.get()\n",
    "\n",
    "        from concurrent.futures import as_completed\n",
    "\n",
    "        for feedback_future in  as_completed(rec.feedback_results):\n",
    "            feedback = feedback_future.result()\n",
    "\n",
    "            feedback: Feedback\n",
    "\n",
    "        #display(feedback.name, feedback_result.result)\n",
    "\n",
    "        records, feedback = tru.get_records_and_feedback(app_ids=[])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### See in Dashboard\n",
    "For reference see the following [link](https://www.trulens.org/trulens_eval/api/tru/#trulens_eval.trulens_eval.tru.Tru)\n",
    "def run_dashboard(\n",
    "        self,\n",
    "        port: Optional[int] = 8501,\n",
    "        address: Optional[str] = None,\n",
    "        force: bool = False,\n",
    "        _dev: Optional[Path] = None\n",
    "    ) -> Process:\n",
    "        \"\"\"\n",
    "        Run a streamlit dashboard to view logged results and apps.\n",
    "\n",
    "        Args:\n",
    "            - port: int: port number to pass to streamlit through server.port."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#troubleshooting \n",
    "#!pip uninstall trulens_eval -y # to remove existing PyPI version\n",
    "#!pip install git+https://github.com/truera/trulens#subdirectory=trulens_eval"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from trulens_eval import TruChain, Feedback, Huggingface, Tru\n",
    "from trulens_eval.schema import FeedbackResult\n",
    "tru = Tru()\n",
    "#tru.reset_database()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru.run_dashboard() # open a local streamlit app to explore "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru.stop_dashboard(force = True) # stop if needed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Text Dashboard"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Retrieve records and feedback Trulens + Langchain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The results of the feedback functions can be rertireved from the record. These\n",
    "# are `Future` instances (see `concurrent.futures`). You can use `as_completed`\n",
    "# to wait until they have finished evaluating.\n",
    "\n",
    "from concurrent.futures import as_completed\n",
    "\n",
    "for feedback_future in  as_completed(rec.feedback_results):\n",
    "    feedback = feedback_future.result()\n",
    "\n",
    "    feedback: Feedback\n",
    "\n",
    "    display(feedback.name)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#set the row \n",
    "n = 0\n",
    "\n",
    "print(\"Question:\"+ records.iloc[n].input + str(\"\\n\") + \"Answer:\" + records.iloc[n].output)\n",
    "print(\"---------------------\" + \"\\n\" + \"EVALUATION:\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"qs_relevance_with_cot_reasons\")\n",
    "print(\"SCORE: \" + str(records.iloc[n].qs_relevance_with_cot_reasons) +\" | \" + records.qs_relevance_with_cot_reasons_calls[n][0]['meta']['reason'])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"groundedness_measure_with_cot_reasons\")\n",
    "print(\"SCORE: \" + str(records.iloc[n].groundedness_measure_with_cot_reasons) +\" | \" + records.groundedness_measure_with_cot_reasons[n][0]['meta']['reason'])\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"conciseness_with_cot_reasons\")\n",
    "print(\"SCORE: \" + str(records.iloc[n].conciseness_with_cot_reasons) +\" | \" + records.conciseness_with_cot_reasons[n][0]['meta']['reason'])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"helpfulness_with_cot_reasons\")\n",
    "print(\"SCORE: \" + str(records.iloc[n].helpfulness_with_cot_reasons) +\" | \" + records.helpfulness_with_cot_reasons[n][0]['meta']['reason'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "print(\"comprehensiveness_with_cot_reasons\")\n",
    "print(\"SCORE: \" + str(records.iloc[n].comprehensiveness_with_cot_reasons) +\" | \" + records.comprehensiveness_with_cot_reasons[n][0]['meta']['reason'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "print(\"groundedness_measure_with_cot_reasons\")\n",
    "print(\"SCORE: \" + str(records.iloc[n].groundedness_measure_with_cot_reasons))\n",
    "     # +\" | \" + "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "records.groundedness_measure_with_cot_reasons[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])\n",
    "\n",
    "records.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Readable evaluations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "[0][0]['meta']['reason']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3. Multiple questions evaluations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        print(item)\n",
    "        eval_questions.append(item)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder as recording:\n",
    "        rag_chain.invoke(question)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "self_retriever.invoke(\"Vorrei prenotare un alloggio a tariffa intera per l'a.a. 2023-24. Come posso procedere?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder3 as recording:\n",
    "        self_retriever.invoke(question)\n",
    "        \n",
    "        #__record__.app.first.steps.context.first.get_relevant_documents"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder4 as recording:\n",
    "        self_retriever.invoke(question)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder2 as recording:\n",
    "        rag_chain_compressed.invoke(question)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])\n",
    "records.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "records[[\"input\", \"output\"] + feedback]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the recorder is initialized as prebuilt we will need some more lessons to undertand how to actually implemet "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Chatbot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save/Load\n",
    "- [save](https://api.python.langchain.com/en/latest/chains/langchain.chains.retrieval_qa.base.RetrievalQA.html#:~:text=save(file_path%3A%20Union%5BPath%2C%20str%5D)%20%E2%86%92%20None%C2%B6)\n",
    "- [load](https://api.python.langchain.com/en/latest/chains/langchain.chains.loading.load_chain.html#langchain.chains.loading.load_chain)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_basic_full_ref.save(file_path=\"models/rqa_basic_full_ref.yaml\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Union\n",
    "\n",
    "import yaml"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_chain = RetrievalQA.load(\"models/rqa_basic_full_ref.yaml\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = langchain.chains.loading.load_chain(\"models/rqa_basic_full_ref.yaml\", retriever=ret_full_ref)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = langchain.chains.loading.load_chain_from_file(\"models/rqa_basic_full_ref.yaml\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import langchain.chains.loading"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "langchain.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!sudo pip install langchain --upgrade"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. MODEL COMPARISONS "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1. COMPARISON ON RETRIVALQA \n",
    "We will use ceteris paribus for evaluating which on is the best model. \n",
    "We will choose the best model in Retrival_QA setting. \n",
    "We want to investigate: \n",
    "1. HOW DO THE MODEL PERFORM "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Trulens troubleshooting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# terminal commands \n",
    "conda activate aienv\n",
    "cd Finetuning/BOT_V3_Langchain  \n",
    "# PORT problem solved by chainging the port number in /Users/valedipalo/miniforge3/lib/python3.9/site-packages/tru.py "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: Feedback functions evaluated in the deferred manner can be seen in the \"Progress\" page of the TruLens dashboard.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Comparison\n",
    "## 3.1. Amount of data \n",
    "How do the model perform based on the amount of datas we are giving into. \n",
    "To do so we will evaluate with a basic retriever \n",
    "1. rqa_basic_house_ref VS rqa_basic_full_ref \n",
    "2. rqa_basic_house_plain VS rqa_basic_full_plain "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Importance of Data Cleaning \n",
    "We will evaluate how much structuring data is relevant for the models to properly work. \n",
    "To do so we will evaluate the performance for \n",
    "1. rqa_basic_house_ref VS rqa_basic_house_plain\n",
    "2. rqa_basic_full_ref VS rqa_basic_full_plain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 How much is important the retriever \n",
    "The same tests will be done with the self retriever to evaluate if it is performing better or worse than the Basic one. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.4. Different chains \n",
    "Once determined the bes scoring from previous test, we will evaluate different chains and how do they perform using \n",
    "- RetrivalQA\n",
    "- MAPreduce \n",
    "- MAPrerank "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# determining eval question "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_basic_full_plain.invoke"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TEST EVAL_QUESTIONS "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Function to invoke models\n",
    "def invoke_model_with_inputs(models,model, inputs):\n",
    "    print(f\"ðŸ¤– starting execution of the model: {model}\") \n",
    "    result = models[model].invoke(inputs)\n",
    "    return result\n",
    "\n",
    "# Map model names to instances\n",
    "models_basic = {\n",
    "    \"rqa_basic_house_ref\": rqa_basic_house_ref,\n",
    "    \"rqa_basic_house_plain\": rqa_basic_house_plain,\n",
    "    \"rqa_basic_full_ref\": rqa_basic_full_ref,\n",
    "    \"rqa_basic_full_plain\": rqa_basic_full_plain,\n",
    "}\n",
    "\n",
    "models_self = {\n",
    "    \"rqa_self_house_ref\": rqa_self_house_ref,\n",
    "    \"rqa_self_house_plain\": rqa_self_house_plain,\n",
    "    \"rqa_self_full_ref\": rqa_self_full_ref,\n",
    "    \"rqa_self_full_plain\": rqa_self_full_plain,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define the question to ask to the model\n",
    "question = \"Does Bocconi has a Medical Center?\" \n",
    "\n",
    "# Initialize an empty list to collect data\n",
    "data = []\n",
    "\n",
    "# Iterate over your models dictionary and invoke them\n",
    "for model_name, model_instance in models_basic.items():\n",
    "    # Invoke the model with a question and get the result\n",
    "    result = invoke_model_with_inputs(models_basic,model_name, question)\n",
    "    print(result)#\n",
    "    print(\"--\")#\n",
    "\n",
    "    # Extract the question and answer from the result\n",
    "    question_asked = result[\"query\"]\n",
    "    answer_received = result[\"result\"]\n",
    "    \n",
    "    # Append a dictionary with model name, question, and answer to the data list\n",
    "    data.append({\"Model Name\": model_name, \"Question\": question_asked, \"Answer\": answer_received})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ---\n",
    "# Model appendix "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#PATHS \n",
    "path_fees_r = \"../../Data/New/Markdown/Fees_reformat.md\"\n",
    "path_full_r = \"../../Data/New/Markdown/Full_reformat.md\"\n",
    "path_funding_r = \"../../Data/New/Markdown/Funding_reformat.md\"\n",
    "path_housing_r = \"../../Data/New/Markdown/Housing_reformat.md\"\n",
    "path_oth_r = \"../../Data/New/Markdown/Library-Freemover_DD_reformat.md\"\n",
    "#plain \n",
    "path_fees_p = \"../../Data/New/Markdown/Fees_plain.md\"\n",
    "path_funding_p = \"../../Data/New/Markdown/Funding_plain.md\"\n",
    "path_housing_p = \"../../Data/New/Markdown/Housing_plain.md\"\n",
    "path_exc_p = \"../../Data/New/Markdown/Incoming-Exc_plain.md\"\n",
    "path_oth_p = \"../../Data/New/Markdown/Library-Freemover-DD_plain.md\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "headers_to_split_on_reformat = [\n",
    "    (\"#\", \"Category\"),\n",
    "    (\"##\", \"Subcategory\"),\n",
    "    (\"###\", \"Question\"),\n",
    "    (\"####\", \"Subquestion\"),\n",
    "    (\"#####\", \"Subsubquestion\"),\n",
    "    (\"######\", \"URL\"),\n",
    "    (\"#######\",\"ID\"), ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vector store and basic retrievers\n",
    "In this section there are models that probably are not necessary given the way in which retrievers work. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(path_full_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_full_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_full_ref = vs_full_ref.as_retriever()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Refined"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# oth\n",
    "\n",
    "with open(path_housing_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_house_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_house_ref = vs_house_ref.as_retriever()\n",
    "###\n",
    "\n",
    "with open(path_fees_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_fees_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_fees_ref = vs_fees_ref.as_retriever()\n",
    "\n",
    "with open(path_funding_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_funding_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_funding_ref = vs_funding_ref.as_retriever()\n",
    "\n",
    "with open(path_oth_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_oth_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_oth_ref = vs_oth_ref.as_retriever()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plain vector stores "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#oth \n",
    "\n",
    "with open(path_housing_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_house_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_house_plain = vs_house_plain.as_retriever()\n",
    "\n",
    "with open(path_fees_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_fees_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_fees_plain = vs_fees_plain.as_retriever()\n",
    "\n",
    "with open(path_funding_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_funding_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_fudning_plain = vs_funding_plain.as_retriever()\n",
    "\n",
    "with open(path_exc_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_exc_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_exc_plain = vs_exc_plain.as_retriever()\n",
    "\n",
    "\n",
    "with open(path_oth_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_oth_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_oth_plain = vs_oth_plain.as_retriever()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Self retrievers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# self_full_ref\n",
    "metadata_field_info_ref = [\n",
    "    AttributeInfo(\n",
    "        name=\"Category\",\n",
    "        description=\"a primary category or a general topic. It introduces the broader theme under which more specific information is grouped. In a retrieval task, it acts as the first level of data filtering or organization, offering a broad overview of the context or subject area.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Subcategory\",\n",
    "        description=\"This is a subtheme or subcategory of Header 1. It provides a further level of detail, focusing on a specific aspect of the main theme. It serves to refine the search or understanding within the general topic defined by Header 1, guiding the user towards more targeted information.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Question\",\n",
    "        description=\"This represents an even more specific subdivision of Header 2. This level contains the actual question. In a retrieval task, this header helps to focus on a very specific question, making the search even more targeted. \",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Subquestion\",\n",
    "        description=\"For questions which are represented by multiple section,it serves to direct the user or the retrieval system towards a highly detailed and specific answer or information. It's the level that directly responds to the user's questions or needs. Oftentime is defined as General as a placeholder. \",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "        AttributeInfo(\n",
    "        name=\"Subsubquestion\",\n",
    "        description=\"This is the most specific level, is used in case of further and specific details. In most of the cases is defined as general as a placeholder\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "        AttributeInfo(\n",
    "        name=\"URL\",\n",
    "        description=\"A reference to the URL from which the Question has been obtained. It is not relevant in any way for retrieving\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"ID\",\n",
    "        description=\"A reference to the specific question. It is not relevant in any way for retrieving\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "self_full_ref = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vs_full_ref,\n",
    "    document_content_description, #\n",
    "    metadata_field_info_ref,          #\n",
    "    verbose= True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "self_house_ref = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vs_house_ref,\n",
    "    document_content_description, #\n",
    "    metadata_field_info,          #\n",
    "    verbose= True\n",
    ")\n",
    "self_house_plain = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vs_house_plain,\n",
    "    document_content_description, #\n",
    "    metadata_field_info,          #\n",
    "    verbose= True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.1.2 RETRIVAL_QA BASIC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_basic_house_ref = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=ret_house_ref,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "    tags = [\"base\", \"house\",\"refined\"]\n",
    ")\n",
    "\n",
    "rqa_basic_house_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=ret_house_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.1.2 RETRIVAL_QA SELF "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#\n",
    "rqa_self_house_ref = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_house_ref,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    ")\n",
    "\n",
    "rqa_self_house_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_house_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "\n",
    "rqa_self_full_ref = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_full_ref,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "\n",
    "rqa_self_full_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_full_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# --- "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.7. Langchain evaluation \n",
    "To access the results from the dashboard you can use the folowing [link](https://smith.langchain.com/o/917d7cd4-4420-5477-8a36-902a60673259/projects?paginationState=%7B%22pageIndex%22%3A0%2C%22pageSize%22%3A10%7D&chartedColumn=latency_p50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.7.1. Single question eval"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_self.invoke(\"Who are the student representatives?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Memory and Sourcing "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1. Memory "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True \n",
    ")\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "retriever=vectorstore.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# New type of chain: It adds a new bit on top that allows for keeping chat history and new question creating a ew standalone question  \n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "retriever=vectorstore.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "question = \"Quali sono le dotazioni disponibili all'interno delle camere? \"\n",
    "result = qa({\"question\": question})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result[\"answer\"] "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "question = \"Per quanto riguarda la cucina?\"\n",
    "result = qa({\"question\": question})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result[\"answer\"] "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "question = \"Sono quindi comuni?\"\n",
    "result = qa({\"question\": question})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result[\"answer\"] "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Comparison with model with no memory \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "qa_chain1.invoke(question)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2. Sourcing \n",
    "https://python.langchain.com/docs/use_cases/question_answering/sources"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)\n",
    "\n",
    "rag_chain_with_source.invoke(\"Cosa troverÃ  nella stanza in residenza? \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Initialize Feedback Function(s)\n",
    "For iterations over different models\n",
    "N.B. in case of problems refer to the langchain_quickstart in this folder, or to: [Optimize RAG application - Trulens](https://colab.research.google.com/drive/1bjplY8jIUYtkiKzM4tXmZ5U5U10BaiCd)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from trulens_eval import TruChain, Feedback, Huggingface, Tru\n",
    "from trulens_eval.schema import FeedbackResult\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from trulens_eval.feedback.provider import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "# Initialize provider class\n",
    "openai = OpenAI()\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "from trulens_eval.app import App\n",
    "context = App.select_context(rqa_base)\n",
    "\n",
    "from trulens_eval.feedback import Groundedness\n",
    "grounded = Groundedness(groundedness_provider=OpenAI())\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons)\n",
    "    .on(context.collect()) # collect context chunks into a list\n",
    "    .on_output()\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = Feedback(openai.relevance).on_input_output()\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(openai.qs_relevance)\n",
    "    .on_input()\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Instrument chain for logging with TruLens\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#OK \n",
    "tru_recorder = TruChain(rqa_base,\n",
    "    app_id='Chain1_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with tru_recorder as recording:\n",
    "    llm_response = rqa_base.invoke(\"Come funziona l'ingresso in residenza\")\n",
    "\n",
    "print(llm_response)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_base.invoke(\"Come funziona l'ingresso in residenza\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru_recorder2 = TruChain(rqa_compressed,\n",
    "    app_id='Chain2_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])\n",
    "\n",
    "with tru_recorder2 as recording:\n",
    "    llm_response = rqa_compressed.invoke(\"What is the purpose of the source?\")\n",
    "\n",
    "display(llm_response)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tru_recorder3 = TruChain(self_retriever,\n",
    "    app_id='ChainSelf_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])\n",
    "\n",
    "tru_recorder4 = TruChain(multi_retriever,\n",
    "    app_id='Chainmulti_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Retrieve records and feedback (single question) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The record of the app invocation can be retrieved from the `recording`:\n",
    "\n",
    "rec = recording.get() # use .get if only one record\n",
    "#recs = recording.records # use .records if multiple\n",
    "\n",
    "#display(rec)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The results of the feedback functions can be rertireved from the record. These\n",
    "# are `Future` instances (see `concurrent.futures`). You can use `as_completed`\n",
    "# to wait until they have finished evaluating.\n",
    "\n",
    "from concurrent.futures import as_completed\n",
    "\n",
    "for feedback_future in  as_completed(rec.feedback_results):\n",
    "    feedback, feedback_result = feedback_future.result()\n",
    "\n",
    "    feedback: Feedback\n",
    "    feedbac_result: FeedbackResult\n",
    "\n",
    "    display(feedback.name, feedback_result.result)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[\"Chain1_ChatApplication\"])\n",
    "\n",
    "records.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[\"Chain2_ChatApplication\"])\n",
    "\n",
    "records.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3. Multiple questions evaluations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        print(item)\n",
    "        eval_questions.append(item)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder as recording:\n",
    "        rag_chain.invoke(question)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "self_retriever.invoke(\"Vorrei prenotare un alloggio a tariffa intera per l'a.a. 2023-24. Come posso procedere?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder3 as recording:\n",
    "        self_retriever.invoke(question)\n",
    "        \n",
    "        #__record__.app.first.steps.context.first.get_relevant_documents"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder4 as recording:\n",
    "        self_retriever.invoke(question)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder2 as recording:\n",
    "        rag_chain_compressed.invoke(question)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])\n",
    "records.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "records[[\"input\", \"output\"] + feedback]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.4. Explore in a Dashboard\n",
    "For reference see the following [link](https://www.trulens.org/trulens_eval/api/tru/#trulens_eval.trulens_eval.tru.Tru)\n",
    "def run_dashboard(\n",
    "        self,\n",
    "        port: Optional[int] = 8501,\n",
    "        address: Optional[str] = None,\n",
    "        force: bool = False,\n",
    "        _dev: Optional[Path] = None\n",
    "    ) -> Process:\n",
    "        \"\"\"\n",
    "        Run a streamlit dashboard to view logged results and apps.\n",
    "\n",
    "        Args:\n",
    "            - port: int: port number to pass to streamlit through server.port."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru = Tru()\n",
    "#tru.reset_database()\n",
    "tru.run_dashboard(port = 8503) # open a local streamlit app to explore\n",
    "\n",
    "# tru.stop_dashboard() # stop if needed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conda activate aienv\n",
    "cd Finetuning/BOT_V3_Langchain  \n",
    "# PORT problem solved by chainging the port number in tru.py "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: Feedback functions evaluated in the deferred manner can be seen in the \"Progress\" page of the TruLens dashboard.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the recorder is initialized as prebuilt we will need some more lessons to undertand how to actually implemet \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_basic_full_ref.save(file_path=\"models/rqa_basic_full_ref.yaml\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Union\n",
    "\n",
    "import yaml"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_chain = RetrievalQA.load(\"models/rqa_basic_full_ref.yaml\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = langchain.chains.loading.load_chain(\"models/rqa_basic_full_ref.yaml\", retriever=ret_full_ref)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = langchain.chains.loading.load_chain_from_file(\"models/rqa_basic_full_ref.yaml\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import langchain.chains.loading"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "langchain.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!sudo pip install langchain --upgrade"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. MODEL COMPARISONS "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1. COMPARISON ON RETRIVALQA \n",
    "We will use ceteris paribus for evaluating which on is the best model. \n",
    "We will choose the best model in Retrival_QA setting. \n",
    "We want to investigate: \n",
    "1. HOW DO THE MODEL PERFORM "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Trulens troubleshooting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# terminal commands \n",
    "conda activate aienv\n",
    "cd Finetuning/BOT_V3_Langchain  \n",
    "# PORT problem solved by chainging the port number in /Users/valedipalo/miniforge3/lib/python3.9/site-packages/tru.py "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: Feedback functions evaluated in the deferred manner can be seen in the \"Progress\" page of the TruLens dashboard.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Comparison\n",
    "## 3.1. Amount of data \n",
    "How do the model perform based on the amount of datas we are giving into. \n",
    "To do so we will evaluate with a basic retriever \n",
    "1. rqa_basic_house_ref VS rqa_basic_full_ref \n",
    "2. rqa_basic_house_plain VS rqa_basic_full_plain "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Importance of Data Cleaning \n",
    "We will evaluate how much structuring data is relevant for the models to properly work. \n",
    "To do so we will evaluate the performance for \n",
    "1. rqa_basic_house_ref VS rqa_basic_house_plain\n",
    "2. rqa_basic_full_ref VS rqa_basic_full_plain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 How much is important the retriever \n",
    "The same tests will be done with the self retriever to evaluate if it is performing better or worse than the Basic one. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.4. Different chains \n",
    "Once determined the bes scoring from previous test, we will evaluate different chains and how do they perform using \n",
    "- RetrivalQA\n",
    "- MAPreduce \n",
    "- MAPrerank "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# determining eval question "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_basic_full_plain.invoke"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TEST EVAL_QUESTIONS "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Function to invoke models\n",
    "def invoke_model_with_inputs(models,model, inputs):\n",
    "    print(f\"ðŸ¤– starting execution of the model: {model}\") \n",
    "    result = models[model].invoke(inputs)\n",
    "    return result\n",
    "\n",
    "# Map model names to instances\n",
    "models_basic = {\n",
    "    \"rqa_basic_house_ref\": rqa_basic_house_ref,\n",
    "    \"rqa_basic_house_plain\": rqa_basic_house_plain,\n",
    "    \"rqa_basic_full_ref\": rqa_basic_full_ref,\n",
    "    \"rqa_basic_full_plain\": rqa_basic_full_plain,\n",
    "}\n",
    "\n",
    "models_self = {\n",
    "    \"rqa_self_house_ref\": rqa_self_house_ref,\n",
    "    \"rqa_self_house_plain\": rqa_self_house_plain,\n",
    "    \"rqa_self_full_ref\": rqa_self_full_ref,\n",
    "    \"rqa_self_full_plain\": rqa_self_full_plain,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define the question to ask to the model\n",
    "question = \"Does Bocconi has a Medical Center?\" \n",
    "\n",
    "# Initialize an empty list to collect data\n",
    "data = []\n",
    "\n",
    "# Iterate over your models dictionary and invoke them\n",
    "for model_name, model_instance in models_basic.items():\n",
    "    # Invoke the model with a question and get the result\n",
    "    result = invoke_model_with_inputs(models_basic,model_name, question)\n",
    "    print(result)#\n",
    "    print(\"--\")#\n",
    "\n",
    "    # Extract the question and answer from the result\n",
    "    question_asked = result[\"query\"]\n",
    "    answer_received = result[\"result\"]\n",
    "    \n",
    "    # Append a dictionary with model name, question, and answer to the data list\n",
    "    data.append({\"Model Name\": model_name, \"Question\": question_asked, \"Answer\": answer_received})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ---\n",
    "# Model appendix "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#PATHS \n",
    "path_fees_r = \"../../Data/New/Markdown/Fees_reformat.md\"\n",
    "path_full_r = \"../../Data/New/Markdown/Full_reformat.md\"\n",
    "path_funding_r = \"../../Data/New/Markdown/Funding_reformat.md\"\n",
    "path_housing_r = \"../../Data/New/Markdown/Housing_reformat.md\"\n",
    "path_oth_r = \"../../Data/New/Markdown/Library-Freemover_DD_reformat.md\"\n",
    "#plain \n",
    "path_fees_p = \"../../Data/New/Markdown/Fees_plain.md\"\n",
    "path_funding_p = \"../../Data/New/Markdown/Funding_plain.md\"\n",
    "path_housing_p = \"../../Data/New/Markdown/Housing_plain.md\"\n",
    "path_exc_p = \"../../Data/New/Markdown/Incoming-Exc_plain.md\"\n",
    "path_oth_p = \"../../Data/New/Markdown/Library-Freemover-DD_plain.md\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "headers_to_split_on_reformat = [\n",
    "    (\"#\", \"Category\"),\n",
    "    (\"##\", \"Subcategory\"),\n",
    "    (\"###\", \"Question\"),\n",
    "    (\"####\", \"Subquestion\"),\n",
    "    (\"#####\", \"Subsubquestion\"),\n",
    "    (\"######\", \"URL\"),\n",
    "    (\"#######\",\"ID\"), ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vector store and basic retrievers\n",
    "In this section there are models that probably are not necessary given the way in which retrievers work. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(path_full_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_full_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_full_ref = vs_full_ref.as_retriever()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Refined"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# oth\n",
    "\n",
    "with open(path_housing_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_house_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_house_ref = vs_house_ref.as_retriever()\n",
    "###\n",
    "\n",
    "with open(path_fees_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_fees_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_fees_ref = vs_fees_ref.as_retriever()\n",
    "\n",
    "with open(path_funding_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_funding_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_funding_ref = vs_funding_ref.as_retriever()\n",
    "\n",
    "with open(path_oth_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_oth_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_oth_ref = vs_oth_ref.as_retriever()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plain vector stores "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#oth \n",
    "\n",
    "with open(path_housing_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_house_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_house_plain = vs_house_plain.as_retriever()\n",
    "\n",
    "with open(path_fees_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_fees_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_fees_plain = vs_fees_plain.as_retriever()\n",
    "\n",
    "with open(path_funding_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_funding_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_fudning_plain = vs_funding_plain.as_retriever()\n",
    "\n",
    "with open(path_exc_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_exc_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_exc_plain = vs_exc_plain.as_retriever()\n",
    "\n",
    "\n",
    "with open(path_oth_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_oth_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_oth_plain = vs_oth_plain.as_retriever()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Self retrievers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# self_full_ref\n",
    "metadata_field_info_ref = [\n",
    "    AttributeInfo(\n",
    "        name=\"Category\",\n",
    "        description=\"a primary category or a general topic. It introduces the broader theme under which more specific information is grouped. In a retrieval task, it acts as the first level of data filtering or organization, offering a broad overview of the context or subject area.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Subcategory\",\n",
    "        description=\"This is a subtheme or subcategory of Header 1. It provides a further level of detail, focusing on a specific aspect of the main theme. It serves to refine the search or understanding within the general topic defined by Header 1, guiding the user towards more targeted information.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Question\",\n",
    "        description=\"This represents an even more specific subdivision of Header 2. This level contains the actual question. In a retrieval task, this header helps to focus on a very specific question, making the search even more targeted. \",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Subquestion\",\n",
    "        description=\"For questions which are represented by multiple section,it serves to direct the user or the retrieval system towards a highly detailed and specific answer or information. It's the level that directly responds to the user's questions or needs. Oftentime is defined as General as a placeholder. \",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "        AttributeInfo(\n",
    "        name=\"Subsubquestion\",\n",
    "        description=\"This is the most specific level, is used in case of further and specific details. In most of the cases is defined as general as a placeholder\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "        AttributeInfo(\n",
    "        name=\"URL\",\n",
    "        description=\"A reference to the URL from which the Question has been obtained. It is not relevant in any way for retrieving\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"ID\",\n",
    "        description=\"A reference to the specific question. It is not relevant in any way for retrieving\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "self_full_ref = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vs_full_ref,\n",
    "    document_content_description, #\n",
    "    metadata_field_info_ref,          #\n",
    "    verbose= True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "self_house_ref = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vs_house_ref,\n",
    "    document_content_description, #\n",
    "    metadata_field_info,          #\n",
    "    verbose= True\n",
    ")\n",
    "self_house_plain = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vs_house_plain,\n",
    "    document_content_description, #\n",
    "    metadata_field_info,          #\n",
    "    verbose= True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.1.2 RETRIVAL_QA BASIC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_basic_house_ref = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=ret_house_ref,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "    tags = [\"base\", \"house\",\"refined\"]\n",
    ")\n",
    "\n",
    "rqa_basic_house_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=ret_house_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.1.2 RETRIVAL_QA SELF "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#\n",
    "rqa_self_house_ref = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_house_ref,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    ")\n",
    "\n",
    "rqa_self_house_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_house_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "\n",
    "rqa_self_full_ref = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_full_ref,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "\n",
    "rqa_self_full_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_full_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# --- "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.7. Langchain evaluation \n",
    "To access the results from the dashboard you can use the folowing [link](https://smith.langchain.com/o/917d7cd4-4420-5477-8a36-902a60673259/projects?paginationState=%7B%22pageIndex%22%3A0%2C%22pageSize%22%3A10%7D&chartedColumn=latency_p50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.7.1. Single question eval"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_self.invoke(\"Who are the student representatives?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Memory and Sourcing "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1. Memory "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True \n",
    ")\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "retriever=vectorstore.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# New type of chain: It adds a new bit on top that allows for keeping chat history and new question creating a ew standalone question  \n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "retriever=vectorstore.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "question = \"Quali sono le dotazioni disponibili all'interno delle camere? \"\n",
    "result = qa({\"question\": question})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result[\"answer\"] "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "question = \"Per quanto riguarda la cucina?\"\n",
    "result = qa({\"question\": question})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result[\"answer\"] "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "question = \"Sono quindi comuni?\"\n",
    "result = qa({\"question\": question})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result[\"answer\"] "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Comparison with model with no memory \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "qa_chain1.invoke(question)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2. Sourcing \n",
    "https://python.langchain.com/docs/use_cases/question_answering/sources"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)\n",
    "\n",
    "rag_chain_with_source.invoke(\"Cosa troverÃ  nella stanza in residenza? \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Initialize Feedback Function(s)\n",
    "For iterations over different models\n",
    "N.B. in case of problems refer to the langchain_quickstart in this folder, or to: [Optimize RAG application - Trulens](https://colab.research.google.com/drive/1bjplY8jIUYtkiKzM4tXmZ5U5U10BaiCd)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from trulens_eval import TruChain, Feedback, Huggingface, Tru\n",
    "from trulens_eval.schema import FeedbackResult\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from trulens_eval.feedback.provider import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "# Initialize provider class\n",
    "openai = OpenAI()\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "from trulens_eval.app import App\n",
    "context = App.select_context(rqa_base)\n",
    "\n",
    "from trulens_eval.feedback import Groundedness\n",
    "grounded = Groundedness(groundedness_provider=OpenAI())\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons)\n",
    "    .on(context.collect()) # collect context chunks into a list\n",
    "    .on_output()\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = Feedback(openai.relevance).on_input_output()\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(openai.qs_relevance)\n",
    "    .on_input()\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Instrument chain for logging with TruLens\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#OK \n",
    "tru_recorder = TruChain(rqa_base,\n",
    "    app_id='Chain1_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with tru_recorder as recording:\n",
    "    llm_response = rqa_base.invoke(\"Come funziona l'ingresso in residenza\")\n",
    "\n",
    "print(llm_response)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_base.invoke(\"Come funziona l'ingresso in residenza\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru_recorder2 = TruChain(rqa_compressed,\n",
    "    app_id='Chain2_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])\n",
    "\n",
    "with tru_recorder2 as recording:\n",
    "    llm_response = rqa_compressed.invoke(\"What is the purpose of the source?\")\n",
    "\n",
    "display(llm_response)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tru_recorder3 = TruChain(self_retriever,\n",
    "    app_id='ChainSelf_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])\n",
    "\n",
    "tru_recorder4 = TruChain(multi_retriever,\n",
    "    app_id='Chainmulti_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Retrieve records and feedback (single question) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The record of the app invocation can be retrieved from the `recording`:\n",
    "\n",
    "rec = recording.get() # use .get if only one record\n",
    "#recs = recording.records # use .records if multiple\n",
    "\n",
    "#display(rec)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The results of the feedback functions can be rertireved from the record. These\n",
    "# are `Future` instances (see `concurrent.futures`). You can use `as_completed`\n",
    "# to wait until they have finished evaluating.\n",
    "\n",
    "from concurrent.futures import as_completed\n",
    "\n",
    "for feedback_future in  as_completed(rec.feedback_results):\n",
    "    feedback, feedback_result = feedback_future.result()\n",
    "\n",
    "    feedback: Feedback\n",
    "    feedbac_result: FeedbackResult\n",
    "\n",
    "    display(feedback.name, feedback_result.result)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[\"Chain1_ChatApplication\"])\n",
    "\n",
    "records.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[\"Chain2_ChatApplication\"])\n",
    "\n",
    "records.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3. Multiple questions evaluations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        print(item)\n",
    "        eval_questions.append(item)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder as recording:\n",
    "        rag_chain.invoke(question)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "self_retriever.invoke(\"Vorrei prenotare un alloggio a tariffa intera per l'a.a. 2023-24. Come posso procedere?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder3 as recording:\n",
    "        self_retriever.invoke(question)\n",
    "        \n",
    "        #__record__.app.first.steps.context.first.get_relevant_documents"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder4 as recording:\n",
    "        self_retriever.invoke(question)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder2 as recording:\n",
    "        rag_chain_compressed.invoke(question)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])\n",
    "records.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "records[[\"input\", \"output\"] + feedback]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.4. Explore in a Dashboard\n",
    "For reference see the following [link](https://www.trulens.org/trulens_eval/api/tru/#trulens_eval.trulens_eval.tru.Tru)\n",
    "def run_dashboard(\n",
    "        self,\n",
    "        port: Optional[int] = 8501,\n",
    "        address: Optional[str] = None,\n",
    "        force: bool = False,\n",
    "        _dev: Optional[Path] = None\n",
    "    ) -> Process:\n",
    "        \"\"\"\n",
    "        Run a streamlit dashboard to view logged results and apps.\n",
    "\n",
    "        Args:\n",
    "            - port: int: port number to pass to streamlit through server.port."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru = Tru()\n",
    "#tru.reset_database()\n",
    "tru.run_dashboard(port = 8503) # open a local streamlit app to explore\n",
    "\n",
    "# tru.stop_dashboard() # stop if needed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conda activate aienv\n",
    "cd Finetuning/BOT_V3_Langchain  \n",
    "# PORT problem solved by chainging the port number in tru.py "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: Feedback functions evaluated in the deferred manner can be seen in the \"Progress\" page of the TruLens dashboard.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the recorder is initialized as prebuilt we will need some more lessons to undertand how to actually implemet \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The results of the feedback functions can be rertireved from the record. These\n",
    "# are `Future` instances (see `concurrent.futures`). You can use `as_completed`\n",
    "# to wait until they have finished evaluating.\n",
    "\n",
    "from concurrent.futures import as_completed\n",
    "\n",
    "for feedback_future in  as_completed(rec.feedback_results):\n",
    "    feedback, feedback_result = feedback_future.result()\n",
    "\n",
    "    feedback: Feedback\n",
    "    feedbac_result: FeedbackResult\n",
    "\n",
    "    display(feedback.name, feedback_result.result)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[\"Chain1_ChatApplication\"])\n",
    "\n",
    "records.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[\"Chain2_ChatApplication\"])\n",
    "\n",
    "records.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3. Multiple questions evaluations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        print(item)\n",
    "        eval_questions.append(item)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder as recording:\n",
    "        rag_chain.invoke(question)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "self_retriever.invoke(\"Vorrei prenotare un alloggio a tariffa intera per l'a.a. 2023-24. Come posso procedere?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder3 as recording:\n",
    "        self_retriever.invoke(question)\n",
    "        \n",
    "        #__record__.app.first.steps.context.first.get_relevant_documents"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder4 as recording:\n",
    "        self_retriever.invoke(question)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder2 as recording:\n",
    "        rag_chain_compressed.invoke(question)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])\n",
    "records.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "records[[\"input\", \"output\"] + feedback]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.4. Explore in a Dashboard\n",
    "For reference see the following [link](https://www.trulens.org/trulens_eval/api/tru/#trulens_eval.trulens_eval.tru.Tru)\n",
    "def run_dashboard(\n",
    "        self,\n",
    "        port: Optional[int] = 8501,\n",
    "        address: Optional[str] = None,\n",
    "        force: bool = False,\n",
    "        _dev: Optional[Path] = None\n",
    "    ) -> Process:\n",
    "        \"\"\"\n",
    "        Run a streamlit dashboard to view logged results and apps.\n",
    "\n",
    "        Args:\n",
    "            - port: int: port number to pass to streamlit through server.port."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru = Tru()\n",
    "#tru.reset_database()\n",
    "tru.run_dashboard(port = 8503) # open a local streamlit app to explore\n",
    "\n",
    "# tru.stop_dashboard() # stop if needed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conda activate aienv\n",
    "cd Finetuning/BOT_V3_Langchain  \n",
    "# PORT problem solved by chainging the port number in tru.py "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: Feedback functions evaluated in the deferred manner can be seen in the \"Progress\" page of the TruLens dashboard.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the recorder is initialized as prebuilt we will need some more lessons to undertand how to actually implemet \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_basic_full_ref.save(file_path=\"models/rqa_basic_full_ref.yaml\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Union\n",
    "\n",
    "import yaml"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_chain = RetrievalQA.load(\"models/rqa_basic_full_ref.yaml\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = langchain.chains.loading.load_chain(\"models/rqa_basic_full_ref.yaml\", retriever=ret_full_ref)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = langchain.chains.loading.load_chain_from_file(\"models/rqa_basic_full_ref.yaml\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import langchain.chains.loading"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "langchain.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!sudo pip install langchain --upgrade"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. MODEL COMPARISONS "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1. COMPARISON ON RETRIVALQA \n",
    "We will use ceteris paribus for evaluating which on is the best model. \n",
    "We will choose the best model in Retrival_QA setting. \n",
    "We want to investigate: \n",
    "1. HOW DO THE MODEL PERFORM "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Trulens troubleshooting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# terminal commands \n",
    "conda activate aienv\n",
    "cd Finetuning/BOT_V3_Langchain  \n",
    "# PORT problem solved by chainging the port number in /Users/valedipalo/miniforge3/lib/python3.9/site-packages/tru.py "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: Feedback functions evaluated in the deferred manner can be seen in the \"Progress\" page of the TruLens dashboard.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Comparison\n",
    "## 3.1. Amount of data \n",
    "How do the model perform based on the amount of datas we are giving into. \n",
    "To do so we will evaluate with a basic retriever \n",
    "1. rqa_basic_house_ref VS rqa_basic_full_ref \n",
    "2. rqa_basic_house_plain VS rqa_basic_full_plain "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Importance of Data Cleaning \n",
    "We will evaluate how much structuring data is relevant for the models to properly work. \n",
    "To do so we will evaluate the performance for \n",
    "1. rqa_basic_house_ref VS rqa_basic_house_plain\n",
    "2. rqa_basic_full_ref VS rqa_basic_full_plain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 How much is important the retriever \n",
    "The same tests will be done with the self retriever to evaluate if it is performing better or worse than the Basic one. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.4. Different chains \n",
    "Once determined the bes scoring from previous test, we will evaluate different chains and how do they perform using \n",
    "- RetrivalQA\n",
    "- MAPreduce \n",
    "- MAPrerank "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# determining eval question "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_basic_full_plain.invoke"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TEST EVAL_QUESTIONS "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Function to invoke models\n",
    "def invoke_model_with_inputs(models,model, inputs):\n",
    "    print(f\"ðŸ¤– starting execution of the model: {model}\") \n",
    "    result = models[model].invoke(inputs)\n",
    "    return result\n",
    "\n",
    "# Map model names to instances\n",
    "models_basic = {\n",
    "    \"rqa_basic_house_ref\": rqa_basic_house_ref,\n",
    "    \"rqa_basic_house_plain\": rqa_basic_house_plain,\n",
    "    \"rqa_basic_full_ref\": rqa_basic_full_ref,\n",
    "    \"rqa_basic_full_plain\": rqa_basic_full_plain,\n",
    "}\n",
    "\n",
    "models_self = {\n",
    "    \"rqa_self_house_ref\": rqa_self_house_ref,\n",
    "    \"rqa_self_house_plain\": rqa_self_house_plain,\n",
    "    \"rqa_self_full_ref\": rqa_self_full_ref,\n",
    "    \"rqa_self_full_plain\": rqa_self_full_plain,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define the question to ask to the model\n",
    "question = \"Does Bocconi has a Medical Center?\" \n",
    "\n",
    "# Initialize an empty list to collect data\n",
    "data = []\n",
    "\n",
    "# Iterate over your models dictionary and invoke them\n",
    "for model_name, model_instance in models_basic.items():\n",
    "    # Invoke the model with a question and get the result\n",
    "    result = invoke_model_with_inputs(models_basic,model_name, question)\n",
    "    print(result)#\n",
    "    print(\"--\")#\n",
    "\n",
    "    # Extract the question and answer from the result\n",
    "    question_asked = result[\"query\"]\n",
    "    answer_received = result[\"result\"]\n",
    "    \n",
    "    # Append a dictionary with model name, question, and answer to the data list\n",
    "    data.append({\"Model Name\": model_name, \"Question\": question_asked, \"Answer\": answer_received})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ---\n",
    "# Model appendix "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#PATHS \n",
    "path_fees_r = \"../../Data/New/Markdown/Fees_reformat.md\"\n",
    "path_full_r = \"../../Data/New/Markdown/Full_reformat.md\"\n",
    "path_funding_r = \"../../Data/New/Markdown/Funding_reformat.md\"\n",
    "path_housing_r = \"../../Data/New/Markdown/Housing_reformat.md\"\n",
    "path_oth_r = \"../../Data/New/Markdown/Library-Freemover_DD_reformat.md\"\n",
    "#plain \n",
    "path_fees_p = \"../../Data/New/Markdown/Fees_plain.md\"\n",
    "path_funding_p = \"../../Data/New/Markdown/Funding_plain.md\"\n",
    "path_housing_p = \"../../Data/New/Markdown/Housing_plain.md\"\n",
    "path_exc_p = \"../../Data/New/Markdown/Incoming-Exc_plain.md\"\n",
    "path_oth_p = \"../../Data/New/Markdown/Library-Freemover-DD_plain.md\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "headers_to_split_on_reformat = [\n",
    "    (\"#\", \"Category\"),\n",
    "    (\"##\", \"Subcategory\"),\n",
    "    (\"###\", \"Question\"),\n",
    "    (\"####\", \"Subquestion\"),\n",
    "    (\"#####\", \"Subsubquestion\"),\n",
    "    (\"######\", \"URL\"),\n",
    "    (\"#######\",\"ID\"), ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vector store and basic retrievers\n",
    "In this section there are models that probably are not necessary given the way in which retrievers work. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(path_full_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_full_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_full_ref = vs_full_ref.as_retriever()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Refined"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# oth\n",
    "\n",
    "with open(path_housing_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_house_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_house_ref = vs_house_ref.as_retriever()\n",
    "###\n",
    "\n",
    "with open(path_fees_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_fees_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_fees_ref = vs_fees_ref.as_retriever()\n",
    "\n",
    "with open(path_funding_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_funding_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_funding_ref = vs_funding_ref.as_retriever()\n",
    "\n",
    "with open(path_oth_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_oth_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_oth_ref = vs_oth_ref.as_retriever()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plain vector stores "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#oth \n",
    "\n",
    "with open(path_housing_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_house_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_house_plain = vs_house_plain.as_retriever()\n",
    "\n",
    "with open(path_fees_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_fees_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_fees_plain = vs_fees_plain.as_retriever()\n",
    "\n",
    "with open(path_funding_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_funding_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_fudning_plain = vs_funding_plain.as_retriever()\n",
    "\n",
    "with open(path_exc_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_exc_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_exc_plain = vs_exc_plain.as_retriever()\n",
    "\n",
    "\n",
    "with open(path_oth_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_oth_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_oth_plain = vs_oth_plain.as_retriever()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Self retrievers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# self_full_ref\n",
    "metadata_field_info_ref = [\n",
    "    AttributeInfo(\n",
    "        name=\"Category\",\n",
    "        description=\"a primary category or a general topic. It introduces the broader theme under which more specific information is grouped. In a retrieval task, it acts as the first level of data filtering or organization, offering a broad overview of the context or subject area.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Subcategory\",\n",
    "        description=\"This is a subtheme or subcategory of Header 1. It provides a further level of detail, focusing on a specific aspect of the main theme. It serves to refine the search or understanding within the general topic defined by Header 1, guiding the user towards more targeted information.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Question\",\n",
    "        description=\"This represents an even more specific subdivision of Header 2. This level contains the actual question. In a retrieval task, this header helps to focus on a very specific question, making the search even more targeted. \",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Subquestion\",\n",
    "        description=\"For questions which are represented by multiple section,it serves to direct the user or the retrieval system towards a highly detailed and specific answer or information. It's the level that directly responds to the user's questions or needs. Oftentime is defined as General as a placeholder. \",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "        AttributeInfo(\n",
    "        name=\"Subsubquestion\",\n",
    "        description=\"This is the most specific level, is used in case of further and specific details. In most of the cases is defined as general as a placeholder\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "        AttributeInfo(\n",
    "        name=\"URL\",\n",
    "        description=\"A reference to the URL from which the Question has been obtained. It is not relevant in any way for retrieving\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"ID\",\n",
    "        description=\"A reference to the specific question. It is not relevant in any way for retrieving\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "self_full_ref = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vs_full_ref,\n",
    "    document_content_description, #\n",
    "    metadata_field_info_ref,          #\n",
    "    verbose= True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "self_house_ref = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vs_house_ref,\n",
    "    document_content_description, #\n",
    "    metadata_field_info,          #\n",
    "    verbose= True\n",
    ")\n",
    "self_house_plain = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vs_house_plain,\n",
    "    document_content_description, #\n",
    "    metadata_field_info,          #\n",
    "    verbose= True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.1.2 RETRIVAL_QA BASIC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_basic_house_ref = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=ret_house_ref,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "    tags = [\"base\", \"house\",\"refined\"]\n",
    ")\n",
    "\n",
    "rqa_basic_house_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=ret_house_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.1.2 RETRIVAL_QA SELF "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#\n",
    "rqa_self_house_ref = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_house_ref,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    ")\n",
    "\n",
    "rqa_self_house_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_house_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "\n",
    "rqa_self_full_ref = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_full_ref,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "\n",
    "rqa_self_full_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_full_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# --- "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.7. Langchain evaluation \n",
    "To access the results from the dashboard you can use the folowing [link](https://smith.langchain.com/o/917d7cd4-4420-5477-8a36-902a60673259/projects?paginationState=%7B%22pageIndex%22%3A0%2C%22pageSize%22%3A10%7D&chartedColumn=latency_p50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.7.1. Single question eval"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_self.invoke(\"Who are the student representatives?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Memory and Sourcing "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1. Memory "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True \n",
    ")\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "retriever=vectorstore.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# New type of chain: It adds a new bit on top that allows for keeping chat history and new question creating a ew standalone question  \n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "retriever=vectorstore.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "question = \"Quali sono le dotazioni disponibili all'interno delle camere? \"\n",
    "result = qa({\"question\": question})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result[\"answer\"] "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "question = \"Per quanto riguarda la cucina?\"\n",
    "result = qa({\"question\": question})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result[\"answer\"] "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "question = \"Sono quindi comuni?\"\n",
    "result = qa({\"question\": question})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result[\"answer\"] "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Comparison with model with no memory \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "qa_chain1.invoke(question)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2. Sourcing \n",
    "https://python.langchain.com/docs/use_cases/question_answering/sources"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)\n",
    "\n",
    "rag_chain_with_source.invoke(\"Cosa troverÃ  nella stanza in residenza? \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Initialize Feedback Function(s)\n",
    "For iterations over different models\n",
    "N.B. in case of problems refer to the langchain_quickstart in this folder, or to: [Optimize RAG application - Trulens](https://colab.research.google.com/drive/1bjplY8jIUYtkiKzM4tXmZ5U5U10BaiCd)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from trulens_eval import TruChain, Feedback, Huggingface, Tru\n",
    "from trulens_eval.schema import FeedbackResult\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from trulens_eval.feedback.provider import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "# Initialize provider class\n",
    "openai = OpenAI()\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "from trulens_eval.app import App\n",
    "context = App.select_context(rqa_base)\n",
    "\n",
    "from trulens_eval.feedback import Groundedness\n",
    "grounded = Groundedness(groundedness_provider=OpenAI())\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons)\n",
    "    .on(context.collect()) # collect context chunks into a list\n",
    "    .on_output()\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = Feedback(openai.relevance).on_input_output()\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(openai.qs_relevance)\n",
    "    .on_input()\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Instrument chain for logging with TruLens\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#OK \n",
    "tru_recorder = TruChain(rqa_base,\n",
    "    app_id='Chain1_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with tru_recorder as recording:\n",
    "    llm_response = rqa_base.invoke(\"Come funziona l'ingresso in residenza\")\n",
    "\n",
    "print(llm_response)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rqa_base.invoke(\"Come funziona l'ingresso in residenza\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru_recorder2 = TruChain(rqa_compressed,\n",
    "    app_id='Chain2_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])\n",
    "\n",
    "with tru_recorder2 as recording:\n",
    "    llm_response = rqa_compressed.invoke(\"What is the purpose of the source?\")\n",
    "\n",
    "display(llm_response)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tru_recorder3 = TruChain(self_retriever,\n",
    "    app_id='ChainSelf_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])\n",
    "\n",
    "tru_recorder4 = TruChain(multi_retriever,\n",
    "    app_id='Chainmulti_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Retrieve records and feedback (single question) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The record of the app invocation can be retrieved from the `recording`:\n",
    "\n",
    "rec = recording.get() # use .get if only one record\n",
    "#recs = recording.records # use .records if multiple\n",
    "\n",
    "#display(rec)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The results of the feedback functions can be rertireved from the record. These\n",
    "# are `Future` instances (see `concurrent.futures`). You can use `as_completed`\n",
    "# to wait until they have finished evaluating.\n",
    "\n",
    "from concurrent.futures import as_completed\n",
    "\n",
    "for feedback_future in  as_completed(rec.feedback_results):\n",
    "    feedback, feedback_result = feedback_future.result()\n",
    "\n",
    "    feedback: Feedback\n",
    "    feedbac_result: FeedbackResult\n",
    "\n",
    "    display(feedback.name, feedback_result.result)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[\"Chain1_ChatApplication\"])\n",
    "\n",
    "records.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[\"Chain2_ChatApplication\"])\n",
    "\n",
    "records.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3. Multiple questions evaluations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        print(item)\n",
    "        eval_questions.append(item)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder as recording:\n",
    "        rag_chain.invoke(question)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "self_retriever.invoke(\"Vorrei prenotare un alloggio a tariffa intera per l'a.a. 2023-24. Come posso procedere?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder3 as recording:\n",
    "        self_retriever.invoke(question)\n",
    "        \n",
    "        #__record__.app.first.steps.context.first.get_relevant_documents"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder4 as recording:\n",
    "        self_retriever.invoke(question)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder2 as recording:\n",
    "        rag_chain_compressed.invoke(question)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])\n",
    "records.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "records[[\"input\", \"output\"] + feedback]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.4. Explore in a Dashboard\n",
    "For reference see the following [link](https://www.trulens.org/trulens_eval/api/tru/#trulens_eval.trulens_eval.tru.Tru)\n",
    "def run_dashboard(\n",
    "        self,\n",
    "        port: Optional[int] = 8501,\n",
    "        address: Optional[str] = None,\n",
    "        force: bool = False,\n",
    "        _dev: Optional[Path] = None\n",
    "    ) -> Process:\n",
    "        \"\"\"\n",
    "        Run a streamlit dashboard to view logged results and apps.\n",
    "\n",
    "        Args:\n",
    "            - port: int: port number to pass to streamlit through server.port."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru = Tru()\n",
    "#tru.reset_database()\n",
    "tru.run_dashboard(port = 8503) # open a local streamlit app to explore\n",
    "\n",
    "# tru.stop_dashboard() # stop if needed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conda activate aienv\n",
    "cd Finetuning/BOT_V3_Langchain  \n",
    "# PORT problem solved by chainging the port number in tru.py "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: Feedback functions evaluated in the deferred manner can be seen in the \"Progress\" page of the TruLens dashboard.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the recorder is initialized as prebuilt we will need some more lessons to undertand how to actually implemet \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru = Tru()\n",
    "#tru.reset_database()\n",
    "tru.run_dashboard(port = 8503) # open a local streamlit app to explore\n",
    "\n",
    "# tru.stop_dashboard() # stop if needed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conda activate aienv\n",
    "cd Finetuning/BOT_V3_Langchain  \n",
    "# PORT problem solved by chainging the port number in tru.py "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the recorder is initialized as prebuilt we will need some more lessons to undertand how to actually implemet \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the recorder is initialized as prebuilt we will need some more lessons to undertand how to actually implemet \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conda activate aienv\n",
    "cd Finetuning/BOT_V3_Langchain  \n",
    "# PORT problem solved by chainging the port number in tru.py "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: Feedback functions evaluated in the deferred manner can be seen in the \"Progress\" page of the TruLens dashboard.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the recorder is initialized as prebuilt we will need some more lessons to undertand how to actually implemet \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tru = Tru()\n",
    "#tru.reset_database()\n",
    "tru.run_dashboard(port = 8503) # open a local streamlit app to explore\n",
    "\n",
    "# tru.stop_dashboard() # stop if needed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conda activate aienv\n",
    "cd Finetuning/BOT_V3_Langchain  \n",
    "# PORT problem solved by chainging the port number in tru.py "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the recorder is initialized as prebuilt we will need some more lessons to undertand how to actually implemet \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the recorder is initialized as prebuilt we will need some more lessons to undertand how to actually implemet \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conda activate aienv\n",
    "cd Finetuning/BOT_V3_Langchain  \n",
    "# PORT problem solved by chainging the port number in tru.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# the recorder is initialized as prebuilt we will need some more lessons to undertand how to actually implemet \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# the recorder is initialized as prebuilt we will need some more lessons to undertand how to actually implemet \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conda activate aienv\n",
    "cd Finetuning/BOT_V3_Langchain  \n",
    "# PORT problem solved by chainging the port number in tru.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note: Feedback functions evaluated in the deferred manner can be seen in the \"Progress\" page of the TruLens dashboard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# the recorder is initialized as prebuilt we will need some more lessons to undertand how to actually implemet \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru = Tru()\n",
    "#tru.reset_database()\n",
    "tru.run_dashboard(port = 8503) # open a local streamlit app to explore\n",
    "\n",
    "# tru.stop_dashboard() # stop if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conda activate aienv\n",
    "cd Finetuning/BOT_V3_Langchain  \n",
    "# PORT problem solved by chainging the port number in tru.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# the recorder is initialized as prebuilt we will need some more lessons to undertand how to actually implemet \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# the recorder is initialized as prebuilt we will need some more lessons to undertand how to actually implemet \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "aienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5737f6101ac92451320b0e41890107145710b89f85909f3780d702e7818f973"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}