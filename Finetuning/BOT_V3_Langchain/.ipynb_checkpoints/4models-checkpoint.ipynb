{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GRBzwNfnb38",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Langchain Quickstart\n",
    "\n",
    "In this quickstart you will create a simple LLM Chain and learn how to log it and get feedback on an LLM response.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/truera/trulens/blob/main/trulens_eval/examples/quickstart/langchain_quickstart.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJKBWDvCnb3_",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## 0.Setup\n",
    "### 0.1. Import statements & add API keys\n",
    "For this quickstart you will need Open AI and Huggingface keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#pip install -U langchain\n",
    "#! pip install trulens_eval==0.21.0 openai==1.3.7 langchain chromadb langchainhub bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.7\n",
      "0.22.2\n",
      "1.11.1\n"
     ]
    }
   ],
   "source": [
    "# Imports main tools:\n",
    "from trulens_eval import TruChain, Feedback, Huggingface, Tru\n",
    "from trulens_eval.schema import FeedbackResult\n",
    "tru = Tru()\n",
    "tru.reset_database()\n",
    "\n",
    "# Imports from langchain to build app\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain.chains import StuffDocumentsChain,LLMChain,ReduceDocumentsChain,MapReduceDocumentsChain\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "import json\n",
    "import os\n",
    "import textwrap\n",
    "from getpass import getpass\n",
    "from pathlib import Path\n",
    "\n",
    "import chromadb\n",
    "import langchain\n",
    "import openai\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.memory import (\n",
    "    ChatMessageHistory,\n",
    "    ConversationBufferMemory,\n",
    "    ConversationBufferWindowMemory,\n",
    "    ConversationSummaryBufferMemory,\n",
    "    VectorStoreRetrieverMemory,\n",
    ")\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.schema import messages_from_dict, messages_to_dict\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "import langchain \n",
    "print(langchain.__version__) \n",
    "\n",
    "import trulens_eval\n",
    "print(trulens_eval.__version__)\n",
    "\n",
    "import openai \n",
    "print(openai.__version__) #version update \n",
    "\n",
    "import os \n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__a7cd2e593e7248e594ac5b698bae1f7c\"\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] =\"Bocconi-chat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load documents & Create Vector stores & Create RAG  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## paths\n",
    "# reformat \n",
    "path_full_p = \"../../Data/New/Markdown/Full_plain.md\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Headers splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "headers_to_split_on_plain = [\n",
    "    (\"#\", \"Category\"),\n",
    "    (\"##\", \"Subcategory\"),\n",
    "    (\"###\", \"Question\"),\n",
    "    (\"####\", \"URL\"),\n",
    "    (\"#####\", \"ID\"), \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Basic retriever + Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "with open(path_full_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_full_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_full_plain = vs_full_plain.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Self query retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valedipalo/miniforge3/envs/aienv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "metadata_field_info_plain = [\n",
    "    AttributeInfo(\n",
    "        name=\"Category\",\n",
    "        description=\"a primary category or a general topic. It introduces the broader theme under which more specific information is grouped. In a retrieval task, it acts as the first level of data filtering or organization, offering a broad overview of the context or subject area.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Subcategory\",\n",
    "        description=\"This is a subtheme or subcategory of Header 1. It provides a further level of detail, focusing on a specific aspect of the main theme. It serves to refine the search or understanding within the general topic defined by Header 1, guiding the user towards more targeted information.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Question\",\n",
    "        description=\"This represents an even more specific subdivision of Header 2. This level contains the actual question. In a retrieval task, this header helps to focus on a very specific question, making the search even more targeted. \",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "        AttributeInfo(\n",
    "        name=\"URL\",\n",
    "        description=\"A reference to the URL from which the Question has been obtained. It is not relevant in any way for retrieving\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"ID\",\n",
    "        description=\"A reference to the specific question. It is not relevant in any way for retrieving\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "document_content_description = \"Frequently asked questions\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "self_full_plain = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vs_full_plain,\n",
    "    document_content_description, #\n",
    "    metadata_field_info_plain,          #\n",
    "    verbose= True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Prompt engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Build prompt\n",
    "template0 = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "If you the question is too broad ask the user for clarifications.\n",
    "Keep the answer as concise as possible.\n",
    "Be exhaustive if the user is asking for it. \n",
    "For text provided in the format [some text](link) always include the link. \n",
    "Try to keep the same the \"text\" when it surrounded by quotation marks.  \n",
    "Always say \"If you need any further information, don't hesitate to ask!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "If you the question is too broad and could lead to multiple answers ask the user for clarifications.\n",
    "Keep the answer as concise as possible.\n",
    "Be exhaustive if the user is asking for it. \n",
    "For text provided in the format [some text](link) always include the link. \n",
    "Try to keep the same the \"text\" when it surrounded by quotation marks.  \n",
    "Always say \"If you need any further information, don't hesitate to ask!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "#llm_name = \"gpt-3.5-turbo\"\n",
    "#llm = ChatOpenAI(model_name=llm_name, temperature=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### RetrievalQA Chain + Base retriever "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rqa_basic_full_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=ret_full_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Memory RetrievalQA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rqa_basic_full_plain_memory = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=ret_full_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "One output key expected, got dict_keys(['result', 'source_documents'])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrqa_basic_full_plain_memory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat are the dotations in the room? \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/aienv/lib/python3.10/site-packages/langchain/chains/base.py:164\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    163\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m--> 164\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprep_outputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n\u001b[1;32m    168\u001b[0m     final_outputs[RUN_KEY] \u001b[38;5;241m=\u001b[39m RunInfo(run_id\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mrun_id)\n",
      "File \u001b[0;32m~/miniforge3/envs/aienv/lib/python3.10/site-packages/langchain/chains/base.py:440\u001b[0m, in \u001b[0;36mChain.prep_outputs\u001b[0;34m(self, inputs, outputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_outputs(outputs)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_only_outputs:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniforge3/envs/aienv/lib/python3.10/site-packages/langchain/memory/chat_memory.py:38\u001b[0m, in \u001b[0;36mBaseChatMemory.save_context\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any], outputs: Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save context from this conversation to buffer.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     input_str, output_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_input_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_memory\u001b[38;5;241m.\u001b[39madd_messages(\n\u001b[1;32m     40\u001b[0m         [HumanMessage(content\u001b[38;5;241m=\u001b[39minput_str), AIMessage(content\u001b[38;5;241m=\u001b[39moutput_str)]\n\u001b[1;32m     41\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/aienv/lib/python3.10/site-packages/langchain/memory/chat_memory.py:30\u001b[0m, in \u001b[0;36mBaseChatMemory._get_input_output\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(outputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 30\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne output key expected, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutputs\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m     output_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(outputs\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: One output key expected, got dict_keys(['result', 'source_documents'])"
     ]
    }
   ],
   "source": [
    "rqa_basic_full_plain_memory.invoke(\"What are the dotations in the room? \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### RetrievalQA Chain + Self retriever "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rqa_self_full_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_full_plain,\n",
    "    memory = memory,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rqa_self_full_plain.invoke(\"Who are the resident representatives\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Mapreduce Chain\n",
    "[link](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.map_reduce.MapReduceDocumentsChain.html#langchain.chains.combine_documents.map_reduce.MapReduceDocumentsChain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "map_red_full_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=ret_full_plain,\n",
    "    memory = memory, \n",
    "    chain_type = \"map_reduce\"    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "map_red_full_plain.invoke(\"who are the resident representatives?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Conversationalretriever Chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True \n",
    ")\n",
    "\n",
    "\n",
    "retriever=ret_full_plain\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "qa.invoke(\"who are the resident representatives?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "qa.invoke(\"what are the dotations in the rooms ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "qa.invoke(\"what about the kitchen ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "qa.invoke(\"Are they shared ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1,5. Memory and sourcing implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello I'm the Bocconichatbot, I'm designed to answer you questions and provide as much help as I can!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello I'm the Bocconichatbot, I'm designed to answer you questions and provide as much help as I can!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user specific \n",
    "history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello'), AIMessage(content='What can I do you for?')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example commands \n",
    "history.add_user_message(\"Hello\")\n",
    "history.add_ai_message(\"What can I do you for?\")\n",
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='Hello'), AIMessage(content='What can I do you for?')]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example commands - converting in a suitable format \n",
    "memory = ConversationBufferMemory(chat_memory=history)\n",
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "history_buffer = memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hello\n",
      "AI: What can I do you for?\n"
     ]
    }
   ],
   "source": [
    "print(history_buffer[\"history\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_gen = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "If you the question is too broad and could lead to multiple answers ask the user for clarifications.\n",
    "Keep the answer as concise as possible.\n",
    "Be exhaustive if the user is asking for it. \n",
    "For text provided in the format [some text](link) always include the link. \n",
    "Try to keep the same the \"text\" when it surrounded by quotation marks.  \n",
    "Always say \"If you need any further information, don't hesitate to ask!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template_gen)\n",
    "\n",
    "rqa_basic_full_plain_memory = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    memory = ConversationBufferMemory(),\n",
    "    retriever=ret_full_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello I'm the Bocconichatbot, I'm designed to answer you questions and provide as much help as I can!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " who are the resident representatives? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "One output key expected, got dict_keys(['result', 'source_documents'])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m----> 5\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mrqa_basic_full_plain_memory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m print_response(result)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m~/miniforge3/envs/aienv/lib/python3.10/site-packages/langchain/chains/base.py:164\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    163\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m--> 164\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprep_outputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n\u001b[1;32m    168\u001b[0m     final_outputs[RUN_KEY] \u001b[38;5;241m=\u001b[39m RunInfo(run_id\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mrun_id)\n",
      "File \u001b[0;32m~/miniforge3/envs/aienv/lib/python3.10/site-packages/langchain/chains/base.py:440\u001b[0m, in \u001b[0;36mChain.prep_outputs\u001b[0;34m(self, inputs, outputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_outputs(outputs)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_only_outputs:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniforge3/envs/aienv/lib/python3.10/site-packages/langchain/memory/chat_memory.py:38\u001b[0m, in \u001b[0;36mBaseChatMemory.save_context\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any], outputs: Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save context from this conversation to buffer.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     input_str, output_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_input_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_memory\u001b[38;5;241m.\u001b[39madd_messages(\n\u001b[1;32m     40\u001b[0m         [HumanMessage(content\u001b[38;5;241m=\u001b[39minput_str), AIMessage(content\u001b[38;5;241m=\u001b[39moutput_str)]\n\u001b[1;32m     41\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/aienv/lib/python3.10/site-packages/langchain/memory/chat_memory.py:30\u001b[0m, in \u001b[0;36mBaseChatMemory._get_input_output\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(outputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 30\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne output key expected, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutputs\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m     output_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(outputs\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: One output key expected, got dict_keys(['result', 'source_documents'])"
     ]
    }
   ],
   "source": [
    "print(\"Hello I'm the Bocconichatbot, I'm designed to answer you questions and provide as much help as I can!\") \n",
    "while True:\n",
    "    prompt = input()\n",
    "    print()\n",
    "    result = rqa_basic_full_plain_memory.invoke(prompt)\n",
    "    print_response(result)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"The following is a conversation between a human and Dwight K. Schrute from the TV show The Office.\n",
    "Your goal is to outwit the human and show how much smarter Dwight is. No matter the question, Dwight responds as he's talking in The Office.\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "Dwight:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    prompt=PROMPT,\n",
    "    llm=chat_gpt,\n",
    "    verbose=False,\n",
    "    memory=ConversationBufferMemory(ai_prefix=\"Dwight\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "history = ChatMessageHistory()\n",
    "history.add_user_message(\"Hello\")\n",
    "history.add_ai_message(\"What can I do you for?\")\n",
    "\n",
    "history.messages\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(chat_memory=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "history_buffer = memory.load_memory_variables({})\n",
    "history_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(history_buffer[\"history\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chat_gpt = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat_gpt, verbose=True, memory=ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conversation(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conversation_messages = conversation.memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "messages = messages_to_dict(conversation_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with Path(\"messages.json\").open(\"w\") as f:\n",
    "    json.dump(messages, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with Path(\"messages.json\").open(\"r\") as f:\n",
    "    loaded_messages = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "history = ChatMessageHistory(messages=messages_from_dict(loaded_messages))\n",
    "#retrieve informations \n",
    "history.messages[0].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Condensing conversations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "history = ChatMessageHistory(messages=messages_from_dict(loaded_messages))\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    chat_memory=history,\n",
    "    k=1, #take last message \n",
    "    ai_prefix=\"Dwight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "history = ChatMessageHistory(messages=messages_from_dict(loaded_messages))\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    chat_memory=history, ai_prefix=\"Dwight\", llm=chat_gpt, max_token_limit=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rqa_basic_full_plain_memory = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=ret_full_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rqa_basic_full_plain_memory(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Langchain: [link](https://smith.langchain.com/o/917d7cd4-4420-5477-8a36-902a60673259/projects?paginationState=%7B%22pageIndex%22%3A0%2C%22pageSize%22%3A10%7D&chartedColumn=latency_p50)\n",
    "- Trulens: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Trulens set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from trulens_eval import TruChain, Feedback, Huggingface, Tru\n",
    "from trulens_eval.schema import FeedbackResult\n",
    "tru = Tru()\n",
    "#tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from trulens_eval.feedback.provider import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "# Initialize provider class\n",
    "openai = OpenAI()\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "from trulens_eval.app import App\n",
    "context = App.select_context(rqa_basic_full_plain)\n",
    "\n",
    "from trulens_eval.feedback import Groundedness\n",
    "grounded = Groundedness(groundedness_provider=OpenAI())\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons)\n",
    "    .on(context.collect()) # collect context chunks into a list\n",
    "    .on_output()\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = Feedback(openai.relevance_with_cot_reasons).on_input_output()\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(openai.qs_relevance_with_cot_reasons)\n",
    "    .on_input()\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    "    )\n",
    "\n",
    "f_conciseness = Feedback(openai.conciseness_with_cot_reasons).on_output()\n",
    "f_helpfulness = Feedback(openai.helpfulness_with_cot_reasons).on_output()\n",
    "#f_comprensiveness = Feedback(openai.comprehensiveness_with_cot_reasons).on_output()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Eval_question tests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test tabular data \n",
    "question1 = (\"Who are the resident representatives?\") # 18\n",
    "question2 = (\"Are there any grants for international mobility programs?\") #65 - Good \n",
    "question3 = (\"I'm going to Danmark with my mobility program, what grant I will receive?\") #65 - good \n",
    "question4 = (\"I'm a second year student who is using a student loan, how many credit do I need by the end of the year?\")#69 - almost perfect, should ask for info about if you are bachelor or master \n",
    "question5 = (\"I'm a second year master student who is using a student loan, how many credit do I need by the end of the year?\")#69 - perfect \n",
    "question6 = (\"what are the deadlines for payment of tuition?\") # 74 Bad - test sources \n",
    "\n",
    "#test notes \n",
    "question10 = (\"what is maximum occupacy in the library?\") #29 Good \n",
    "\n",
    "#test factual info \n",
    "question11 = (\"where is located the library?\") # 29 Good \n",
    "\n",
    "#test specific info retrieval in answers which have to mention many points \n",
    "question17 = (\"What is the necessary documentation to apply for fees revaluation? \")#41\n",
    "question20 = (\"I want to apply for fees revaluation, what should I do?\")#41\n",
    "question21 = (\"what can u tell me abou fees revaluation?\")# 41 check references \n",
    "question22 = (\"what are the steps for fees revaluation?\")#41 \n",
    "\n",
    "#number list testing \n",
    "question23 = (\"what is the application procedure for international mobility grant?\") #ok\n",
    "    \n",
    "#bullet point testing \n",
    "question18 = (\"What are the requirements to apply for open reservation monthly?\") #6 Perfect \n",
    "question19 = (\"How can I apply for open reservation monthly?\") #6 Good \n",
    "\n",
    "#hard questions \n",
    "question12 = (\"Is it possible to visit the library without being a student?\") # 29 Perfect \n",
    "question13 = (\"I've booked an accomodation in Openreservation, but I can't pay the deposit. What should I do?\") #7 Good \n",
    "question14 = (\"What are the coordinates for making a bank transfer for securing the open reservation given that I can't pay with Paytool?\") # 7 Perfect\n",
    "\n",
    "#very hard \n",
    "question15 = (\"I broke my arm, I'm a bocconi student, who can I contact?\") #174 Verify sources \n",
    "\n",
    "#link retrieval \n",
    "question16 = (\"I broke my arm, does the Bocconi have a medical center?\") # 174 good helpful and secure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#rqa_basic_full_plain.invoke(question4)['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### (tests) Instrument chain for logging with TruLens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#OK \n",
    "tru_recorder = TruChain(rqa_basic_full_plain,\n",
    "    app_id='eval_question_rqa_basic_full_plain',\n",
    "    tags = 'ciao',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with tru_recorder as recording:\n",
    "    llm_response = rqa_basic_full_plain.invoke(\"Who are the resident representatives ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rec = recording.get()\n",
    "\n",
    "from concurrent.futures import as_completed\n",
    "\n",
    "for feedback_future in  as_completed(rec.feedback_results):\n",
    "    feedback = feedback_future.result()\n",
    "\n",
    "    feedback: Feedback\n",
    "\n",
    "    #display(feedback.name, feedback_result.result)\n",
    "\n",
    "records, feedback = tru.get_records_and_feedback(app_ids=['eval_question_rqa_basic_full_plain'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(rqa_basic_full_ref,\n",
    "    app_id='eval_question_rqa_basic_full_ref',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with tru_recorder as recording:\n",
    "    llm_response = rqa_basic_full_ref.invoke(\"Who are the resident representatives ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "llm_response = rqa_basic_full_ref.invoke(\"Who are the resident representatives? \")\n",
    "\n",
    "from trulens_eval import TruChain\n",
    "    tru_recorder = TruChain(\n",
    "    rqa_basic_full_ref,\n",
    "    app_id='trial2')\n",
    "\n",
    "response, tru_record = tru_recorder.with_record(rqa_basic_full_ref, \"Who are the resident representatives? \")\n",
    "json_like = tru_record.layout_calls_as_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rqa_basic_full_ref.invoke(\"What is the necessary documentation to apply for fees revaluation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#gettig cot \n",
    "#records.groundedness_measure_with_cot_reasons_calls[0][0]['meta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Iterating and looking results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('../../Data/New/new_eval2.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#eval_questions\n",
    "eval_questions1 = eval_questions[:5]\n",
    "eval_questions2 = eval_questions[5:10]\n",
    "eval_questions3 = eval_questions[10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## rqa_basic_full_plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# single model \n",
    "tru_recorder = TruChain(rqa_basic_full_plain,\n",
    "    app_id= \"rqa_basic_full_plain\",\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])\n",
    "\n",
    "for question in eval_questions1:\n",
    "    with tru_recorder as recording:\n",
    "        rqa_basic_full_plain.invoke(question)\n",
    "\n",
    "    rec = recording.get()\n",
    "\n",
    "    from concurrent.futures import as_completed\n",
    "\n",
    "    for feedback_future in  as_completed(rec.feedback_results):\n",
    "        feedback = feedback_future.result()\n",
    "\n",
    "        feedback: Feedback\n",
    "\n",
    "    #display(feedback.name, feedback_result.result)\n",
    "\n",
    "    records, feedback = tru.get_records_and_feedback(app_ids=['eval_question_rqa_basic_full_plain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(rqa_basic_full_plain,\n",
    "    app_id= \"rqa_basic_full_plain\",\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])\n",
    "\n",
    "for question in eval_questions2:\n",
    "    with tru_recorder as recording:\n",
    "        rqa_basic_full_plain.invoke(question)\n",
    "\n",
    "    rec = recording.get()\n",
    "\n",
    "    from concurrent.futures import as_completed\n",
    "\n",
    "    for feedback_future in  as_completed(rec.feedback_results):\n",
    "        feedback = feedback_future.result()\n",
    "\n",
    "        feedback: Feedback\n",
    "\n",
    "    #display(feedback.name, feedback_result.result)\n",
    "\n",
    "    records, feedback = tru.get_records_and_feedback(app_ids=['eval_question_rqa_basic_full_plain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(rqa_basic_full_plain,\n",
    "    app_id= \"rqa_basic_full_plain\",\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])\n",
    "\n",
    "for question in eval_questions3:\n",
    "    with tru_recorder as recording:\n",
    "        rqa_basic_full_plain.invoke(question)\n",
    "\n",
    "    rec = recording.get()\n",
    "\n",
    "    from concurrent.futures import as_completed\n",
    "\n",
    "    for feedback_future in  as_completed(rec.feedback_results):\n",
    "        feedback = feedback_future.result()\n",
    "\n",
    "        feedback: Feedback\n",
    "\n",
    "    #display(feedback.name, feedback_result.result)\n",
    "\n",
    "    records, feedback = tru.get_records_and_feedback(app_ids=['eval_question_rqa_basic_full_plain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example use-case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chat = rqa_basic_full_plain.invoke(\"Till when I have to convert Language certificates for exchanges?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chat['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chat['source_documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unique_urls = set()\n",
    "\n",
    "    # Iterate over each document in the source_documents list\n",
    "for document in chat['source_documents']:\n",
    "    # Extract the URL from the metadata dictionary and add it to the set\n",
    "    # This automatically ensures that only unique URLs are stored\n",
    "    unique_urls.add(document['metadata']['URL'])\n",
    "\n",
    "print(list(unique_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## rqa_self_full_plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(rqa_self_full_plain,\n",
    "    app_id= \"rqa_self_full_plain\",\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])\n",
    "\n",
    "for question in eval_questions1:\n",
    "    with tru_recorder as recording:\n",
    "        rqa_self_full_plain.invoke(question)\n",
    "\n",
    "    rec = recording.get()\n",
    "\n",
    "    from concurrent.futures import as_completed\n",
    "\n",
    "    for feedback_future in  as_completed(rec.feedback_results):\n",
    "        feedback = feedback_future.result()\n",
    "\n",
    "        feedback: Feedback\n",
    "\n",
    "    #display(feedback.name, feedback_result.result)\n",
    "\n",
    "    records, feedback = tru.get_records_and_feedback(app_ids=['eval_question_rqa_self_full_plain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(rqa_self_full_plain,\n",
    "    app_id= \"rqa_self_full_plain\",\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])\n",
    "\n",
    "for question in eval_questions2:\n",
    "    with tru_recorder as recording:\n",
    "        rqa_self_full_plain.invoke(question)\n",
    "\n",
    "    rec = recording.get()\n",
    "\n",
    "    from concurrent.futures import as_completed\n",
    "\n",
    "    for feedback_future in  as_completed(rec.feedback_results):\n",
    "        feedback = feedback_future.result()\n",
    "\n",
    "        feedback: Feedback\n",
    "\n",
    "    #display(feedback.name, feedback_result.result)\n",
    "\n",
    "    records, feedback = tru.get_records_and_feedback(app_ids=['eval_question_rqa_self_full_plain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(rqa_self_full_plain,\n",
    "    app_id= \"rqa_self_full_plain\",\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])\n",
    "\n",
    "for question in eval_questions3:\n",
    "    with tru_recorder as recording:\n",
    "        rqa_self_full_plain.invoke(question)\n",
    "\n",
    "    rec = recording.get()\n",
    "\n",
    "    from concurrent.futures import as_completed\n",
    "\n",
    "    for feedback_future in  as_completed(rec.feedback_results):\n",
    "        feedback = feedback_future.result()\n",
    "\n",
    "        feedback: Feedback\n",
    "\n",
    "    #display(feedback.name, feedback_result.result)\n",
    "\n",
    "    records, feedback = tru.get_records_and_feedback(app_ids=['eval_question_rqa_self_full_plain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## map_red_full_plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(map_red_full_plain,\n",
    "    app_id= \"map_red_full_plain\",\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])\n",
    "\n",
    "for question in eval_questions1:\n",
    "    with tru_recorder as recording:\n",
    "        map_red_full_plain.invoke(question)\n",
    "\n",
    "    rec = recording.get()\n",
    "\n",
    "    from concurrent.futures import as_completed\n",
    "\n",
    "    for feedback_future in  as_completed(rec.feedback_results):\n",
    "        feedback = feedback_future.result()\n",
    "\n",
    "        feedback: Feedback\n",
    "\n",
    "    #display(feedback.name, feedback_result.result)\n",
    "\n",
    "    records, feedback = tru.get_records_and_feedback(app_ids=['eval_question_map_red_full_plain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(map_red_full_plain,\n",
    "    app_id= \"map_red_full_plain\",\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])\n",
    "\n",
    "for question in eval_questions2:\n",
    "    with tru_recorder as recording:\n",
    "        map_red_full_plain.invoke(question)\n",
    "\n",
    "    rec = recording.get()\n",
    "\n",
    "    from concurrent.futures import as_completed\n",
    "\n",
    "    for feedback_future in  as_completed(rec.feedback_results):\n",
    "        feedback = feedback_future.result()\n",
    "\n",
    "        feedback: Feedback\n",
    "\n",
    "    #display(feedback.name, feedback_result.result)\n",
    "\n",
    "    records, feedback = tru.get_records_and_feedback(app_ids=['eval_question_map_red_full_plain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru_recorder = TruChain(map_red_full_plain,\n",
    "    app_id= \"map_red_full_plain\",\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])\n",
    "\n",
    "for question in eval_questions3:\n",
    "    with tru_recorder as recording:\n",
    "        map_red_full_plain.invoke(question)\n",
    "\n",
    "    rec = recording.get()\n",
    "\n",
    "    from concurrent.futures import as_completed\n",
    "\n",
    "    for feedback_future in  as_completed(rec.feedback_results):\n",
    "        feedback = feedback_future.result()\n",
    "\n",
    "        feedback: Feedback\n",
    "\n",
    "    #display(feedback.name, feedback_result.result)\n",
    "\n",
    "    records, feedback = tru.get_records_and_feedback(app_ids=['eval_question_map_red_full_plain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# multiple models \n",
    "\n",
    "models = {\n",
    "    \"rqa_basic_full_plain\": rqa_basic_full_plain}\n",
    "\n",
    "#SET UP MODELS \n",
    "\n",
    "# Function to invoke models\n",
    "def invoke_model_with_inputs(model, inputs):\n",
    "    print(f\"🤖 starting execution of the model: {model}\") \n",
    "    result = models[model].invoke(inputs)\n",
    "    return result\n",
    "\n",
    "\n",
    "for model_name,model_instance in models.items():\n",
    "    tru_recorder = TruChain(model_name,\n",
    "        app_id= model_instance,\n",
    "        feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness,f_conciseness,f_helpfulness])#,f_comprensiveness])\n",
    "\n",
    "    for question in eval_questions:\n",
    "        with tru_recorder as recording:\n",
    "            invoke_model_with_inputs(model, question)\n",
    "\n",
    "        rec = recording.get()\n",
    "\n",
    "        from concurrent.futures import as_completed\n",
    "\n",
    "        for feedback_future in  as_completed(rec.feedback_results):\n",
    "            feedback = feedback_future.result()\n",
    "\n",
    "            feedback: Feedback\n",
    "\n",
    "        #display(feedback.name, feedback_result.result)\n",
    "\n",
    "        records, feedback = tru.get_records_and_feedback(app_ids=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### See in Dashboard\n",
    "For reference see the following [link](https://www.trulens.org/trulens_eval/api/tru/#trulens_eval.trulens_eval.tru.Tru)\n",
    "def run_dashboard(\n",
    "        self,\n",
    "        port: Optional[int] = 8501,\n",
    "        address: Optional[str] = None,\n",
    "        force: bool = False,\n",
    "        _dev: Optional[Path] = None\n",
    "    ) -> Process:\n",
    "        \"\"\"\n",
    "        Run a streamlit dashboard to view logged results and apps.\n",
    "\n",
    "        Args:\n",
    "            - port: int: port number to pass to streamlit through server.port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#troubleshooting \n",
    "#!pip uninstall trulens_eval -y # to remove existing PyPI version\n",
    "#!pip install git+https://github.com/truera/trulens#subdirectory=trulens_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from trulens_eval import TruChain, Feedback, Huggingface, Tru\n",
    "from trulens_eval.schema import FeedbackResult\n",
    "tru = Tru()\n",
    "#tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru.run_dashboard() # open a local streamlit app to explore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru.stop_dashboard(force = True) # stop if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Text Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.2 Retrieve records and feedback Trulens + Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The results of the feedback functions can be rertireved from the record. These\n",
    "# are `Future` instances (see `concurrent.futures`). You can use `as_completed`\n",
    "# to wait until they have finished evaluating.\n",
    "\n",
    "from concurrent.futures import as_completed\n",
    "\n",
    "for feedback_future in  as_completed(rec.feedback_results):\n",
    "    feedback = feedback_future.result()\n",
    "\n",
    "    feedback: Feedback\n",
    "\n",
    "    display(feedback.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#set the row \n",
    "n = 0\n",
    "\n",
    "print(\"Question:\"+ records.iloc[n].input + str(\"\\n\") + \"Answer:\" + records.iloc[n].output)\n",
    "print(\"---------------------\" + \"\\n\" + \"EVALUATION:\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"qs_relevance_with_cot_reasons\")\n",
    "print(\"SCORE: \" + str(records.iloc[n].qs_relevance_with_cot_reasons) +\" | \" + records.qs_relevance_with_cot_reasons_calls[n][0]['meta']['reason'])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"groundedness_measure_with_cot_reasons\")\n",
    "print(\"SCORE: \" + str(records.iloc[n].groundedness_measure_with_cot_reasons) +\" | \" + records.groundedness_measure_with_cot_reasons[n][0]['meta']['reason'])\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"conciseness_with_cot_reasons\")\n",
    "print(\"SCORE: \" + str(records.iloc[n].conciseness_with_cot_reasons) +\" | \" + records.conciseness_with_cot_reasons[n][0]['meta']['reason'])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"helpfulness_with_cot_reasons\")\n",
    "print(\"SCORE: \" + str(records.iloc[n].helpfulness_with_cot_reasons) +\" | \" + records.helpfulness_with_cot_reasons[n][0]['meta']['reason'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "print(\"comprehensiveness_with_cot_reasons\")\n",
    "print(\"SCORE: \" + str(records.iloc[n].comprehensiveness_with_cot_reasons) +\" | \" + records.comprehensiveness_with_cot_reasons[n][0]['meta']['reason'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "print(\"groundedness_measure_with_cot_reasons\")\n",
    "print(\"SCORE: \" + str(records.iloc[n].groundedness_measure_with_cot_reasons))\n",
    "     # +\" | \" + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "records.groundedness_measure_with_cot_reasons[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])\n",
    "\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Readable evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "[0][0]['meta']['reason']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.3. Multiple questions evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        print(item)\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder as recording:\n",
    "        rag_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "self_retriever.invoke(\"Vorrei prenotare un alloggio a tariffa intera per l'a.a. 2023-24. Come posso procedere?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder3 as recording:\n",
    "        self_retriever.invoke(question)\n",
    "        \n",
    "        #__record__.app.first.steps.context.first.get_relevant_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder4 as recording:\n",
    "        self_retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder2 as recording:\n",
    "        rag_chain_compressed.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "records[[\"input\", \"output\"] + feedback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# the recorder is initialized as prebuilt we will need some more lessons to undertand how to actually implemet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Save/Load\n",
    "- [save](https://api.python.langchain.com/en/latest/chains/langchain.chains.retrieval_qa.base.RetrievalQA.html#:~:text=save(file_path%3A%20Union%5BPath%2C%20str%5D)%20%E2%86%92%20None%C2%B6)\n",
    "- [load](https://api.python.langchain.com/en/latest/chains/langchain.chains.loading.load_chain.html#langchain.chains.loading.load_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rqa_basic_full_ref.save(file_path=\"models/rqa_basic_full_ref.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Union\n",
    "\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_chain = RetrievalQA.load(\"models/rqa_basic_full_ref.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a = langchain.chains.loading.load_chain(\"models/rqa_basic_full_ref.yaml\", retriever=ret_full_ref)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a = langchain.chains.loading.load_chain_from_file(\"models/rqa_basic_full_ref.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import langchain.chains.loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!sudo pip install langchain --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. MODEL COMPARISONS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 2.1. COMPARISON ON RETRIVALQA \n",
    "We will use ceteris paribus for evaluating which on is the best model. \n",
    "We will choose the best model in Retrival_QA setting. \n",
    "We want to investigate: \n",
    "1. HOW DO THE MODEL PERFORM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Trulens troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# terminal commands \n",
    "conda activate aienv\n",
    "cd Finetuning/BOT_V3_Langchain  \n",
    "# PORT problem solved by chainging the port number in /Users/valedipalo/miniforge3/lib/python3.9/site-packages/tru.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note: Feedback functions evaluated in the deferred manner can be seen in the \"Progress\" page of the TruLens dashboard.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Comparison\n",
    "## 3.1. Amount of data \n",
    "How do the model perform based on the amount of datas we are giving into. \n",
    "To do so we will evaluate with a basic retriever \n",
    "1. rqa_basic_house_ref VS rqa_basic_full_ref \n",
    "2. rqa_basic_house_plain VS rqa_basic_full_plain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.2 Importance of Data Cleaning \n",
    "We will evaluate how much structuring data is relevant for the models to properly work. \n",
    "To do so we will evaluate the performance for \n",
    "1. rqa_basic_house_ref VS rqa_basic_house_plain\n",
    "2. rqa_basic_full_ref VS rqa_basic_full_plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.3 How much is important the retriever \n",
    "The same tests will be done with the self retriever to evaluate if it is performing better or worse than the Basic one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.4. Different chains \n",
    "Once determined the bes scoring from previous test, we will evaluate different chains and how do they perform using \n",
    "- RetrivalQA\n",
    "- MAPreduce \n",
    "- MAPrerank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# determining eval question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rqa_basic_full_plain.invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TEST EVAL_QUESTIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Function to invoke models\n",
    "def invoke_model_with_inputs(models,model, inputs):\n",
    "    print(f\"🤖 starting execution of the model: {model}\") \n",
    "    result = models[model].invoke(inputs)\n",
    "    return result\n",
    "\n",
    "# Map model names to instances\n",
    "models_basic = {\n",
    "    \"rqa_basic_house_ref\": rqa_basic_house_ref,\n",
    "    \"rqa_basic_house_plain\": rqa_basic_house_plain,\n",
    "    \"rqa_basic_full_ref\": rqa_basic_full_ref,\n",
    "    \"rqa_basic_full_plain\": rqa_basic_full_plain,\n",
    "}\n",
    "\n",
    "models_self = {\n",
    "    \"rqa_self_house_ref\": rqa_self_house_ref,\n",
    "    \"rqa_self_house_plain\": rqa_self_house_plain,\n",
    "    \"rqa_self_full_ref\": rqa_self_full_ref,\n",
    "    \"rqa_self_full_plain\": rqa_self_full_plain,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define the question to ask to the model\n",
    "question = \"Does Bocconi has a Medical Center?\" \n",
    "\n",
    "# Initialize an empty list to collect data\n",
    "data = []\n",
    "\n",
    "# Iterate over your models dictionary and invoke them\n",
    "for model_name, model_instance in models_basic.items():\n",
    "    # Invoke the model with a question and get the result\n",
    "    result = invoke_model_with_inputs(models_basic,model_name, question)\n",
    "    print(result)#\n",
    "    print(\"--\")#\n",
    "\n",
    "    # Extract the question and answer from the result\n",
    "    question_asked = result[\"query\"]\n",
    "    answer_received = result[\"result\"]\n",
    "    \n",
    "    # Append a dictionary with model name, question, and answer to the data list\n",
    "    data.append({\"Model Name\": model_name, \"Question\": question_asked, \"Answer\": answer_received})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ---\n",
    "# Model appendix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#PATHS \n",
    "path_fees_r = \"../../Data/New/Markdown/Fees_reformat.md\"\n",
    "path_full_r = \"../../Data/New/Markdown/Full_reformat.md\"\n",
    "path_funding_r = \"../../Data/New/Markdown/Funding_reformat.md\"\n",
    "path_housing_r = \"../../Data/New/Markdown/Housing_reformat.md\"\n",
    "path_oth_r = \"../../Data/New/Markdown/Library-Freemover_DD_reformat.md\"\n",
    "#plain \n",
    "path_fees_p = \"../../Data/New/Markdown/Fees_plain.md\"\n",
    "path_funding_p = \"../../Data/New/Markdown/Funding_plain.md\"\n",
    "path_housing_p = \"../../Data/New/Markdown/Housing_plain.md\"\n",
    "path_exc_p = \"../../Data/New/Markdown/Incoming-Exc_plain.md\"\n",
    "path_oth_p = \"../../Data/New/Markdown/Library-Freemover-DD_plain.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "headers_to_split_on_reformat = [\n",
    "    (\"#\", \"Category\"),\n",
    "    (\"##\", \"Subcategory\"),\n",
    "    (\"###\", \"Question\"),\n",
    "    (\"####\", \"Subquestion\"),\n",
    "    (\"#####\", \"Subsubquestion\"),\n",
    "    (\"######\", \"URL\"),\n",
    "    (\"#######\",\"ID\"), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Vector store and basic retrievers\n",
    "In this section there are models that probably are not necessary given the way in which retrievers work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(path_full_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_full_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_full_ref = vs_full_ref.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# oth\n",
    "\n",
    "with open(path_housing_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_house_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_house_ref = vs_house_ref.as_retriever()\n",
    "###\n",
    "\n",
    "with open(path_fees_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_fees_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_fees_ref = vs_fees_ref.as_retriever()\n",
    "\n",
    "with open(path_funding_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_funding_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_funding_ref = vs_funding_ref.as_retriever()\n",
    "\n",
    "with open(path_oth_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_oth_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_oth_ref = vs_oth_ref.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Plain vector stores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#oth \n",
    "\n",
    "with open(path_housing_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_house_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_house_plain = vs_house_plain.as_retriever()\n",
    "\n",
    "with open(path_fees_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_fees_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_fees_plain = vs_fees_plain.as_retriever()\n",
    "\n",
    "with open(path_funding_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_funding_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_fudning_plain = vs_funding_plain.as_retriever()\n",
    "\n",
    "with open(path_exc_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_exc_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_exc_plain = vs_exc_plain.as_retriever()\n",
    "\n",
    "\n",
    "with open(path_oth_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_oth_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_oth_plain = vs_oth_plain.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Self retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# self_full_ref\n",
    "metadata_field_info_ref = [\n",
    "    AttributeInfo(\n",
    "        name=\"Category\",\n",
    "        description=\"a primary category or a general topic. It introduces the broader theme under which more specific information is grouped. In a retrieval task, it acts as the first level of data filtering or organization, offering a broad overview of the context or subject area.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Subcategory\",\n",
    "        description=\"This is a subtheme or subcategory of Header 1. It provides a further level of detail, focusing on a specific aspect of the main theme. It serves to refine the search or understanding within the general topic defined by Header 1, guiding the user towards more targeted information.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Question\",\n",
    "        description=\"This represents an even more specific subdivision of Header 2. This level contains the actual question. In a retrieval task, this header helps to focus on a very specific question, making the search even more targeted. \",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Subquestion\",\n",
    "        description=\"For questions which are represented by multiple section,it serves to direct the user or the retrieval system towards a highly detailed and specific answer or information. It's the level that directly responds to the user's questions or needs. Oftentime is defined as General as a placeholder. \",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "        AttributeInfo(\n",
    "        name=\"Subsubquestion\",\n",
    "        description=\"This is the most specific level, is used in case of further and specific details. In most of the cases is defined as general as a placeholder\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "        AttributeInfo(\n",
    "        name=\"URL\",\n",
    "        description=\"A reference to the URL from which the Question has been obtained. It is not relevant in any way for retrieving\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"ID\",\n",
    "        description=\"A reference to the specific question. It is not relevant in any way for retrieving\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "self_full_ref = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vs_full_ref,\n",
    "    document_content_description, #\n",
    "    metadata_field_info_ref,          #\n",
    "    verbose= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "self_house_ref = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vs_house_ref,\n",
    "    document_content_description, #\n",
    "    metadata_field_info,          #\n",
    "    verbose= True\n",
    ")\n",
    "self_house_plain = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vs_house_plain,\n",
    "    document_content_description, #\n",
    "    metadata_field_info,          #\n",
    "    verbose= True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### 2.1.2 RETRIVAL_QA BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rqa_basic_house_ref = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=ret_house_ref,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "    tags = [\"base\", \"house\",\"refined\"]\n",
    ")\n",
    "\n",
    "rqa_basic_house_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=ret_house_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### 2.1.2 RETRIVAL_QA SELF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "rqa_self_house_ref = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_house_ref,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    ")\n",
    "\n",
    "rqa_self_house_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_house_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "\n",
    "rqa_self_full_ref = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_full_ref,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "\n",
    "rqa_self_full_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_full_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# --- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.7. Langchain evaluation \n",
    "To access the results from the dashboard you can use the folowing [link](https://smith.langchain.com/o/917d7cd4-4420-5477-8a36-902a60673259/projects?paginationState=%7B%22pageIndex%22%3A0%2C%22pageSize%22%3A10%7D&chartedColumn=latency_p50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1.7.1. Single question eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rqa_self.invoke(\"Who are the student representatives?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Memory and Sourcing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.1. Memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True \n",
    ")\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "retriever=vectorstore.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# New type of chain: It adds a new bit on top that allows for keeping chat history and new question creating a ew standalone question  \n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "retriever=vectorstore.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "question = \"Quali sono le dotazioni disponibili all'interno delle camere? \"\n",
    "result = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result[\"answer\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "question = \"Per quanto riguarda la cucina?\"\n",
    "result = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result[\"answer\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "question = \"Sono quindi comuni?\"\n",
    "result = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result[\"answer\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Comparison with model with no memory \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "qa_chain1.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2. Sourcing \n",
    "https://python.langchain.com/docs/use_cases/question_answering/sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)\n",
    "\n",
    "rag_chain_with_source.invoke(\"Cosa troverà nella stanza in residenza? \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Initialize Feedback Function(s)\n",
    "For iterations over different models\n",
    "N.B. in case of problems refer to the langchain_quickstart in this folder, or to: [Optimize RAG application - Trulens](https://colab.research.google.com/drive/1bjplY8jIUYtkiKzM4tXmZ5U5U10BaiCd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from trulens_eval import TruChain, Feedback, Huggingface, Tru\n",
    "from trulens_eval.schema import FeedbackResult\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from trulens_eval.feedback.provider import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "# Initialize provider class\n",
    "openai = OpenAI()\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "from trulens_eval.app import App\n",
    "context = App.select_context(rqa_base)\n",
    "\n",
    "from trulens_eval.feedback import Groundedness\n",
    "grounded = Groundedness(groundedness_provider=OpenAI())\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons)\n",
    "    .on(context.collect()) # collect context chunks into a list\n",
    "    .on_output()\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = Feedback(openai.relevance).on_input_output()\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(openai.qs_relevance)\n",
    "    .on_input()\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.1 Instrument chain for logging with TruLens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#OK \n",
    "tru_recorder = TruChain(rqa_base,\n",
    "    app_id='Chain1_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with tru_recorder as recording:\n",
    "    llm_response = rqa_base.invoke(\"Come funziona l'ingresso in residenza\")\n",
    "\n",
    "print(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rqa_base.invoke(\"Come funziona l'ingresso in residenza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru_recorder2 = TruChain(rqa_compressed,\n",
    "    app_id='Chain2_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])\n",
    "\n",
    "with tru_recorder2 as recording:\n",
    "    llm_response = rqa_compressed.invoke(\"What is the purpose of the source?\")\n",
    "\n",
    "display(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tru_recorder3 = TruChain(self_retriever,\n",
    "    app_id='ChainSelf_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])\n",
    "\n",
    "tru_recorder4 = TruChain(multi_retriever,\n",
    "    app_id='Chainmulti_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.2 Retrieve records and feedback (single question) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The record of the app invocation can be retrieved from the `recording`:\n",
    "\n",
    "rec = recording.get() # use .get if only one record\n",
    "#recs = recording.records # use .records if multiple\n",
    "\n",
    "#display(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The results of the feedback functions can be rertireved from the record. These\n",
    "# are `Future` instances (see `concurrent.futures`). You can use `as_completed`\n",
    "# to wait until they have finished evaluating.\n",
    "\n",
    "from concurrent.futures import as_completed\n",
    "\n",
    "for feedback_future in  as_completed(rec.feedback_results):\n",
    "    feedback, feedback_result = feedback_future.result()\n",
    "\n",
    "    feedback: Feedback\n",
    "    feedbac_result: FeedbackResult\n",
    "\n",
    "    display(feedback.name, feedback_result.result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[\"Chain1_ChatApplication\"])\n",
    "\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[\"Chain2_ChatApplication\"])\n",
    "\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.3. Multiple questions evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        print(item)\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder as recording:\n",
    "        rag_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "self_retriever.invoke(\"Vorrei prenotare un alloggio a tariffa intera per l'a.a. 2023-24. Come posso procedere?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder3 as recording:\n",
    "        self_retriever.invoke(question)\n",
    "        \n",
    "        #__record__.app.first.steps.context.first.get_relevant_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder4 as recording:\n",
    "        self_retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder2 as recording:\n",
    "        rag_chain_compressed.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "records[[\"input\", \"output\"] + feedback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.4. Explore in a Dashboard\n",
    "For reference see the following [link](https://www.trulens.org/trulens_eval/api/tru/#trulens_eval.trulens_eval.tru.Tru)\n",
    "def run_dashboard(\n",
    "        self,\n",
    "        port: Optional[int] = 8501,\n",
    "        address: Optional[str] = None,\n",
    "        force: bool = False,\n",
    "        _dev: Optional[Path] = None\n",
    "    ) -> Process:\n",
    "        \"\"\"\n",
    "        Run a streamlit dashboard to view logged results and apps.\n",
    "\n",
    "        Args:\n",
    "            - port: int: port number to pass to streamlit through server.port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru = Tru()\n",
    "#tru.reset_database()\n",
    "tru.run_dashboard(port = 8503) # open a local streamlit app to explore\n",
    "\n",
    "# tru.stop_dashboard() # stop if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conda activate aienv\n",
    "cd Finetuning/BOT_V3_Langchain  \n",
    "# PORT problem solved by chainging the port number in tru.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note: Feedback functions evaluated in the deferred manner can be seen in the \"Progress\" page of the TruLens dashboard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# the recorder is initialized as prebuilt we will need some more lessons to undertand how to actually implemet \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rqa_basic_full_ref.save(file_path=\"models/rqa_basic_full_ref.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Union\n",
    "\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_chain = RetrievalQA.load(\"models/rqa_basic_full_ref.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a = langchain.chains.loading.load_chain(\"models/rqa_basic_full_ref.yaml\", retriever=ret_full_ref)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a = langchain.chains.loading.load_chain_from_file(\"models/rqa_basic_full_ref.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import langchain.chains.loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!sudo pip install langchain --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. MODEL COMPARISONS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 2.1. COMPARISON ON RETRIVALQA \n",
    "We will use ceteris paribus for evaluating which on is the best model. \n",
    "We will choose the best model in Retrival_QA setting. \n",
    "We want to investigate: \n",
    "1. HOW DO THE MODEL PERFORM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Trulens troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# terminal commands \n",
    "conda activate aienv\n",
    "cd Finetuning/BOT_V3_Langchain  \n",
    "# PORT problem solved by chainging the port number in /Users/valedipalo/miniforge3/lib/python3.9/site-packages/tru.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note: Feedback functions evaluated in the deferred manner can be seen in the \"Progress\" page of the TruLens dashboard.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Comparison\n",
    "## 3.1. Amount of data \n",
    "How do the model perform based on the amount of datas we are giving into. \n",
    "To do so we will evaluate with a basic retriever \n",
    "1. rqa_basic_house_ref VS rqa_basic_full_ref \n",
    "2. rqa_basic_house_plain VS rqa_basic_full_plain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.2 Importance of Data Cleaning \n",
    "We will evaluate how much structuring data is relevant for the models to properly work. \n",
    "To do so we will evaluate the performance for \n",
    "1. rqa_basic_house_ref VS rqa_basic_house_plain\n",
    "2. rqa_basic_full_ref VS rqa_basic_full_plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.3 How much is important the retriever \n",
    "The same tests will be done with the self retriever to evaluate if it is performing better or worse than the Basic one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.4. Different chains \n",
    "Once determined the bes scoring from previous test, we will evaluate different chains and how do they perform using \n",
    "- RetrivalQA\n",
    "- MAPreduce \n",
    "- MAPrerank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# determining eval question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rqa_basic_full_plain.invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TEST EVAL_QUESTIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Function to invoke models\n",
    "def invoke_model_with_inputs(models,model, inputs):\n",
    "    print(f\"🤖 starting execution of the model: {model}\") \n",
    "    result = models[model].invoke(inputs)\n",
    "    return result\n",
    "\n",
    "# Map model names to instances\n",
    "models_basic = {\n",
    "    \"rqa_basic_house_ref\": rqa_basic_house_ref,\n",
    "    \"rqa_basic_house_plain\": rqa_basic_house_plain,\n",
    "    \"rqa_basic_full_ref\": rqa_basic_full_ref,\n",
    "    \"rqa_basic_full_plain\": rqa_basic_full_plain,\n",
    "}\n",
    "\n",
    "models_self = {\n",
    "    \"rqa_self_house_ref\": rqa_self_house_ref,\n",
    "    \"rqa_self_house_plain\": rqa_self_house_plain,\n",
    "    \"rqa_self_full_ref\": rqa_self_full_ref,\n",
    "    \"rqa_self_full_plain\": rqa_self_full_plain,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define the question to ask to the model\n",
    "question = \"Does Bocconi has a Medical Center?\" \n",
    "\n",
    "# Initialize an empty list to collect data\n",
    "data = []\n",
    "\n",
    "# Iterate over your models dictionary and invoke them\n",
    "for model_name, model_instance in models_basic.items():\n",
    "    # Invoke the model with a question and get the result\n",
    "    result = invoke_model_with_inputs(models_basic,model_name, question)\n",
    "    print(result)#\n",
    "    print(\"--\")#\n",
    "\n",
    "    # Extract the question and answer from the result\n",
    "    question_asked = result[\"query\"]\n",
    "    answer_received = result[\"result\"]\n",
    "    \n",
    "    # Append a dictionary with model name, question, and answer to the data list\n",
    "    data.append({\"Model Name\": model_name, \"Question\": question_asked, \"Answer\": answer_received})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ---\n",
    "# Model appendix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#PATHS \n",
    "path_fees_r = \"../../Data/New/Markdown/Fees_reformat.md\"\n",
    "path_full_r = \"../../Data/New/Markdown/Full_reformat.md\"\n",
    "path_funding_r = \"../../Data/New/Markdown/Funding_reformat.md\"\n",
    "path_housing_r = \"../../Data/New/Markdown/Housing_reformat.md\"\n",
    "path_oth_r = \"../../Data/New/Markdown/Library-Freemover_DD_reformat.md\"\n",
    "#plain \n",
    "path_fees_p = \"../../Data/New/Markdown/Fees_plain.md\"\n",
    "path_funding_p = \"../../Data/New/Markdown/Funding_plain.md\"\n",
    "path_housing_p = \"../../Data/New/Markdown/Housing_plain.md\"\n",
    "path_exc_p = \"../../Data/New/Markdown/Incoming-Exc_plain.md\"\n",
    "path_oth_p = \"../../Data/New/Markdown/Library-Freemover-DD_plain.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "headers_to_split_on_reformat = [\n",
    "    (\"#\", \"Category\"),\n",
    "    (\"##\", \"Subcategory\"),\n",
    "    (\"###\", \"Question\"),\n",
    "    (\"####\", \"Subquestion\"),\n",
    "    (\"#####\", \"Subsubquestion\"),\n",
    "    (\"######\", \"URL\"),\n",
    "    (\"#######\",\"ID\"), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Vector store and basic retrievers\n",
    "In this section there are models that probably are not necessary given the way in which retrievers work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(path_full_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_full_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_full_ref = vs_full_ref.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# oth\n",
    "\n",
    "with open(path_housing_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_house_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_house_ref = vs_house_ref.as_retriever()\n",
    "###\n",
    "\n",
    "with open(path_fees_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_fees_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_fees_ref = vs_fees_ref.as_retriever()\n",
    "\n",
    "with open(path_funding_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_funding_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_funding_ref = vs_funding_ref.as_retriever()\n",
    "\n",
    "with open(path_oth_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_oth_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_oth_ref = vs_oth_ref.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Plain vector stores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#oth \n",
    "\n",
    "with open(path_housing_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_house_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_house_plain = vs_house_plain.as_retriever()\n",
    "\n",
    "with open(path_fees_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_fees_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_fees_plain = vs_fees_plain.as_retriever()\n",
    "\n",
    "with open(path_funding_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_funding_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_fudning_plain = vs_funding_plain.as_retriever()\n",
    "\n",
    "with open(path_exc_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_exc_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_exc_plain = vs_exc_plain.as_retriever()\n",
    "\n",
    "\n",
    "with open(path_oth_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_oth_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_oth_plain = vs_oth_plain.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Self retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# self_full_ref\n",
    "metadata_field_info_ref = [\n",
    "    AttributeInfo(\n",
    "        name=\"Category\",\n",
    "        description=\"a primary category or a general topic. It introduces the broader theme under which more specific information is grouped. In a retrieval task, it acts as the first level of data filtering or organization, offering a broad overview of the context or subject area.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Subcategory\",\n",
    "        description=\"This is a subtheme or subcategory of Header 1. It provides a further level of detail, focusing on a specific aspect of the main theme. It serves to refine the search or understanding within the general topic defined by Header 1, guiding the user towards more targeted information.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Question\",\n",
    "        description=\"This represents an even more specific subdivision of Header 2. This level contains the actual question. In a retrieval task, this header helps to focus on a very specific question, making the search even more targeted. \",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Subquestion\",\n",
    "        description=\"For questions which are represented by multiple section,it serves to direct the user or the retrieval system towards a highly detailed and specific answer or information. It's the level that directly responds to the user's questions or needs. Oftentime is defined as General as a placeholder. \",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "        AttributeInfo(\n",
    "        name=\"Subsubquestion\",\n",
    "        description=\"This is the most specific level, is used in case of further and specific details. In most of the cases is defined as general as a placeholder\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "        AttributeInfo(\n",
    "        name=\"URL\",\n",
    "        description=\"A reference to the URL from which the Question has been obtained. It is not relevant in any way for retrieving\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"ID\",\n",
    "        description=\"A reference to the specific question. It is not relevant in any way for retrieving\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "self_full_ref = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vs_full_ref,\n",
    "    document_content_description, #\n",
    "    metadata_field_info_ref,          #\n",
    "    verbose= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "self_house_ref = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vs_house_ref,\n",
    "    document_content_description, #\n",
    "    metadata_field_info,          #\n",
    "    verbose= True\n",
    ")\n",
    "self_house_plain = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vs_house_plain,\n",
    "    document_content_description, #\n",
    "    metadata_field_info,          #\n",
    "    verbose= True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### 2.1.2 RETRIVAL_QA BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rqa_basic_house_ref = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=ret_house_ref,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "    tags = [\"base\", \"house\",\"refined\"]\n",
    ")\n",
    "\n",
    "rqa_basic_house_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=ret_house_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### 2.1.2 RETRIVAL_QA SELF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "rqa_self_house_ref = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_house_ref,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    ")\n",
    "\n",
    "rqa_self_house_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_house_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "\n",
    "rqa_self_full_ref = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_full_ref,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "\n",
    "rqa_self_full_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_full_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# --- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.7. Langchain evaluation \n",
    "To access the results from the dashboard you can use the folowing [link](https://smith.langchain.com/o/917d7cd4-4420-5477-8a36-902a60673259/projects?paginationState=%7B%22pageIndex%22%3A0%2C%22pageSize%22%3A10%7D&chartedColumn=latency_p50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1.7.1. Single question eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rqa_self.invoke(\"Who are the student representatives?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Memory and Sourcing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.1. Memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True \n",
    ")\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "retriever=vectorstore.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# New type of chain: It adds a new bit on top that allows for keeping chat history and new question creating a ew standalone question  \n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "retriever=vectorstore.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "question = \"Quali sono le dotazioni disponibili all'interno delle camere? \"\n",
    "result = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result[\"answer\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "question = \"Per quanto riguarda la cucina?\"\n",
    "result = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result[\"answer\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "question = \"Sono quindi comuni?\"\n",
    "result = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result[\"answer\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Comparison with model with no memory \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "qa_chain1.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2. Sourcing \n",
    "https://python.langchain.com/docs/use_cases/question_answering/sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)\n",
    "\n",
    "rag_chain_with_source.invoke(\"Cosa troverà nella stanza in residenza? \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Initialize Feedback Function(s)\n",
    "For iterations over different models\n",
    "N.B. in case of problems refer to the langchain_quickstart in this folder, or to: [Optimize RAG application - Trulens](https://colab.research.google.com/drive/1bjplY8jIUYtkiKzM4tXmZ5U5U10BaiCd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from trulens_eval import TruChain, Feedback, Huggingface, Tru\n",
    "from trulens_eval.schema import FeedbackResult\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from trulens_eval.feedback.provider import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "# Initialize provider class\n",
    "openai = OpenAI()\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "from trulens_eval.app import App\n",
    "context = App.select_context(rqa_base)\n",
    "\n",
    "from trulens_eval.feedback import Groundedness\n",
    "grounded = Groundedness(groundedness_provider=OpenAI())\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons)\n",
    "    .on(context.collect()) # collect context chunks into a list\n",
    "    .on_output()\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = Feedback(openai.relevance).on_input_output()\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(openai.qs_relevance)\n",
    "    .on_input()\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.1 Instrument chain for logging with TruLens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#OK \n",
    "tru_recorder = TruChain(rqa_base,\n",
    "    app_id='Chain1_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with tru_recorder as recording:\n",
    "    llm_response = rqa_base.invoke(\"Come funziona l'ingresso in residenza\")\n",
    "\n",
    "print(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rqa_base.invoke(\"Come funziona l'ingresso in residenza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru_recorder2 = TruChain(rqa_compressed,\n",
    "    app_id='Chain2_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])\n",
    "\n",
    "with tru_recorder2 as recording:\n",
    "    llm_response = rqa_compressed.invoke(\"What is the purpose of the source?\")\n",
    "\n",
    "display(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tru_recorder3 = TruChain(self_retriever,\n",
    "    app_id='ChainSelf_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])\n",
    "\n",
    "tru_recorder4 = TruChain(multi_retriever,\n",
    "    app_id='Chainmulti_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.2 Retrieve records and feedback (single question) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The record of the app invocation can be retrieved from the `recording`:\n",
    "\n",
    "rec = recording.get() # use .get if only one record\n",
    "#recs = recording.records # use .records if multiple\n",
    "\n",
    "#display(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The results of the feedback functions can be rertireved from the record. These\n",
    "# are `Future` instances (see `concurrent.futures`). You can use `as_completed`\n",
    "# to wait until they have finished evaluating.\n",
    "\n",
    "from concurrent.futures import as_completed\n",
    "\n",
    "for feedback_future in  as_completed(rec.feedback_results):\n",
    "    feedback, feedback_result = feedback_future.result()\n",
    "\n",
    "    feedback: Feedback\n",
    "    feedbac_result: FeedbackResult\n",
    "\n",
    "    display(feedback.name, feedback_result.result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[\"Chain1_ChatApplication\"])\n",
    "\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[\"Chain2_ChatApplication\"])\n",
    "\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.3. Multiple questions evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        print(item)\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder as recording:\n",
    "        rag_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "self_retriever.invoke(\"Vorrei prenotare un alloggio a tariffa intera per l'a.a. 2023-24. Come posso procedere?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder3 as recording:\n",
    "        self_retriever.invoke(question)\n",
    "        \n",
    "        #__record__.app.first.steps.context.first.get_relevant_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder4 as recording:\n",
    "        self_retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder2 as recording:\n",
    "        rag_chain_compressed.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "records[[\"input\", \"output\"] + feedback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.4. Explore in a Dashboard\n",
    "For reference see the following [link](https://www.trulens.org/trulens_eval/api/tru/#trulens_eval.trulens_eval.tru.Tru)\n",
    "def run_dashboard(\n",
    "        self,\n",
    "        port: Optional[int] = 8501,\n",
    "        address: Optional[str] = None,\n",
    "        force: bool = False,\n",
    "        _dev: Optional[Path] = None\n",
    "    ) -> Process:\n",
    "        \"\"\"\n",
    "        Run a streamlit dashboard to view logged results and apps.\n",
    "\n",
    "        Args:\n",
    "            - port: int: port number to pass to streamlit through server.port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru = Tru()\n",
    "#tru.reset_database()\n",
    "tru.run_dashboard(port = 8503) # open a local streamlit app to explore\n",
    "\n",
    "# tru.stop_dashboard() # stop if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conda activate aienv\n",
    "cd Finetuning/BOT_V3_Langchain  \n",
    "# PORT problem solved by chainging the port number in tru.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note: Feedback functions evaluated in the deferred manner can be seen in the \"Progress\" page of the TruLens dashboard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# the recorder is initialized as prebuilt we will need some more lessons to undertand how to actually implemet \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The results of the feedback functions can be rertireved from the record. These\n",
    "# are `Future` instances (see `concurrent.futures`). You can use `as_completed`\n",
    "# to wait until they have finished evaluating.\n",
    "\n",
    "from concurrent.futures import as_completed\n",
    "\n",
    "for feedback_future in  as_completed(rec.feedback_results):\n",
    "    feedback, feedback_result = feedback_future.result()\n",
    "\n",
    "    feedback: Feedback\n",
    "    feedbac_result: FeedbackResult\n",
    "\n",
    "    display(feedback.name, feedback_result.result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[\"Chain1_ChatApplication\"])\n",
    "\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[\"Chain2_ChatApplication\"])\n",
    "\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.3. Multiple questions evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        print(item)\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder as recording:\n",
    "        rag_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "self_retriever.invoke(\"Vorrei prenotare un alloggio a tariffa intera per l'a.a. 2023-24. Come posso procedere?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder3 as recording:\n",
    "        self_retriever.invoke(question)\n",
    "        \n",
    "        #__record__.app.first.steps.context.first.get_relevant_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder4 as recording:\n",
    "        self_retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder2 as recording:\n",
    "        rag_chain_compressed.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "records[[\"input\", \"output\"] + feedback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.4. Explore in a Dashboard\n",
    "For reference see the following [link](https://www.trulens.org/trulens_eval/api/tru/#trulens_eval.trulens_eval.tru.Tru)\n",
    "def run_dashboard(\n",
    "        self,\n",
    "        port: Optional[int] = 8501,\n",
    "        address: Optional[str] = None,\n",
    "        force: bool = False,\n",
    "        _dev: Optional[Path] = None\n",
    "    ) -> Process:\n",
    "        \"\"\"\n",
    "        Run a streamlit dashboard to view logged results and apps.\n",
    "\n",
    "        Args:\n",
    "            - port: int: port number to pass to streamlit through server.port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru = Tru()\n",
    "#tru.reset_database()\n",
    "tru.run_dashboard(port = 8503) # open a local streamlit app to explore\n",
    "\n",
    "# tru.stop_dashboard() # stop if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conda activate aienv\n",
    "cd Finetuning/BOT_V3_Langchain  \n",
    "# PORT problem solved by chainging the port number in tru.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note: Feedback functions evaluated in the deferred manner can be seen in the \"Progress\" page of the TruLens dashboard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# the recorder is initialized as prebuilt we will need some more lessons to undertand how to actually implemet \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RunnableBinding' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrqa_basic_full_ref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m(file_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/rqa_basic_full_ref.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RunnableBinding' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "rqa_basic_full_ref.save(file_path=\"models/rqa_basic_full_ref.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Union\n",
    "\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chain = RetrievalQA.load(\"models/rqa_basic_full_ref.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = langchain.chains.loading.load_chain(\"models/rqa_basic_full_ref.yaml\", retriever=ret_full_ref)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = langchain.chains.loading.load_chain_from_file(\"models/rqa_basic_full_ref.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain.chains.loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo pip install langchain --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. MODEL COMPARISONS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 2.1. COMPARISON ON RETRIVALQA \n",
    "We will use ceteris paribus for evaluating which on is the best model. \n",
    "We will choose the best model in Retrival_QA setting. \n",
    "We want to investigate: \n",
    "1. HOW DO THE MODEL PERFORM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Trulens troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
      "To initialize your shell, run\n",
      "\n",
      "    $ conda init <SHELL_NAME>\n",
      "\n",
      "Currently supported shells are:\n",
      "  - bash\n",
      "  - fish\n",
      "  - tcsh\n",
      "  - xonsh\n",
      "  - zsh\n",
      "  - powershell\n",
      "\n",
      "See 'conda init --help' for more information and options.\n",
      "\n",
      "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
      "\n",
      "\n",
      "zsh:cd:1: no such file or directory: Finetuning/BOT_V3_Langchain\n"
     ]
    }
   ],
   "source": [
    "# terminal commands \n",
    "conda activate aienv\n",
    "cd Finetuning/BOT_V3_Langchain  \n",
    "# PORT problem solved by chainging the port number in /Users/valedipalo/miniforge3/lib/python3.9/site-packages/tru.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note: Feedback functions evaluated in the deferred manner can be seen in the \"Progress\" page of the TruLens dashboard.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Comparison\n",
    "## 3.1. Amount of data \n",
    "How do the model perform based on the amount of datas we are giving into. \n",
    "To do so we will evaluate with a basic retriever \n",
    "1. rqa_basic_house_ref VS rqa_basic_full_ref \n",
    "2. rqa_basic_house_plain VS rqa_basic_full_plain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.2 Importance of Data Cleaning \n",
    "We will evaluate how much structuring data is relevant for the models to properly work. \n",
    "To do so we will evaluate the performance for \n",
    "1. rqa_basic_house_ref VS rqa_basic_house_plain\n",
    "2. rqa_basic_full_ref VS rqa_basic_full_plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.3 How much is important the retriever \n",
    "The same tests will be done with the self retriever to evaluate if it is performing better or worse than the Basic one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.4. Different chains \n",
    "Once determined the bes scoring from previous test, we will evaluate different chains and how do they perform using \n",
    "- RetrivalQA\n",
    "- MAPreduce \n",
    "- MAPrerank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# determining eval question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rqa_basic_full_plain.invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST EVAL_QUESTIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Function to invoke models\n",
    "def invoke_model_with_inputs(models,model, inputs):\n",
    "    print(f\"🤖 starting execution of the model: {model}\") \n",
    "    result = models[model].invoke(inputs)\n",
    "    return result\n",
    "\n",
    "# Map model names to instances\n",
    "models_basic = {\n",
    "    \"rqa_basic_house_ref\": rqa_basic_house_ref,\n",
    "    \"rqa_basic_house_plain\": rqa_basic_house_plain,\n",
    "    \"rqa_basic_full_ref\": rqa_basic_full_ref,\n",
    "    \"rqa_basic_full_plain\": rqa_basic_full_plain,\n",
    "}\n",
    "\n",
    "models_self = {\n",
    "    \"rqa_self_house_ref\": rqa_self_house_ref,\n",
    "    \"rqa_self_house_plain\": rqa_self_house_plain,\n",
    "    \"rqa_self_full_ref\": rqa_self_full_ref,\n",
    "    \"rqa_self_full_plain\": rqa_self_full_plain,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 starting execution of the model: rqa_basic_house_ref\n",
      "{'query': 'Does Bocconi has a Medical Center?', 'result': \"Yes, Bocconi University has a medical clinic located on the mezzanine floor of the Piazza Sraffa 11 building. It is available to members of the Bocconi Community (Students, Faculty, and Staff) on Mondays, Wednesdays, and Fridays from 9:00am to 2:00pm. Access to the service is preferably by reservation, and you can make a reservation by calling +39 02 03009152 or sending an email to ambulatorio.bocconi@mc.humanitas.it. Outside of these hours, there is no telephone availability. For more information, you can refer to the [provided link](https://agenda.unibocconi.it/documenti/allegati/Bocconi__flyer_Campus_Doctor_English20230427171203.pdf). If you need any further information, don't hesitate to ask!\", 'source_documents': [Document(page_content='A nursing service is available at Euromedica, a health center very close to Bocconi campus, by paying a yearly subscription of 12 euro (Mondays through Fridays from 9:00am to 1:00pm, no appointment required). In case you need to see a general practitioner, the ISD staff will provide you with a list of English-speaking doctors.\\nBocconi University also has a medical clinic, located on the mezzanine floor of the Piazza Sraffa 11 building and available to members of the Bocconi Community (Students, Faculty and Staff) Mondays, Wednesdays and Fridays from 9:00am to 2:00pm. There is no telephone availability outside these hours. Access to the service is preferably by reservation, by calling +39 02 03009152 (Organizational Office open from 9:00am to 5:30pm Mondays through Fridays), or by sending an email to:\\xa0ambulatorio.bocconi@mc.humanitas.it.\\nMore information is available\\xa0[here](https://agenda.unibocconi.it/documenti/allegati/Bocconi__flyer_Campus_Doctor_English20230427171203.pdf).', metadata={'Category': 'Incoming Exchange Program', 'ID': '174', 'Question': 'Does the University have a medical center?', 'Subcategory': 'During your stay', 'URL': 'https://bit.unibocconi.it/hc/en-us/articles/4404734360722-Does-the-University-have-a-medical-center'}), Document(page_content='A nursing service is available at Euromedica, a health center very close to Bocconi campus, by paying a yearly subscription of 12 euro (Mondays through Fridays from 9:00am to 1:00pm, no appointment required). In case you need to see a general practitioner, the ISD staff will provide you with a list of English-speaking doctors.\\nBocconi University also has a medical clinic, located on the mezzanine floor of the Piazza Sraffa 11 building and available to members of the Bocconi Community (Students, Faculty and Staff) Mondays, Wednesdays and Fridays from 9:00am to 2:00pm. There is no telephone availability outside these hours. Access to the service is preferably by reservation, by calling +39 02 03009152 (Organizational Office open from 9:00am to 5:30pm Mondays through Fridays), or by sending an email to:\\xa0ambulatorio.bocconi@mc.humanitas.it.\\nMore information is available\\xa0[here](https://agenda.unibocconi.it/documenti/allegati/Bocconi__flyer_Campus_Doctor_English20230427171203.pdf).', metadata={'Category': 'Incoming Exchange Program', 'ID': '174', 'Question': 'Does the University have a medical center?', 'Subcategory': 'During your stay', 'URL': 'https://bit.unibocconi.it/hc/en-us/articles/4404734360722-Does-the-University-have-a-medical-center'}), Document(page_content='A nursing service is available at Euromedica, a health center very close to Bocconi campus, by paying a yearly subscription of 12 euro (Mondays through Fridays from 9:00am to 1:00pm, no appointment required). In case you need to see a general practitioner, the ISD staff will provide you with a list of English-speaking doctors.\\nBocconi University also has a medical clinic, located on the mezzanine floor of the Piazza Sraffa 11 building and available to members of the Bocconi Community (Students, Faculty and Staff) Mondays, Wednesdays and Fridays from 9:00am to 2:00pm. There is no telephone availability outside these hours. Access to the service is preferably by reservation, by calling +39 02 03009152 (Organizational Office open from 9:00am to 5:30pm Mondays through Fridays), or by sending an email to:\\xa0ambulatorio.bocconi@mc.humanitas.it.\\nMore information is available\\xa0[here](https://agenda.unibocconi.it/documenti/allegati/Bocconi__flyer_Campus_Doctor_English20230427171203.pdf).', metadata={'Category': 'Incoming Exchange Program', 'ID': '174', 'Question': 'Does the University have a medical center?', 'Subcategory': 'During your stay', 'URL': 'https://bit.unibocconi.it/hc/en-us/articles/4404734360722-Does-the-University-have-a-medical-center'}), Document(page_content='A nursing service is available at Euromedica, a health center very close to Bocconi campus, by paying a yearly subscription of 12 euro (Mondays through Fridays from 9:00am to 1:00pm, no appointment required). In case you need to see a general practitioner, the ISD staff will provide you with a list of English-speaking doctors.\\nBocconi University also has a medical clinic, located on the mezzanine floor of the Piazza Sraffa 11 building and available to members of the Bocconi Community (Students, Faculty and Staff) Mondays, Wednesdays and Fridays from 9:00am to 2:00pm. There is no telephone availability outside these hours. Access to the service is preferably by reservation, by calling +39 02 03009152 (Organizational Office open from 9:00am to 5:30pm Mondays through Fridays), or by sending an email to:\\xa0ambulatorio.bocconi@mc.humanitas.it.\\nMore information is available\\xa0[here](https://agenda.unibocconi.it/documenti/allegati/Bocconi__flyer_Campus_Doctor_English20230427171203.pdf).', metadata={'Category': 'Incoming Exchange Program', 'ID': '174.0', 'Question': 'Does the University have a medical center?', 'Subcategory': 'During your stay', 'Subquestion': 'General', 'Subsubquestion': 'General', 'URL': 'https://bit.unibocconi.it/hc/en-us/articles/4404734360722-Does-the-University-have-a-medical-center'})]}\n",
      "--\n",
      "🤖 starting execution of the model: rqa_basic_house_plain\n",
      "{'query': 'Does Bocconi has a Medical Center?', 'result': \"Yes, Bocconi University has a medical clinic located on the mezzanine floor of the Piazza Sraffa 11 building. It is available to members of the Bocconi Community (Students, Faculty, and Staff) on Mondays, Wednesdays, and Fridays from 9:00am to 2:00pm. Access to the service is preferably by reservation, and you can make a reservation by calling +39 02 03009152 or sending an email to ambulatorio.bocconi@mc.humanitas.it. Outside of these hours, there is no telephone availability. For more information, you can refer to the [Bocconi Campus Doctor flyer](https://agenda.unibocconi.it/documenti/allegati/Bocconi__flyer_Campus_Doctor_English20230427171203.pdf). If you need any further information, don't hesitate to ask!\", 'source_documents': [Document(page_content='A nursing service is available at Euromedica, a health center very close to Bocconi campus, by paying a yearly subscription of 12 euro (Mondays through Fridays from 9:00am to 1:00pm, no appointment required). In case you need to see a general practitioner, the ISD staff will provide you with a list of English-speaking doctors.\\nBocconi University also has a medical clinic, located on the mezzanine floor of the Piazza Sraffa 11 building and available to members of the Bocconi Community (Students, Faculty and Staff) Mondays, Wednesdays and Fridays from 9:00am to 2:00pm. There is no telephone availability outside these hours. Access to the service is preferably by reservation, by calling +39 02 03009152 (Organizational Office open from 9:00am to 5:30pm Mondays through Fridays), or by sending an email to:\\xa0ambulatorio.bocconi@mc.humanitas.it.\\nMore information is available\\xa0[here](https://agenda.unibocconi.it/documenti/allegati/Bocconi__flyer_Campus_Doctor_English20230427171203.pdf).', metadata={'Category': 'Incoming Exchange Program', 'ID': '174', 'Question': 'Does the University have a medical center?', 'Subcategory': 'During your stay', 'URL': 'https://bit.unibocconi.it/hc/en-us/articles/4404734360722-Does-the-University-have-a-medical-center'}), Document(page_content='A nursing service is available at Euromedica, a health center very close to Bocconi campus, by paying a yearly subscription of 12 euro (Mondays through Fridays from 9:00am to 1:00pm, no appointment required). In case you need to see a general practitioner, the ISD staff will provide you with a list of English-speaking doctors.\\nBocconi University also has a medical clinic, located on the mezzanine floor of the Piazza Sraffa 11 building and available to members of the Bocconi Community (Students, Faculty and Staff) Mondays, Wednesdays and Fridays from 9:00am to 2:00pm. There is no telephone availability outside these hours. Access to the service is preferably by reservation, by calling +39 02 03009152 (Organizational Office open from 9:00am to 5:30pm Mondays through Fridays), or by sending an email to:\\xa0ambulatorio.bocconi@mc.humanitas.it.\\nMore information is available\\xa0[here](https://agenda.unibocconi.it/documenti/allegati/Bocconi__flyer_Campus_Doctor_English20230427171203.pdf).', metadata={'Category': 'Incoming Exchange Program', 'ID': '174', 'Question': 'Does the University have a medical center?', 'Subcategory': 'During your stay', 'URL': 'https://bit.unibocconi.it/hc/en-us/articles/4404734360722-Does-the-University-have-a-medical-center'}), Document(page_content='A nursing service is available at Euromedica, a health center very close to Bocconi campus, by paying a yearly subscription of 12 euro (Mondays through Fridays from 9:00am to 1:00pm, no appointment required). In case you need to see a general practitioner, the ISD staff will provide you with a list of English-speaking doctors.\\nBocconi University also has a medical clinic, located on the mezzanine floor of the Piazza Sraffa 11 building and available to members of the Bocconi Community (Students, Faculty and Staff) Mondays, Wednesdays and Fridays from 9:00am to 2:00pm. There is no telephone availability outside these hours. Access to the service is preferably by reservation, by calling +39 02 03009152 (Organizational Office open from 9:00am to 5:30pm Mondays through Fridays), or by sending an email to:\\xa0ambulatorio.bocconi@mc.humanitas.it.\\nMore information is available\\xa0[here](https://agenda.unibocconi.it/documenti/allegati/Bocconi__flyer_Campus_Doctor_English20230427171203.pdf).', metadata={'Category': 'Incoming Exchange Program', 'ID': '174', 'Question': 'Does the University have a medical center?', 'Subcategory': 'During your stay', 'URL': 'https://bit.unibocconi.it/hc/en-us/articles/4404734360722-Does-the-University-have-a-medical-center'}), Document(page_content='A nursing service is available at Euromedica, a health center very close to Bocconi campus, by paying a yearly subscription of 12 euro (Mondays through Fridays from 9:00am to 1:00pm, no appointment required). In case you need to see a general practitioner, the ISD staff will provide you with a list of English-speaking doctors.\\nBocconi University also has a medical clinic, located on the mezzanine floor of the Piazza Sraffa 11 building and available to members of the Bocconi Community (Students, Faculty and Staff) Mondays, Wednesdays and Fridays from 9:00am to 2:00pm. There is no telephone availability outside these hours. Access to the service is preferably by reservation, by calling +39 02 03009152 (Organizational Office open from 9:00am to 5:30pm Mondays through Fridays), or by sending an email to:\\xa0ambulatorio.bocconi@mc.humanitas.it.\\nMore information is available\\xa0[here](https://agenda.unibocconi.it/documenti/allegati/Bocconi__flyer_Campus_Doctor_English20230427171203.pdf).', metadata={'Category': 'Incoming Exchange Program', 'ID': '174.0', 'Question': 'Does the University have a medical center?', 'Subcategory': 'During your stay', 'Subquestion': 'General', 'Subsubquestion': 'General', 'URL': 'https://bit.unibocconi.it/hc/en-us/articles/4404734360722-Does-the-University-have-a-medical-center'})]}\n",
      "--\n",
      "🤖 starting execution of the model: rqa_basic_full_ref\n",
      "{'query': 'Does Bocconi has a Medical Center?', 'result': \"Yes, Bocconi University has a medical clinic located on the mezzanine floor of the Piazza Sraffa 11 building. It is available to members of the Bocconi Community (Students, Faculty, and Staff) on Mondays, Wednesdays, and Fridays from 9:00am to 2:00pm. Access to the service is preferably by reservation, and you can make a reservation by calling +39 02 03009152 or sending an email to ambulatorio.bocconi@mc.humanitas.it. Outside of these hours, there is no telephone availability. If you need any further information, don't hesitate to ask!\", 'source_documents': [Document(page_content='A nursing service is available at Euromedica, a health center very close to Bocconi campus, by paying a yearly subscription of 12 euro (Mondays through Fridays from 9:00am to 1:00pm, no appointment required). In case you need to see a general practitioner, the ISD staff will provide you with a list of English-speaking doctors.\\nBocconi University also has a medical clinic, located on the mezzanine floor of the Piazza Sraffa 11 building and available to members of the Bocconi Community (Students, Faculty and Staff) Mondays, Wednesdays and Fridays from 9:00am to 2:00pm. There is no telephone availability outside these hours. Access to the service is preferably by reservation, by calling +39 02 03009152 (Organizational Office open from 9:00am to 5:30pm Mondays through Fridays), or by sending an email to:\\xa0ambulatorio.bocconi@mc.humanitas.it.\\nMore information is available\\xa0[here](https://agenda.unibocconi.it/documenti/allegati/Bocconi__flyer_Campus_Doctor_English20230427171203.pdf).', metadata={'Category': 'Incoming Exchange Program', 'ID': '174', 'Question': 'Does the University have a medical center?', 'Subcategory': 'During your stay', 'URL': 'https://bit.unibocconi.it/hc/en-us/articles/4404734360722-Does-the-University-have-a-medical-center'}), Document(page_content='A nursing service is available at Euromedica, a health center very close to Bocconi campus, by paying a yearly subscription of 12 euro (Mondays through Fridays from 9:00am to 1:00pm, no appointment required). In case you need to see a general practitioner, the ISD staff will provide you with a list of English-speaking doctors.\\nBocconi University also has a medical clinic, located on the mezzanine floor of the Piazza Sraffa 11 building and available to members of the Bocconi Community (Students, Faculty and Staff) Mondays, Wednesdays and Fridays from 9:00am to 2:00pm. There is no telephone availability outside these hours. Access to the service is preferably by reservation, by calling +39 02 03009152 (Organizational Office open from 9:00am to 5:30pm Mondays through Fridays), or by sending an email to:\\xa0ambulatorio.bocconi@mc.humanitas.it.\\nMore information is available\\xa0[here](https://agenda.unibocconi.it/documenti/allegati/Bocconi__flyer_Campus_Doctor_English20230427171203.pdf).', metadata={'Category': 'Incoming Exchange Program', 'ID': '174', 'Question': 'Does the University have a medical center?', 'Subcategory': 'During your stay', 'URL': 'https://bit.unibocconi.it/hc/en-us/articles/4404734360722-Does-the-University-have-a-medical-center'}), Document(page_content='A nursing service is available at Euromedica, a health center very close to Bocconi campus, by paying a yearly subscription of 12 euro (Mondays through Fridays from 9:00am to 1:00pm, no appointment required). In case you need to see a general practitioner, the ISD staff will provide you with a list of English-speaking doctors.\\nBocconi University also has a medical clinic, located on the mezzanine floor of the Piazza Sraffa 11 building and available to members of the Bocconi Community (Students, Faculty and Staff) Mondays, Wednesdays and Fridays from 9:00am to 2:00pm. There is no telephone availability outside these hours. Access to the service is preferably by reservation, by calling +39 02 03009152 (Organizational Office open from 9:00am to 5:30pm Mondays through Fridays), or by sending an email to:\\xa0ambulatorio.bocconi@mc.humanitas.it.\\nMore information is available\\xa0[here](https://agenda.unibocconi.it/documenti/allegati/Bocconi__flyer_Campus_Doctor_English20230427171203.pdf).', metadata={'Category': 'Incoming Exchange Program', 'ID': '174', 'Question': 'Does the University have a medical center?', 'Subcategory': 'During your stay', 'URL': 'https://bit.unibocconi.it/hc/en-us/articles/4404734360722-Does-the-University-have-a-medical-center'}), Document(page_content='A nursing service is available at Euromedica, a health center very close to Bocconi campus, by paying a yearly subscription of 12 euro (Mondays through Fridays from 9:00am to 1:00pm, no appointment required). In case you need to see a general practitioner, the ISD staff will provide you with a list of English-speaking doctors.\\nBocconi University also has a medical clinic, located on the mezzanine floor of the Piazza Sraffa 11 building and available to members of the Bocconi Community (Students, Faculty and Staff) Mondays, Wednesdays and Fridays from 9:00am to 2:00pm. There is no telephone availability outside these hours. Access to the service is preferably by reservation, by calling +39 02 03009152 (Organizational Office open from 9:00am to 5:30pm Mondays through Fridays), or by sending an email to:\\xa0ambulatorio.bocconi@mc.humanitas.it.\\nMore information is available\\xa0[here](https://agenda.unibocconi.it/documenti/allegati/Bocconi__flyer_Campus_Doctor_English20230427171203.pdf).', metadata={'Category': 'Incoming Exchange Program', 'ID': '174.0', 'Question': 'Does the University have a medical center?', 'Subcategory': 'During your stay', 'Subquestion': 'General', 'Subsubquestion': 'General', 'URL': 'https://bit.unibocconi.it/hc/en-us/articles/4404734360722-Does-the-University-have-a-medical-center'})]}\n",
      "--\n",
      "🤖 starting execution of the model: rqa_basic_full_plain\n",
      "{'query': 'Does Bocconi has a Medical Center?', 'result': \"Yes, Bocconi University has a medical clinic located on the mezzanine floor of the Piazza Sraffa 11 building. It is available to members of the Bocconi Community (Students, Faculty, and Staff) on Mondays, Wednesdays, and Fridays from 9:00am to 2:00pm. Access to the service is preferably by reservation, and you can make a reservation by calling +39 02 03009152 or sending an email to ambulatorio.bocconi@mc.humanitas.it. Outside of these hours, there is no telephone availability. For more information, you can refer to the [provided link](https://agenda.unibocconi.it/documenti/allegati/Bocconi__flyer_Campus_Doctor_English20230427171203.pdf). If you need any further information, don't hesitate to ask!\", 'source_documents': [Document(page_content='A nursing service is available at Euromedica, a health center very close to Bocconi campus, by paying a yearly subscription of 12 euro (Mondays through Fridays from 9:00am to 1:00pm, no appointment required). In case you need to see a general practitioner, the ISD staff will provide you with a list of English-speaking doctors.\\nBocconi University also has a medical clinic, located on the mezzanine floor of the Piazza Sraffa 11 building and available to members of the Bocconi Community (Students, Faculty and Staff) Mondays, Wednesdays and Fridays from 9:00am to 2:00pm. There is no telephone availability outside these hours. Access to the service is preferably by reservation, by calling +39 02 03009152 (Organizational Office open from 9:00am to 5:30pm Mondays through Fridays), or by sending an email to:\\xa0ambulatorio.bocconi@mc.humanitas.it.\\nMore information is available\\xa0[here](https://agenda.unibocconi.it/documenti/allegati/Bocconi__flyer_Campus_Doctor_English20230427171203.pdf).', metadata={'Category': 'Incoming Exchange Program', 'ID': '174', 'Question': 'Does the University have a medical center?', 'Subcategory': 'During your stay', 'URL': 'https://bit.unibocconi.it/hc/en-us/articles/4404734360722-Does-the-University-have-a-medical-center'}), Document(page_content='A nursing service is available at Euromedica, a health center very close to Bocconi campus, by paying a yearly subscription of 12 euro (Mondays through Fridays from 9:00am to 1:00pm, no appointment required). In case you need to see a general practitioner, the ISD staff will provide you with a list of English-speaking doctors.\\nBocconi University also has a medical clinic, located on the mezzanine floor of the Piazza Sraffa 11 building and available to members of the Bocconi Community (Students, Faculty and Staff) Mondays, Wednesdays and Fridays from 9:00am to 2:00pm. There is no telephone availability outside these hours. Access to the service is preferably by reservation, by calling +39 02 03009152 (Organizational Office open from 9:00am to 5:30pm Mondays through Fridays), or by sending an email to:\\xa0ambulatorio.bocconi@mc.humanitas.it.\\nMore information is available\\xa0[here](https://agenda.unibocconi.it/documenti/allegati/Bocconi__flyer_Campus_Doctor_English20230427171203.pdf).', metadata={'Category': 'Incoming Exchange Program', 'ID': '174', 'Question': 'Does the University have a medical center?', 'Subcategory': 'During your stay', 'URL': 'https://bit.unibocconi.it/hc/en-us/articles/4404734360722-Does-the-University-have-a-medical-center'}), Document(page_content='A nursing service is available at Euromedica, a health center very close to Bocconi campus, by paying a yearly subscription of 12 euro (Mondays through Fridays from 9:00am to 1:00pm, no appointment required). In case you need to see a general practitioner, the ISD staff will provide you with a list of English-speaking doctors.\\nBocconi University also has a medical clinic, located on the mezzanine floor of the Piazza Sraffa 11 building and available to members of the Bocconi Community (Students, Faculty and Staff) Mondays, Wednesdays and Fridays from 9:00am to 2:00pm. There is no telephone availability outside these hours. Access to the service is preferably by reservation, by calling +39 02 03009152 (Organizational Office open from 9:00am to 5:30pm Mondays through Fridays), or by sending an email to:\\xa0ambulatorio.bocconi@mc.humanitas.it.\\nMore information is available\\xa0[here](https://agenda.unibocconi.it/documenti/allegati/Bocconi__flyer_Campus_Doctor_English20230427171203.pdf).', metadata={'Category': 'Incoming Exchange Program', 'ID': '174', 'Question': 'Does the University have a medical center?', 'Subcategory': 'During your stay', 'URL': 'https://bit.unibocconi.it/hc/en-us/articles/4404734360722-Does-the-University-have-a-medical-center'}), Document(page_content='A nursing service is available at Euromedica, a health center very close to Bocconi campus, by paying a yearly subscription of 12 euro (Mondays through Fridays from 9:00am to 1:00pm, no appointment required). In case you need to see a general practitioner, the ISD staff will provide you with a list of English-speaking doctors.\\nBocconi University also has a medical clinic, located on the mezzanine floor of the Piazza Sraffa 11 building and available to members of the Bocconi Community (Students, Faculty and Staff) Mondays, Wednesdays and Fridays from 9:00am to 2:00pm. There is no telephone availability outside these hours. Access to the service is preferably by reservation, by calling +39 02 03009152 (Organizational Office open from 9:00am to 5:30pm Mondays through Fridays), or by sending an email to:\\xa0ambulatorio.bocconi@mc.humanitas.it.\\nMore information is available\\xa0[here](https://agenda.unibocconi.it/documenti/allegati/Bocconi__flyer_Campus_Doctor_English20230427171203.pdf).', metadata={'Category': 'Incoming Exchange Program', 'ID': '174.0', 'Question': 'Does the University have a medical center?', 'Subcategory': 'During your stay', 'Subquestion': 'General', 'Subsubquestion': 'General', 'URL': 'https://bit.unibocconi.it/hc/en-us/articles/4404734360722-Does-the-University-have-a-medical-center'})]}\n",
      "--\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rqa_basic_house_ref</td>\n",
       "      <td>Does Bocconi has a Medical Center?</td>\n",
       "      <td>Yes, Bocconi University has a medical clinic l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rqa_basic_house_plain</td>\n",
       "      <td>Does Bocconi has a Medical Center?</td>\n",
       "      <td>Yes, Bocconi University has a medical clinic l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rqa_basic_full_ref</td>\n",
       "      <td>Does Bocconi has a Medical Center?</td>\n",
       "      <td>Yes, Bocconi University has a medical clinic l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rqa_basic_full_plain</td>\n",
       "      <td>Does Bocconi has a Medical Center?</td>\n",
       "      <td>Yes, Bocconi University has a medical clinic l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model Name                            Question  \\\n",
       "0    rqa_basic_house_ref  Does Bocconi has a Medical Center?   \n",
       "1  rqa_basic_house_plain  Does Bocconi has a Medical Center?   \n",
       "2     rqa_basic_full_ref  Does Bocconi has a Medical Center?   \n",
       "3   rqa_basic_full_plain  Does Bocconi has a Medical Center?   \n",
       "\n",
       "                                              Answer  \n",
       "0  Yes, Bocconi University has a medical clinic l...  \n",
       "1  Yes, Bocconi University has a medical clinic l...  \n",
       "2  Yes, Bocconi University has a medical clinic l...  \n",
       "3  Yes, Bocconi University has a medical clinic l...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the question to ask to the model\n",
    "question = \"Does Bocconi has a Medical Center?\" \n",
    "\n",
    "# Initialize an empty list to collect data\n",
    "data = []\n",
    "\n",
    "# Iterate over your models dictionary and invoke them\n",
    "for model_name, model_instance in models_basic.items():\n",
    "    # Invoke the model with a question and get the result\n",
    "    result = invoke_model_with_inputs(models_basic,model_name, question)\n",
    "    print(result)#\n",
    "    print(\"--\")#\n",
    "\n",
    "    # Extract the question and answer from the result\n",
    "    question_asked = result[\"query\"]\n",
    "    answer_received = result[\"result\"]\n",
    "    \n",
    "    # Append a dictionary with model name, question, and answer to the data list\n",
    "    data.append({\"Model Name\": model_name, \"Question\": question_asked, \"Answer\": answer_received})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---\n",
    "# Model appendix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATHS \n",
    "path_fees_r = \"../../Data/New/Markdown/Fees_reformat.md\"\n",
    "path_full_r = \"../../Data/New/Markdown/Full_reformat.md\"\n",
    "path_funding_r = \"../../Data/New/Markdown/Funding_reformat.md\"\n",
    "path_housing_r = \"../../Data/New/Markdown/Housing_reformat.md\"\n",
    "path_oth_r = \"../../Data/New/Markdown/Library-Freemover_DD_reformat.md\"\n",
    "#plain \n",
    "path_fees_p = \"../../Data/New/Markdown/Fees_plain.md\"\n",
    "path_funding_p = \"../../Data/New/Markdown/Funding_plain.md\"\n",
    "path_housing_p = \"../../Data/New/Markdown/Housing_plain.md\"\n",
    "path_exc_p = \"../../Data/New/Markdown/Incoming-Exc_plain.md\"\n",
    "path_oth_p = \"../../Data/New/Markdown/Library-Freemover-DD_plain.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on_reformat = [\n",
    "    (\"#\", \"Category\"),\n",
    "    (\"##\", \"Subcategory\"),\n",
    "    (\"###\", \"Question\"),\n",
    "    (\"####\", \"Subquestion\"),\n",
    "    (\"#####\", \"Subsubquestion\"),\n",
    "    (\"######\", \"URL\"),\n",
    "    (\"#######\",\"ID\"), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector store and basic retrievers\n",
    "In this section there are models that probably are not necessary given the way in which retrievers work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_full_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_full_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_full_ref = vs_full_ref.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oth\n",
    "\n",
    "with open(path_housing_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_house_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_house_ref = vs_house_ref.as_retriever()\n",
    "###\n",
    "\n",
    "with open(path_fees_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_fees_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_fees_ref = vs_fees_ref.as_retriever()\n",
    "\n",
    "with open(path_funding_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_funding_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_funding_ref = vs_funding_ref.as_retriever()\n",
    "\n",
    "with open(path_oth_r, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_reformat)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_oth_ref = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_oth_ref = vs_oth_ref.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Plain vector stores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#oth \n",
    "\n",
    "with open(path_housing_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_house_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_house_plain = vs_house_plain.as_retriever()\n",
    "\n",
    "with open(path_fees_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_fees_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_fees_plain = vs_fees_plain.as_retriever()\n",
    "\n",
    "with open(path_funding_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_funding_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_fudning_plain = vs_funding_plain.as_retriever()\n",
    "\n",
    "with open(path_exc_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_exc_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_exc_plain = vs_exc_plain.as_retriever()\n",
    "\n",
    "\n",
    "with open(path_oth_p, 'r') as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on_plain)\n",
    "splits = markdown_splitter.split_text(markdown_content)\n",
    "vs_oth_plain = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "ret_oth_plain = vs_oth_plain.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self_full_ref\n",
    "metadata_field_info_ref = [\n",
    "    AttributeInfo(\n",
    "        name=\"Category\",\n",
    "        description=\"a primary category or a general topic. It introduces the broader theme under which more specific information is grouped. In a retrieval task, it acts as the first level of data filtering or organization, offering a broad overview of the context or subject area.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Subcategory\",\n",
    "        description=\"This is a subtheme or subcategory of Header 1. It provides a further level of detail, focusing on a specific aspect of the main theme. It serves to refine the search or understanding within the general topic defined by Header 1, guiding the user towards more targeted information.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Question\",\n",
    "        description=\"This represents an even more specific subdivision of Header 2. This level contains the actual question. In a retrieval task, this header helps to focus on a very specific question, making the search even more targeted. \",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"Subquestion\",\n",
    "        description=\"For questions which are represented by multiple section,it serves to direct the user or the retrieval system towards a highly detailed and specific answer or information. It's the level that directly responds to the user's questions or needs. Oftentime is defined as General as a placeholder. \",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "        AttributeInfo(\n",
    "        name=\"Subsubquestion\",\n",
    "        description=\"This is the most specific level, is used in case of further and specific details. In most of the cases is defined as general as a placeholder\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "        AttributeInfo(\n",
    "        name=\"URL\",\n",
    "        description=\"A reference to the URL from which the Question has been obtained. It is not relevant in any way for retrieving\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"ID\",\n",
    "        description=\"A reference to the specific question. It is not relevant in any way for retrieving\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "self_full_ref = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vs_full_ref,\n",
    "    document_content_description, #\n",
    "    metadata_field_info_ref,          #\n",
    "    verbose= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_house_ref = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vs_house_ref,\n",
    "    document_content_description, #\n",
    "    metadata_field_info,          #\n",
    "    verbose= True\n",
    ")\n",
    "self_house_plain = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vs_house_plain,\n",
    "    document_content_description, #\n",
    "    metadata_field_info,          #\n",
    "    verbose= True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.2 RETRIVAL_QA BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rqa_basic_house_ref = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=ret_house_ref,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "    tags = [\"base\", \"house\",\"refined\"]\n",
    ")\n",
    "\n",
    "rqa_basic_house_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=ret_house_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### 2.1.2 RETRIVAL_QA SELF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self_house_ref' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      2\u001b[0m rqa_self_house_ref \u001b[38;5;241m=\u001b[39m RetrievalQA\u001b[38;5;241m.\u001b[39mfrom_chain_type(\n\u001b[1;32m      3\u001b[0m     llm,\n\u001b[0;32m----> 4\u001b[0m     retriever\u001b[38;5;241m=\u001b[39m\u001b[43mself_house_ref\u001b[49m,\n\u001b[1;32m      5\u001b[0m     return_source_documents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     chain_type_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: QA_CHAIN_PROMPT},\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m rqa_self_house_plain \u001b[38;5;241m=\u001b[39m RetrievalQA\u001b[38;5;241m.\u001b[39mfrom_chain_type(\n\u001b[1;32m     10\u001b[0m     llm,\n\u001b[1;32m     11\u001b[0m     retriever\u001b[38;5;241m=\u001b[39mself_house_plain,\n\u001b[1;32m     12\u001b[0m     return_source_documents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m     chain_type_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: QA_CHAIN_PROMPT}\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m rqa_self_full_ref \u001b[38;5;241m=\u001b[39m RetrievalQA\u001b[38;5;241m.\u001b[39mfrom_chain_type(\n\u001b[1;32m     17\u001b[0m     llm,\n\u001b[1;32m     18\u001b[0m     retriever\u001b[38;5;241m=\u001b[39mself_full_ref,\n\u001b[1;32m     19\u001b[0m     return_source_documents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m     chain_type_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: QA_CHAIN_PROMPT}\n\u001b[1;32m     21\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self_house_ref' is not defined"
     ]
    }
   ],
   "source": [
    "#\n",
    "rqa_self_house_ref = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_house_ref,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    ")\n",
    "\n",
    "rqa_self_house_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_house_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "\n",
    "rqa_self_full_ref = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_full_ref,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "\n",
    "rqa_self_full_plain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=self_full_plain,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.7. Langchain evaluation \n",
    "To access the results from the dashboard you can use the folowing [link](https://smith.langchain.com/o/917d7cd4-4420-5477-8a36-902a60673259/projects?paginationState=%7B%22pageIndex%22%3A0%2C%22pageSize%22%3A10%7D&chartedColumn=latency_p50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1.7.1. Single question eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Who are the student representatives?',\n",
       " 'result': \"The current student representatives for the Bocconi Residence Halls are:\\n- BLIGNY: Benedetta Scarcelli, Paolo Versini\\n- BOCCONI: Alessandro Pacitto, Gabriele Stella\\n- CASTIGLIONI: Giuseppe Greco, Ernesto Nocerino\\n- DUBINI: Francesco Salvatore Panarisi, Giulio Vitale\\n- ISONZO: Giuseppe Savona, Martina Violi\\n- JAVOTTE: Giorgio Armillis, Michele Lo Buono\\n- SPADOLINI: Michele Baretta, Mariano Benedetto\\n\\nIf you need any further information, don't hesitate to ask!\",\n",
       " 'source_documents': [Document(page_content='The residents of every Bocconi Residence Halls are given the right to elect\\xa0two Residence representatives\\xa0that will be their contact persons in the Residence and will manage their requests of use of the residents’ fund for free time activities. The current Residence representatives, in charge until September 2024, are listed below:\\nBLIGNY - Benedetta Scarcelli, Paolo Versini\\nBOCCONI - Alessandro Pacitto, Gabriele Stella\\nCASTIGLIONI - Giuseppe Greco, Ernesto Nocerino\\nDUBINI - Francesco Salvatore Panarisi, Giulio Vitale\\nISONZO - Giuseppe Savona, Martina Violi\\nJAVOTTE - Giorgio Armillis, Michele Lo Buono\\nSPADOLINI - Michele Baretta, Mariano Benedetto  \\nIf you are interested in filling the role of Residential Representative, you can refer to the regulations for the election of the Residential Representatives.\\nFurthermore, we suggest that you discuss in advance with the representatives in charge, to hear about their experience and fully understand the importance of the role.\\nThe election of the Residence representatives take place every year on the first Tuesday of October.\\nFor Election rules you can consult the following (document)[https://bit.unibocconi.it/hc/en-us/article_attachments/13835733684626]', metadata={'Category': 'Housing', 'ID': '18', 'Question': 'The residence representatives', 'Subcategory': 'Living in the residence halls', 'Subquestion': 'General', 'Subsubquestion': 'General', 'URL': 'https://bit.unibocconi.it/hc/en-us/articles/8867156235922-The-residence-representatives'}),\n",
       "  Document(page_content='The residents of every Bocconi Residence Halls are given the right to elect\\xa0two Residence representatives\\xa0that will be their contact persons in the Residence and will manage their requests of use of the residents’ fund for free time activities. The current Residence representatives, in charge until September 2024, are listed below:\\nBLIGNY - Benedetta Scarcelli, Paolo Versini\\nBOCCONI - Alessandro Pacitto, Gabriele Stella\\nCASTIGLIONI - Giuseppe Greco, Ernesto Nocerino\\nDUBINI - Francesco Salvatore Panarisi, Giulio Vitale\\nISONZO - Giuseppe Savona, Martina Violi\\nJAVOTTE - Giorgio Armillis, Michele Lo Buono\\nSPADOLINI - Michele Baretta, Mariano Benedetto  \\nIf you are interested in filling the role of Residential Representative, you can refer to the regulations for the election of the Residential Representatives.\\nFurthermore, we suggest that you discuss in advance with the representatives in charge, to hear about their experience and fully understand the importance of the role.\\nThe election of the Residence representatives take place every year on the first Tuesday of October.\\nFor Election rules you can consult the following (document)[https://bit.unibocconi.it/hc/en-us/article_attachments/13835733684626]', metadata={'Category': 'Housing', 'ID': '18', 'Question': 'The residence representatives', 'Subcategory': 'Living in the residence halls', 'Subquestion': 'General', 'Subsubquestion': 'General', 'URL': 'https://bit.unibocconi.it/hc/en-us/articles/8867156235922-The-residence-representatives'}),\n",
       "  Document(page_content='Below a summary of the main deadlines referred to the election of the Residence representatives.\\nMain deadlines:\\n>Submission of candidatures - By September, 20th.\\n>The complete list of candidates is sent to the Fees, Funding and Housing Office by the former residence representatives - September, 21st\\n>Election of the Residence representatives - 1st Tuesday of October  \\nFor Election rules you can consult the following (document)[https://bit.unibocconi.it/hc/en-us/article_attachments/13835733684626]', metadata={'Category': 'Housing', 'ID': '18', 'Question': 'The residence representatives', 'Subcategory': 'Living in the residence halls', 'Subquestion': 'Main Deadlines', 'Subsubquestion': 'General', 'URL': 'https://bit.unibocconi.it/hc/en-us/articles/8867156235922-The-residence-representatives'}),\n",
       "  Document(page_content='Below a summary of the main deadlines referred to the election of the Residence representatives.\\nMain deadlines:\\n>Submission of candidatures - By September, 20th.\\n>The complete list of candidates is sent to the Fees, Funding and Housing Office by the former residence representatives - September, 21st\\n>Election of the Residence representatives - 1st Tuesday of October  \\nFor Election rules you can consult the following (document)[https://bit.unibocconi.it/hc/en-us/article_attachments/13835733684626]', metadata={'Category': 'Housing', 'ID': '18', 'Question': 'The residence representatives', 'Subcategory': 'Living in the residence halls', 'Subquestion': 'Main Deadlines', 'Subsubquestion': 'General', 'URL': 'https://bit.unibocconi.it/hc/en-us/articles/8867156235922-The-residence-representatives'})]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rqa_self.invoke(\"Who are the student representatives?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Memory and Sourcing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.1. Memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True \n",
    ")\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "retriever=vectorstore.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# New type of chain: It adds a new bit on top that allows for keeping chat history and new question creating a ew standalone question  \n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "retriever=vectorstore.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "question = \"Quali sono le dotazioni disponibili all'interno delle camere? \"\n",
    "result = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result[\"answer\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "question = \"Per quanto riguarda la cucina?\"\n",
    "result = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result[\"answer\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "question = \"Sono quindi comuni?\"\n",
    "result = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result[\"answer\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Comparison with model with no memory \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "qa_chain1.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2. Sourcing \n",
    "https://python.langchain.com/docs/use_cases/question_answering/sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)\n",
    "\n",
    "rag_chain_with_source.invoke(\"Cosa troverà nella stanza in residenza? \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Initialize Feedback Function(s)\n",
    "For iterations over different models\n",
    "N.B. in case of problems refer to the langchain_quickstart in this folder, or to: [Optimize RAG application - Trulens](https://colab.research.google.com/drive/1bjplY8jIUYtkiKzM4tXmZ5U5U10BaiCd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from trulens_eval import TruChain, Feedback, Huggingface, Tru\n",
    "from trulens_eval.schema import FeedbackResult\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rqa_base' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# select context to be used in feedback. the location of context is app specific.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m App\n\u001b[0;32m----> 9\u001b[0m context \u001b[38;5;241m=\u001b[39m App\u001b[38;5;241m.\u001b[39mselect_context(\u001b[43mrqa_base\u001b[49m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeedback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Groundedness\n\u001b[1;32m     12\u001b[0m grounded \u001b[38;5;241m=\u001b[39m Groundedness(groundedness_provider\u001b[38;5;241m=\u001b[39mOpenAI())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rqa_base' is not defined"
     ]
    }
   ],
   "source": [
    "from trulens_eval.feedback.provider import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "# Initialize provider class\n",
    "openai = OpenAI()\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "from trulens_eval.app import App\n",
    "context = App.select_context(rqa_base)\n",
    "\n",
    "from trulens_eval.feedback import Groundedness\n",
    "grounded = Groundedness(groundedness_provider=OpenAI())\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons)\n",
    "    .on(context.collect()) # collect context chunks into a list\n",
    "    .on_output()\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = Feedback(openai.relevance).on_input_output()\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(openai.qs_relevance)\n",
    "    .on_input()\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.1 Instrument chain for logging with TruLens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#OK \n",
    "tru_recorder = TruChain(rqa_base,\n",
    "    app_id='Chain1_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with tru_recorder as recording:\n",
    "    llm_response = rqa_base.invoke(\"Come funziona l'ingresso in residenza\")\n",
    "\n",
    "print(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rqa_base.invoke(\"Come funziona l'ingresso in residenza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru_recorder2 = TruChain(rqa_compressed,\n",
    "    app_id='Chain2_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])\n",
    "\n",
    "with tru_recorder2 as recording:\n",
    "    llm_response = rqa_compressed.invoke(\"What is the purpose of the source?\")\n",
    "\n",
    "display(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tru_recorder3 = TruChain(self_retriever,\n",
    "    app_id='ChainSelf_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])\n",
    "\n",
    "tru_recorder4 = TruChain(multi_retriever,\n",
    "    app_id='Chainmulti_ChatApplication',\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.2 Retrieve records and feedback (single question) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The record of the app invocation can be retrieved from the `recording`:\n",
    "\n",
    "rec = recording.get() # use .get if only one record\n",
    "#recs = recording.records # use .records if multiple\n",
    "\n",
    "#display(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The results of the feedback functions can be rertireved from the record. These\n",
    "# are `Future` instances (see `concurrent.futures`). You can use `as_completed`\n",
    "# to wait until they have finished evaluating.\n",
    "\n",
    "from concurrent.futures import as_completed\n",
    "\n",
    "for feedback_future in  as_completed(rec.feedback_results):\n",
    "    feedback, feedback_result = feedback_future.result()\n",
    "\n",
    "    feedback: Feedback\n",
    "    feedbac_result: FeedbackResult\n",
    "\n",
    "    display(feedback.name, feedback_result.result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[\"Chain1_ChatApplication\"])\n",
    "\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[\"Chain2_ChatApplication\"])\n",
    "\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.3. Multiple questions evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        print(item)\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder as recording:\n",
    "        rag_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "self_retriever.invoke(\"Vorrei prenotare un alloggio a tariffa intera per l'a.a. 2023-24. Come posso procedere?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder3 as recording:\n",
    "        self_retriever.invoke(question)\n",
    "        \n",
    "        #__record__.app.first.steps.context.first.get_relevant_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder4 as recording:\n",
    "        self_retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder2 as recording:\n",
    "        rag_chain_compressed.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "records[[\"input\", \"output\"] + feedback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.4. Explore in a Dashboard\n",
    "For reference see the following [link](https://www.trulens.org/trulens_eval/api/tru/#trulens_eval.trulens_eval.tru.Tru)\n",
    "def run_dashboard(\n",
    "        self,\n",
    "        port: Optional[int] = 8501,\n",
    "        address: Optional[str] = None,\n",
    "        force: bool = False,\n",
    "        _dev: Optional[Path] = None\n",
    "    ) -> Process:\n",
    "        \"\"\"\n",
    "        Run a streamlit dashboard to view logged results and apps.\n",
    "\n",
    "        Args:\n",
    "            - port: int: port number to pass to streamlit through server.port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tru = Tru()\n",
    "#tru.reset_database()\n",
    "tru.run_dashboard(port = 8503) # open a local streamlit app to explore\n",
    "\n",
    "# tru.stop_dashboard() # stop if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conda activate aienv\n",
    "cd Finetuning/BOT_V3_Langchain  \n",
    "# PORT problem solved by chainging the port number in tru.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Alternatively, you can run `trulens-eval` from a command line in the same folder to start the dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note: Feedback functions evaluated in the deferred manner can be seen in the \"Progress\" page of the TruLens dashboard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# the recorder is initialized as prebuilt we will need some more lessons to undertand how to actually implemet "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "aienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5737f6101ac92451320b0e41890107145710b89f85909f3780d702e7818f973"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
